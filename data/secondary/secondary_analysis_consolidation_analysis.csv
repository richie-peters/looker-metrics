dashboard_id,dashboard_name,consolidation_priority,key_synthesis,response_id
fbf4d483-b17a-4040-b18c-091481d62200,NewsQuery - Cost Tracking,medium,"The 'NewsQuery - Cost Tracking' dashboard exhibits strong data source consolidation, with all six metrics consistently querying the same BigQuery billing export table and applying uniform date and 'Invoice' service exclusions. This indicates a well-structured foundation for cost tracking. However, the absence of SQL execution data prevents a comprehensive validation of these metrics against live query performance or actual results. Two key anti-patterns were identified: a hardcoded list of 'Selected Services' in one metric, which lacks flexibility, and duplicated project name cleaning logic across multiple metrics, suggesting an opportunity for centralized transformation. The high consolidation score (9) from the initial analysis is supported by the consistent data source usage, but the identified coding practices and lack of execution data warrant further investigation.",0
4e1253ba-efdf-459d-83de-d00b3d77cc29,Brands Review Dashboard - FY25,medium,"The dashboard's metrics primarily source from a single table, `adsales_performance_archive_FY25`, indicating a good level of data source consolidation. However, the absence of live SQL execution data prevents validation of query performance or actual data consistency. Analysis of the metric definitions reveals significant opportunities for refactoring complex, hardcoded logic and consolidating redundant calculated fields to improve maintainability, readability, and potentially performance. The dashboard's complexity score of 8 aligns with the observed intricate SQL for certain metrics.",1
490533a1-5f98-468e-aa8a-2f245e8a2b90,Team Sales Performance CONS WA,high,"The dashboard 'Team Sales Performance CONS WA' exhibits a high degree of complexity and consolidation potential, as indicated by its scores of 8. While all metrics consistently draw from the same `adsales_performance` table, there are significant anti-patterns related to repeated hardcoded filters, a static 'as-of' date in a key revenue metric, and critically, the use of `LIMIT 100` on dimension queries, which can lead to incomplete data representation. The absence of SQL execution summary data prevents validation of query performance or actual result sets, necessitating further investigation into live data behavior.",2
af5b3038-ea93-4cf0-9bf5-44a9b09b3766,Conde Nast Analysis,high,"The initial AI analysis assigned a high consolidation score (9), but a deeper review of the detailed metric SQL reveals significant anti-patterns related to hardcoded filtering logic. Multiple 'Gross Revenue' and 'Pages Count' metrics are essentially duplicates, differing only by a single month or the absence of a month filter, and all share extensive hardcoded `WHERE` clauses for publication, revenue type, source system, and transaction status. This indicates a lack of parameterization and reusability, leading to metric proliferation and high maintenance overhead. Additionally, all dimension metrics are limited to 10 distinct values, which could lead to incomplete data representation. The absence of SQL execution summary data prevents validation of live performance or actual data output, making these observations areas for further investigation.",3
71dfdbc0-a8d2-4131-bf4e-7e54ac7e6b5e,Lapsed/Cancelled EDM stats,high,"The dashboard 'Lapsed/Cancelled EDM stats' exhibits a high degree of physical data source consolidation, with all 17 metrics drawing from the `prstn_consumer.newsletter_activity` table. However, a critical anti-pattern in logical consolidation has been identified: campaign-specific metrics (Lapse, Newspass, Winback, Cancel EDM) rely on repeated, hardcoded `REGEXP_CONTAINS` patterns for `newsletter_send_email_name`. This approach is brittle, prone to errors (a 'Winbacl' typo was found in Winback EDM metrics), and lacks scalability for future campaign types or naming convention changes. The absence of live SQL execution data prevents validation of these metrics against actual query performance or results, highlighting a significant gap in monitoring.",4
1e9c7a29-2613-47b8-85d1-127e5b8c66ac,Cancellations Extract,high,"The 'Cancellations Extract' dashboard exhibits a high consolidation score (9) due to all 6 metrics sourcing data from a single table (`acquisitions_cancellations_movements`) and applying consistent core filtering logic. This promotes data consistency across the dashboard. However, this consolidation is significantly undermined by pervasive anti-patterns in the SQL logic: critical business dimensions like 'masthead_group' and 'subscription_type' are defined using complex, hardcoded CASE statements that are repeated verbatim across all metrics. This introduces substantial technical debt, making the dashboard brittle, difficult to maintain, and prone to inconsistencies if business rules change. The absence of SQL Query Execution Summary data prevents validation of live performance and data behavior, highlighting a critical gap in observability.",5
cb5ce22d-b196-49dc-9d7b-8db7ca1f1f4d,Performance Solutions - Fin Year,high,"The dashboard 'Performance Solutions - Fin Year' exhibits a high degree of consolidation at the data source level, with all 9 metrics drawing from the single `v_adpoint_detail` table in BigQuery. This is a strong foundation. However, despite the AI's reported 'consolidation_score' of 8, a detailed review of the SQL logic reveals significant duplication of common filtering conditions and hardcoded business rules across metrics. This indicates a high opportunity for *further* consolidation at the SQL logic layer, which would drastically improve maintainability, reduce potential for inconsistencies, and enhance reusability. The absence of live SQL execution data prevents validation of metric accuracy or performance, highlighting a critical area for investigation.",6
a07c3b8c-9aac-4462-8d22-f3c662016f59,Verity 2.0 The Weekend Australian Performance,high,"The analysis of 'Verity 2.0 The Weekend Australian Performance' dashboard reveals significant concerns regarding data completeness and dynamic filtering capabilities. Crucially, the `sql_execution_summary` was empty, preventing validation of the provided SQL logic against live query results. All three metrics exhibit hardcoded date ranges, severely limiting the dashboard's utility for historical or dynamic analysis. Furthermore, two metrics (`page_view_events_by_user_detail`, `verity_user_reference_count`) include `LIMIT 10` clauses, and `total_publication_group_target` includes `LIMIT 1`, which are highly unusual for dashboard metrics and suggest incomplete data presentation. The `total_publication_group_target` also hardcodes a specific publication group ('Business'), reducing its flexibility. These issues contradict the initial AI analysis's '0 governance issues' and indicate a need for immediate review to ensure data accuracy and dashboard functionality.",7
88d635d0-512a-4ad8-b430-afcffbdb72bb,FY24 Freemiums Report,high,"The 'FY24 Freemiums Report' dashboard, while sourcing all metrics from a single BigQuery table (`campaign_performance_consol`), exhibits significant anti-patterns that severely undermine its consolidation and maintainability. A critical observation is the pervasive repetition of an identical, complex `WHERE` clause across all 41 metrics, indicating a lack of centralized filtering. Furthermore, all dimension queries are arbitrarily limited to 100 distinct values, which will lead to incomplete and potentially misleading data representation. Hardcoded `CASE` statements for `campaign_classification` and source-specific subscription metrics (`Meta Subscriptions`, etc.) introduce brittleness and hinder scalability. The absence of `sql_execution_summary` data prevents direct validation of live query performance or actual data results, making these observations critical areas for immediate investigation and remediation.",8
57d87efe-c112-4d42-be1b-045f0c8ca73e,Commercial Finance Scorecards,high,"The 'Commercial Finance Scorecards' dashboard, despite its high initial complexity and consolidation scores, exhibits significant anti-patterns that severely impact its maintainability, accuracy, and future scalability. The most critical finding is the pervasive hardcoding of a specific fiscal week (FY2025, Week 37) across nearly all metrics and filtering logic. This renders the dashboard static and requires manual updates for each reporting period. Furthermore, the presence of numerous '_V' suffixed metrics suggests potential redundancy or unclear metric definitions, hindering true data consolidation. The initial AI analysis's '0 total governance issues' is a critical misrepresentation, as the detailed SQL logic reveals multiple severe governance and coding practice violations.",9
e2102eb1-8bdb-4df7-b3ea-e72481f1bb55,Verity 2.0 Geelong Advertiser: Sunrise Report (Click here to access the full report),low,"The 'Verity 2.0 Geelong Advertiser: Sunrise Report' dashboard is highly focused, featuring a single, high-criticality KPI ('Total C-Score Target') derived from a straightforward aggregation of a reference table. This inherent simplicity and direct data sourcing contribute to its high initial consolidation score (6). While the underlying SQL appears clean and simple, the critical absence of SQL query execution summary data prevents a comprehensive validation of the metric's live performance, data volume, and consistency. This lack of live data is the primary area for immediate investigation, despite the apparent simplicity and good consolidation of the metric definition itself.",10
8ae7916a-45c9-4713-8d46-e3470805c7f6,NewsQuery Cost Operation Dashboard,high,"The analysis is significantly constrained by the absence of live SQL query execution data, preventing direct validation of metric outputs. However, a review of the provided SQL logic reveals critical anti-patterns and potential logical errors. Most notably, the 'PII Data Access Events' metric includes a `LIMIT 1` clause on a `COUNT(*)` aggregation, which will fundamentally misrepresent the actual count of events. Additionally, both metrics exhibit hardcoded values and complex filtering logic that could benefit from consolidation into shared lookup tables or more robust, dynamic parameterization, aligning with the dashboard's low initial consolidation score (3).",11
06bf534b-be32-4ebe-9013-fee9a581dcd6,Verity 2.0 NSN,high,"The dashboard 'Verity 2.0 NSN' exhibits significant opportunities for consolidation and refactoring. A critical observation is the complete absence of SQL query execution summary data, which prevents validation of metric assumptions against live performance or result sets. However, the detailed metric definitions reveal pervasive anti-patterns, including extensive duplication of complex SQL logic (especially for newsletter-related metrics), heavy reliance on hardcoded `REGEXP_CONTAINS` patterns for categorization and filtering, and hardcoded dates for target metrics. These issues indicate a high maintenance burden, potential for inconsistencies, and a lack of a centralized data model or reusable components.",12
6c8affc5-3d5f-4481-a0ff-d3f6b4cec4a8,Verity 2.0 The Australian Daily,high,"The initial AI analysis reported a high consolidation score (8) and zero governance issues for this dashboard. However, a detailed review of the metric SQL logic reveals significant anti-patterns, specifically the repeated use of identical SQL queries with only hardcoded date filters changing. This directly contradicts the reported high consolidation and absence of governance issues, indicating a strong need for metric consolidation and parameterization. The absence of SQL query execution summary data prevents validation of live performance or data consistency, limiting the depth of this analysis.",13
bd697806-2124-441a-b991-fdf075461dbf,Genome - Herald Sun engagement,high,"The dashboard's metrics are well-defined in terms of business descriptions and appear to follow a consistent naming convention. However, the absence of live SQL execution data prevents validation of actual performance or data integrity. A critical anti-pattern identified is the hardcoded date range in the 'HS Masthead' metrics, rendering them static and not suitable for ongoing monitoring. Furthermore, the SQL logic for different mastheads ('AA', 'HS', 'TA') is highly repetitive, relying on hardcoded string filters for masthead, member type, customer type, and classification, indicating a significant opportunity for consolidation and parameterization to improve maintainability and scalability.",14
3da46266-c061-46a2-95df-5c4486efd89c,Last 6 months - highest subscriber usage - PII removed,high,"The dashboard, despite its name 'Last 6 months - highest subscriber usage', relies heavily on hardcoded future `YearMonth` filters (e.g., '2025-06', '2025-01', '2025-02') across almost all its metrics. This renders the dashboard static and unable to dynamically reflect 'Last 6 months' data without manual updates, directly contradicting its implied purpose. The initial AI analysis reported 'total_governance_issues: 0', which is inaccurate given the prevalence of hardcoded logic and complex `CASE` statements for categorization. A significant concern is the dashboard's name stating 'PII removed' while several metrics explicitly use `DETERMINISTIC_DECRYPT` on `email` and reference `PCSID`, suggesting potential PII handling. The absence of `sql_execution_summary` data prevents validation of query performance or actual results, making it impossible to confirm if the queries are even returning data for these future dates.",15
47854b57-024a-4188-adec-cb2f68607208,NewsQuery Overview ,high,"The 'NewsQuery Overview' dashboard, while having a moderate consolidation score, presents a critical issue in its high-criticality KPI, 'Count of Tables by Usage/Load Status (SDM Data Layer)'. This metric's SQL logic relies on a hardcoded future date (2025-07-09) for all its time-based calculations, rendering it static and ineffective for real-time or ongoing operational monitoring of table usage and load status. This directly contradicts its stated business purpose of identifying stale or underutilized tables dynamically. The absence of any SQL execution summary data prevents live validation of query performance or results, indicating a significant gap in observability that requires immediate investigation.",16
76614538-e13f-4fd7-b6f2-f23a1ce65e1b,Postcode paid subscriber lookup - Genome data - draft,high,"The dashboard, despite having a reported consolidation score of 7, presents significant opportunities for architectural improvement and consolidation. Two of its three key metrics are nearly identical, differing only by hardcoded dates, which indicates a lack of dynamic parameterization and leads to redundant metric definitions. A critical observation is the complete absence of SQL query execution data, which prevents any validation of live query performance, cost, or potential runtime errors, making it an immediate area for investigation.",17
7888a780-7777-411b-b07b-398b87d2cfd0,Newpass reporting,high,"The analysis is significantly limited by the absence of live SQL query execution data, preventing validation of metric performance or identification of data mismatches. However, based on the provided metric definitions, the dashboard presents a clear opportunity for consolidation. Both metrics, 'Total Acquisitions by Product, Offer, and Source Dimensions' and 'Total Acquisitions (Excluding The Australian Product)', derive from the same base table (`t_newspass_crm_coversion_myaccount_fct`) and the same core measure (`acquisition_count`). The latter metric is merely a filtered version of the former, indicating that they could be consolidated into a single, more flexible base metric with dynamic filtering capabilities, reducing redundancy and improving maintainability.",18
3f48ba44-14ba-4a43-b02c-7700d0f49c0b,Kidspot Weekly Update,high,"The 'Kidspot Weekly Update' dashboard, despite its low metric count (2) and initial low consolidation score (2), presents a high consolidation priority due to critical hardcoded date ranges within both metric SQL definitions. This design choice renders the dashboard static and effectively useless for ongoing weekly updates without manual intervention, directly contradicting its 'Weekly Update' purpose. The complete absence of `sql_execution_summary` data prevents any validation of query performance, data volume, or potential runtime errors, highlighting a significant gap in observability. The dashboard's current state suggests it functions more as a historical snapshot than a dynamic reporting tool, necessitating immediate refactoring to incorporate dynamic date parameters for true utility and maintainability.",19
bac3734e-7fa0-4c2e-aee2-5547277d21f3,EIC Weekly Newsletter Dashboard,high,"The dashboard, despite its name 'EIC Weekly Newsletter Dashboard' implying dynamic weekly reporting, relies heavily on hardcoded date ranges for all its metrics. This fundamentally limits its utility as a 'weekly' dashboard and necessitates manual updates or re-creation for each new reporting period. Furthermore, specific brand and email filters are hardcoded into individual metrics, leading to significant SQL repetition and hindering true metric reusability. The initial AI analysis's 'consolidation_score' of 8 appears misleading given these hardcoding patterns. The absence of SQL execution summary data prevents validation of query performance or actual data results, leaving critical gaps in the analysis.",20
b1c5901f-a535-42eb-870d-05cc025f7c27,OS extract for month end rec,high,"The dashboard 'OS extract for month end rec' is designed for highly specific financial reporting, evidenced by metrics like 'Budget Amount (FY2025, Week 4, News Media Publishing, Revenue/Expenses)'. While the initial AI analysis assigned a high consolidation score (8), a deeper dive into the SQL reveals that the primary measures (`Budget Amount`, `Actual Amount`) are heavily hardcoded with specific fiscal years, weeks, and business units. This approach, while potentially consolidating specific 'extracts' onto one dashboard, leads to a lack of reusability and scalability for the underlying metric definitions. The repeated, complex subquery logic for calendar and period control across multiple metrics further indicates an opportunity for architectural consolidation and improved maintainability. The absence of SQL execution summary data means observations are based solely on static SQL analysis.",21
0f03691d-f6b8-4313-bfd9-a5fb1e6dedab,IP Engagement Report,high,"The 'IP Engagement Report' dashboard exhibits a high degree of data source consolidation, with all metrics drawing from a single fact table (`b2b_ipsubscriber_engagement_fct`). However, this consolidation is significantly undermined by extensive hardcoding of client names, specific date ranges, and brand exclusions directly within individual metric SQL queries. Crucially, the presence of a `LIMIT 1` clause in *all* metric queries directly contradicts the stated business descriptions that these metrics are 'often analyzed by' various dimensions (e.g., visit hour, client, industry, device type). This indicates that the current metric definitions are not suitable for dynamic slicing and dicing, severely limiting the dashboard's analytical utility and requiring significant refactoring for true reusability and parameterization. The initial AI's high consolidation score (8) likely refers to the single data source, but misses the lack of dynamic parameterization.",22
3c8903a2-8dab-445a-9965-8cc2dbeceb0b,AVP - Video Data Dashboard,high,"The 'AVP - Video Data Dashboard' effectively tracks key video advertising and content metrics. However, a critical observation is the pervasive use of hardcoded exclusion logic for specific ad units across 7 out of 9 metrics. This anti-pattern significantly increases maintenance overhead and the risk of data inconsistencies. The absence of any SQL execution summary data is also a major concern, as it prevents validation of query performance, actual data behavior, or identification of potential runtime issues. This lack of operational insight elevates the consolidation priority to high, necessitating immediate investigation into data collection and a strategic refactoring of the hardcoded logic.",23
63f9fc08-acd1-4d1b-866e-5b2050b5093f,Genome - The Daily Telegraph engagement,high,"The dashboard 'Genome - The Daily Telegraph engagement' demonstrates strong consolidation at the data source level, with all five metrics drawing from the same `ncau-data-newsquery-prd.asl_audience_insights.subscriber_base_agg` table. This is a positive indicator for data governance and consistency. However, a critical anti-pattern observed is the pervasive use of hardcoded `report_date` values across almost all metrics, with each metric using a *different* static date. This severely limits the dashboard's utility for showing current or trending data and necessitates manual updates. Furthermore, there's an inconsistency in filtering for 'Print-only' subscribers across related metrics, which could lead to definitional discrepancies. The absence of live SQL execution data (`sql_execution_summary` was empty) prevents validation of query performance or actual data output, highlighting a crucial area for further investigation into the data pipeline and dashboard's operational health.",24
8ef11f47-cddf-481d-aad5-5d643a5a6031,Registration Journey Data Product,high,"The 'Registration Journey Data Product' dashboard, while having a high initial consolidation score, exhibits significant underlying data consistency issues and anti-patterns. Multiple metrics rely on repeated, complex SQL logic and hardcoded `CASE` statements for masthead and brand categorization. Critically, there are direct contradictions in how mastheads are grouped into 'Food Brands' and 'Lifestyle Brands' across different metrics, leading to potential misreporting and a lack of a single source of truth for these business definitions. The absence of `sql_execution_summary` prevents validation of live data behavior, but the static SQL analysis reveals a high need for refactoring and governance. The initial AI analysis stating '0 governance issues' is inaccurate given these findings.",25
2dfb1b58-42eb-44cb-b550-66469ae7df3c,Data Load Checks,high,"The 'Data Load Checks' dashboard, while having a good initial consolidation score, suffers from a critical anti-pattern: pervasive hardcoding of dates and specific filter values within its metric definitions. This makes the dashboard's metrics static and not reflective of current data load statuses. For instance, metrics are querying data from April/June 2025, whereas the live data execution summary indicates recent data from September 2025. This discrepancy severely limits the dashboard's utility for ongoing data load monitoring and reduces the reusability of its underlying metrics, necessitating a high consolidation priority to implement dynamic filtering.",26
5a9f9224-1cf1-48ec-a970-02bf9884b070,NTTM migrations and cancellations,high,"The dashboard, 'NTTM migrations and cancellations', initially received a high consolidation score (8), likely due to its reliance on a single core dataset (`prstn_consumer.subscription_movement` and `prstn_consumer.subscription_base`). However, a deeper analysis of the underlying SQL logic reveals significant fragmentation and anti-patterns in metric definitions. Multiple metrics employ extensive hardcoded date ranges, specific source codes, and lengthy 'IN' clauses for reason descriptions. This indicates a lack of logical consolidation and parameterization, making the dashboard brittle, difficult to maintain, and prone to errors when business rules or data values change. The absence of a `sql_execution_summary` prevents validation against live query performance or data consistency, highlighting a critical area for investigation.",27
a96a5942-b538-4aba-83cb-d4f16db9a59d,Code App quick look,medium,"The dashboard's initial AI analysis accurately describes its single metric. However, a deeper dive into the SQL logic reveals significant hardcoding, particularly for the report date and masthead identification, which severely limits the dashboard's dynamic utility and maintainability. Crucially, the absence of SQL execution summary data prevents any validation of the metric's live performance or data integrity, raising a critical area for investigation.",28
9269e9c6-1ad0-4415-96c3-aca8a710ba01,Team Sales Performance - FY26 (Interim),high,"The 'Team Sales Performance - FY26 (Interim)' dashboard, while initially assessed with a good consolidation score, presents significant maintainability and accuracy risks due to highly complex and hardcoded logic within its 'Conditional Gross Revenue' metric. The use of a fixed timestamp for date calculations and hardcoded lists for business categories (publication names, sales segments, advertiser parents) directly contradicts the dynamic nature implied by 'FY26 (Interim)' and will lead to data inaccuracies over time without constant manual intervention. The complete absence of live SQL execution data prevents any validation of query performance or actual data output, highlighting a critical gap in the current analysis and raising immediate concerns about the dashboard's operational health and reliability.",29
a474edd4-1aa9-4609-97ed-5d04f19dba9b,Governance Dashboard (MGR-TechM)[Data Portfolio] V2.1,high,"The analysis is significantly impacted by the absence of live SQL query execution data, which prevents direct validation of metric assumptions against runtime behavior. However, based on the provided metric definitions, the dashboard demonstrates good consolidation around a primary source table (`v_servicenow`) for most metrics. A critical observation is the pervasive inclusion of `LIMIT 1` in all metric SQL queries. This fundamental flaw would severely restrict the data returned to Looker Studio, rendering the dashboard largely non-functional for its stated analytical purposes (e.g., time-series analysis, aggregations). This functional impediment elevates the consolidation priority to 'high' due to the immediate need for remediation to ensure data accuracy and usability. While some hardcoded logic exists for priority and caller categorization, the adoption of an external lookup table for incident subject categorization is a positive indicator of good data modeling practice.",30
fed70b12-c274-4cde-9920-592ca4c4dab0,Independent Agency Report,high,"The 'Independent Agency Report' dashboard, while rated high in consolidation, contains a critical hardcoded date within its 'Previous FY YTD Gross Revenue (Adjusted)' KPI. This renders a high-criticality metric inaccurate for dynamic year-to-date comparisons. Additionally, the financial quarter logic relies on a hardcoded CASE statement, which is a common anti-pattern for financial reporting. The absence of SQL execution summary data prevents validation of query performance and actual data values, highlighting a gap in observability for this finance-domain dashboard.",31
abca77ac-e6e3-44ab-8cd9-64f1064d04fd,Mutti Rebranding,high,"The dashboard 'Mutti Rebranding' exhibits a high degree of hardcoded logic, particularly for date ranges and specific rebranding initiatives ('mutti'). Despite an initial consolidation score of 8, the detailed metric analysis reveals significant opportunities for further consolidation by leveraging Looker Studio's dynamic filtering capabilities (e.g., date range controls, dimension filters). The absence of SQL execution summary data prevents validation of query performance or actual data output, leaving critical areas for investigation regarding data integrity and efficiency.",32
3a820eee-f69e-403d-a972-29c4529ec582,Verity 2.0 Weekly performance report: DT & ST,high,"The dashboard's initial AI analysis reported a high consolidation score (5), however, a deeper review of the detailed metric SQL reveals a significant anti-pattern of de-consolidation. All four metrics are essentially variations of two base metrics ('C-Score Target' and 'Daily Website Target') with hardcoded date ranges and specific filters. This design choice necessitates manual updates for each reporting period, severely impacting maintainability and scalability. The absence of SQL execution summary data prevents validation against live query performance or results, limiting the analysis to theoretical code review.",33
9c992f02-f13b-4c32-a400-90135fdff180,Verity 2.0 - TAUS Wealth Last Week,high,"The dashboard 'Verity 2.0 - TAUS Wealth Last Week' exhibits a high degree of hardcoding, particularly for date ranges and categorical filters, across all its metrics. This leads to multiple, near-identical metrics that could be consolidated into fewer, more dynamic metrics using parameters. The absence of SQL execution data prevents validation of these metrics against live results, but the structural issues in the SQL logic are clear. The initial consolidation score of 7 suggests a significant need for improvement, which is strongly supported by the detailed metric analysis.",34
f8b92c6c-021f-47fc-b373-ad37503303c9,The Australian Business Network dashboards,high,"The dashboard's metrics, while seemingly consolidated based on the initial score, exhibit significant anti-patterns in their SQL logic, including deeply nested subqueries, convoluted date parsing, and hardcoded filters. Crucially, the SQL execution summary is empty, preventing live data validation and raising concerns about the dashboard's operational health or the analysis pipeline itself. A critical issue is the 'Record Count of Targets' metric, which is filtered for a future date, likely rendering it uninformative.",35
df9ff24e-bc0e-41ae-ae42-6b52502b3c25,CentOs to RockyLinux migration report [PRD],high,"The dashboard's metrics, while well-defined in their business descriptions, suffer from significant SQL code duplication across multiple measures. A complex subquery for filtering and deduplicating Airflow DAG run data is repeated verbatim in 9 out of 13 metrics. This indicates a strong need for a consolidated data model or common table expressions (CTEs) to improve maintainability, performance, and ensure data consistency. Furthermore, the absence of live SQL execution data prevents validation of these complex queries against actual runtime performance or data consistency, making the identified code duplication a critical area for immediate attention.",36
b7e81310-51c9-4095-a2d9-7b1ad2e25504,Leader: My week last week,high,"The dashboard 'Leader: My week last week' was initially assessed with a high consolidation score (8). However, a detailed review of its metrics reveals a significant anti-pattern: three distinct 'Events by Dimension' metrics are present, each hardcoded to a specific week in 2025. This design choice directly contradicts the principle of consolidation, as a single, parameterized metric with dynamic date filtering would be far more efficient and maintainable. This indicates a high priority for consolidation efforts to improve reusability and reduce metric sprawl. Furthermore, the absence of SQL execution summary data prevents any validation of metric performance, query costs, or actual data consistency, highlighting a critical area for immediate investigation.",37
858161fd-9f14-4882-b218-2190b7325229,REA/RCA Referral Report,high,"The 'REA/RCA Referral Report' dashboard, while having a high consolidation score (8) in its initial summary, exhibits several opportunities for improved data governance and consolidation at the metric level. Key metrics like 'REA News.com.au Traffic Visits' and 'RCA Total Traffic Visits' rely heavily on hardcoded string values for filtering, indicating a potential for maintenance overhead and lack of reusability. Similarly, 'Transformed NCAU Brand' uses a hardcoded CASE statement for display logic. The absence of `SQL Query Execution Summary` data prevents validation of these hardcoded assumptions against live data and the identification of runtime issues or data mismatches. The use of `LIMIT 10` in dimension definitions is also an anti-pattern for production metrics.",38
873c6df9-9e76-46fd-ac4d-c35588976095,"Cases & Booking Test Report - Operational - 14/03/2025, 18:00",high,"The dashboard's metrics, while seemingly consolidated at a high level (indicated by a consolidation score of 8), exhibit significant anti-patterns in their underlying SQL logic. All 8 metrics share an almost identical, complex Common Table Expression (CTE) for `RankedCases`. This repetition indicates a severe lack of data model consolidation and reusability at the SQL level, leading to potential performance inefficiencies, increased maintenance burden, and a higher risk of inconsistencies. Furthermore, the absence of live SQL execution data prevents validation of assumptions or identification of runtime issues, necessitating immediate investigation.",39
f5afdb43-bb70-48be-a049-79cf77f7c6a6,Verity 2.0 The National News Network Weekly,high,"The 'Verity 2.0 The National News Network Weekly' dashboard is critical, with all 4 metrics identified as KPIs and having high business criticality. However, a significant observation is the complete absence of SQL query execution summary data, preventing validation of the provided SQL logic against live performance or results. A primary anti-pattern identified across all metrics is the use of hardcoded date ranges, which severely limits the dashboard's dynamic utility and requires manual updates. Additionally, string-based filtering using `STRPOS` for key dimensions like 'customer type' and 'masthead' could indicate a need for more robust, standardized lookup values or direct equality checks for improved maintainability and performance.",40
80ca81f3-0671-40ef-a0a9-825a1580ca1b,Team Sales Performance,medium,"The 'Team Sales Performance' dashboard, while having a low number of metrics and sourcing from a single table, exhibits a significant anti-pattern in its dimension definitions. The 'Advertiser Name (Filtered by Portfolio)' metric relies on hardcoded values for filtering, which severely impacts its maintainability and reusability, contradicting the initial high consolidation score. The absence of SQL query execution summary data prevents validation of metric performance or data integrity against live results, necessitating further investigation into data pipeline health.",41
eb93c6d9-ab5b-47bb-8acd-3cc0f3978a8b,Video Data Dashboard - development v1,high,"The dashboard's metrics consistently apply a hardcoded exclusion filter for specific ad unit names, which is repeated across all defined metrics. While the initial analysis indicates a high consolidation score (8), this pervasive hardcoded logic contradicts that from a code maintainability and governance perspective. The absence of live SQL execution data prevents validation of metric performance or data accuracy, making it a critical area for investigation. The repeated logic for deriving event counts also presents an opportunity for data model optimization.",42
c4355ac4-14e3-42a0-ae17-f706fa774b3b,Election Reporting,high,"The dashboard's initial analysis reports a high consolidation score (8/10), but a deeper dive into the detailed metric SQL reveals critical issues that render the dashboard non-functional for live reporting. All metrics and dimensions include a 'LIMIT 1' clause, which fundamentally breaks aggregation for counts and prevents dimensions from returning multiple values for grouping or filtering. Furthermore, all queries are hardcoded to a specific future date range (January to April 2025), making them irrelevant for current data. The absence of `sql_execution_summary` prevents validation against live query performance or results, but the inherent flaws in the SQL logic itself are severe. The repeated hardcoded lists of websites and varying hardcoded end dates across metrics indicate a lack of parameterization and potential for inconsistency.",43
c560ed20-040d-4c6a-9c3f-ec8bce27d132,Xtend Details,high,"The analysis is severely hampered by the absence of live SQL execution data, preventing validation of the dashboard's metrics against actual query performance or results. However, a critical anti-pattern was identified in the SQL definitions for all dimensions: they incorrectly use `LIMIT 1`. This design flaw will prevent the dashboard from displaying a full range of values for these dimensions, rendering time-based analysis (year, quarter, load datetime) largely dysfunctional. Additionally, the primary revenue metrics exhibit duplicated hardcoded filtering logic, indicating a potential for maintenance overhead and inconsistency.",44
d3723d73-7698-4fc2-b998-157308d5353f,CDP Ph3 Derived dimensions - subscriber_value_group,low,"The dashboard exhibits strong logical consolidation, with all five metrics sourcing data from the same `subscription_base` table and four out of five metrics applying identical filtering logic for 'active, paying' subscribers. This indicates a well-structured dashboard in terms of data sourcing. However, the absence of live SQL execution summary data prevents a comprehensive validation of these metrics against actual query performance or potential data discrepancies, making it impossible to confirm if the theoretical consolidation translates into optimized live performance or accurate results.",45
77c68c35-20ce-477a-b216-0c781d43a8ca,Cecile - Adsales Adhoc Analysis,medium,"The analysis of the 'Cecile - Adsales Adhoc Analysis' dashboard is significantly constrained by the absence of live SQL execution data. This prevents validation of metric assumptions against actual results and identification of data discrepancies. Based solely on the provided metric definitions, several anti-patterns related to hardcoded values and duplicated filtering logic were identified. While the dashboard's reported consolidation score is good (7), the underlying metric SQL suggests opportunities for improved code consolidation and reusability, particularly in shared filtering criteria. A highly unusual aggregation (summing financial week IDs) also warrants immediate investigation.",46
be89856b-4177-42f1-8cb6-50cdde0d516c,Network Module- Engagement ( version 1.0),high,"The dashboard exhibits a high degree of base metric reuse (e.g., 'total_page_bounces', 'unique_visits'), which contributes to its reported 'consolidation score' of 8. However, the implementation of these metrics is highly fragmented and hardcoded. All metrics are tied to specific, hardcoded date ranges (e.g., June 2025, July 2025, April 2025), requiring manual updates for each reporting period. This significantly increases maintenance overhead and the risk of data staleness or errors. Furthermore, there is a direct duplication of an identical metric definition (`unique_visits_by_source_july2025` and its alias), indicating a lack of robust metric governance. The initial AI analysis reported '0 governance issues', which is contradicted by the detailed metric review, highlighting a gap in automated detection of hardcoded logic and duplication.",47
dcaf9349-5068-4b74-8073-0b6c1cb56435,CTO Dashboard ,high,"The analysis of the 'CTO Dashboard' reveals significant opportunities for consolidation and improvement in SQL coding practices. Crucially, the `sql_execution_summary` was empty, preventing direct validation of metric outputs against live data. This absence means the analysis relies solely on the provided SQL logic and metadata. Based on the SQL, a pervasive anti-pattern of hardcoded values (table names, date ranges, status definitions) and duplicated complex logic for data quality checks was identified across multiple metrics. This indicates a high need for refactoring into shared views or a more robust data quality framework to enhance maintainability, scalability, and accuracy.",48
a17622e2-ad43-49cc-b3c5-19c95036fd14,Advertising Rebates Dashboard,high,"The dashboard's initial analysis indicates a high consolidation score (8), which is supported by all metrics drawing from a single, consistent data source (`v_adsales_revenue_client`). However, a deeper dive into the detailed metric SQL reveals a significant anti-pattern: extensive duplication of SQL logic with hardcoded filter values for year, month, and specific account numbers. This indicates a lack of parameterized or templated metric definitions, leading to high maintenance overhead and potential for inconsistencies. The absence of SQL execution summary data prevents any validation of live query performance, data volume, or potential data mismatches, making it a critical area for immediate investigation.",49
8187da8b-833b-4d26-b833-4d26-b88c-8fafddf4906a,CODE Sport Performance Report,high,"The 'CODE Sport Performance Report' dashboard, despite an initial consolidation score of 6, exhibits significant opportunities for improvement. A deep dive into the metric SQL reveals extensive hardcoding, particularly in channel and classification definitions, leading to repetitive and unmaintainable logic. Furthermore, the dashboard draws from two distinct data models (`v_subscription_movement` and `campaign_conversion_fct`), each with its own set of hardcoded filters (e.g., fixed date ranges for campaign data), indicating a lack of a unified data strategy and dynamic reporting capabilities. The reported '0 governance issues' by the initial AI analysis is contradicted by these observed anti-patterns, highlighting a gap in automated governance detection.",50
828d35dc-ea9f-4c01-b95f-9b64ae7500f1,Verity 2.0 AA Weekly Performance Report,high,"The initial AI analysis reported a high consolidation score (7) and zero governance issues. However, a detailed review of the metric SQL logic reveals significant anti-patterns related to hardcoding and metric duplication. Specifically, three distinct metrics exist for 'Total C-Score Target' that differ only by hardcoded date ranges, indicating a severe lack of parameterization. Furthermore, multiple metrics hardcode 'The Advertiser' publication group, limiting reusability. The absence of SQL execution summary data prevents validation against live performance or actual query results, making the assessment of efficiency and potential data mismatches challenging.",51
e4388523-0bd5-4a21-9f68-b84d2dcd8ef6,Team Sales Performance - TY vs LY,high,"The 'Team Sales Performance - TY vs LY' dashboard, while focused on a critical sales domain, exhibits significant opportunities for consolidation and improved data governance. A primary observation is the pervasive use of hardcoded values and complex, repeated `CASE` statements directly within metric SQL. This includes financial period calculations, revenue type encoding, and especially sales manager categorization, which even contains inconsistent leading spaces. This approach severely impacts maintainability, scalability, and data consistency. The absence of live SQL execution data prevents validation of these patterns against actual query performance or result sets, but the static SQL itself points to a high technical debt. The dashboard's reliance on specific hardcoded filters (e.g., 'Client' sales group, 'Belinda MacPherson' GM, 'Jul Q1 H1' financial period) suggests a lack of dynamic filtering or parameterization, limiting its reusability across different sales teams or timeframes without manual modification.",52
b6409a96-a733-4898-a32b-12372919adb7,SD and Z scores Metro,high,"The dashboard's metrics are consistently sourced from a single table (`Metro_SD_Z_Score`), indicating good data source consolidation. However, the absence of `SQL Query Execution Summary` data prevents validation of assumptions against live query performance or results. Analysis of the SQL logic reveals significant anti-patterns, including repeated hardcoded `CASE` statements for bucketing and hardcoded filter values, which undermine maintainability and scalability. Furthermore, the aggregation of pre-calculated standard deviation values (`SUM(active_days_stddev_...)`) raises concerns about statistical validity and data interpretation.",53
da75444c-ed16-43f1-accc-56326aa8ccb0,Verity 2.0 - TAUS World Daily Update,high,"The dashboard 'Verity 2.0 - TAUS World Daily Update' exhibits a high degree of underlying data consolidation, with all metrics sourcing from the same `t_registration_details_snapshot_summary` table and sharing a common `base_metric_id` of 'total_registrations'. However, a critical issue is the pervasive use of hardcoded dates across all metrics, rendering the 'Daily Update' aspect of the dashboard name misleading and requiring manual intervention for data freshness. Furthermore, one metric employs a hardcoded `CASE` statement for categorization, which is an anti-pattern for maintainability and scalability. The absence of live SQL execution data prevents validation of query performance or actual data output, necessitating further investigation.",54
df37a847-0ea1-4c69-a1a6-aeed166fa708,Editorial AI Dashboard - UAT Copy,high,"The 'Editorial AI Dashboard - UAT Copy' exhibits significant opportunities for consolidation and optimization, despite the initial AI analysis indicating '0 governance issues'. A deep dive into the SQL logic reveals a pervasive anti-pattern: identical, complex CTEs (`capi_data`, `artie_and_capi`, `final`) are duplicated across all 8 metrics. This redundancy severely impacts maintainability, performance, and consistency. Furthermore, a critical data integrity issue exists in the `capi_data` CTE, where a date filter `BETWEEN '2025-07-01' AND `current_date`()` will prevent any data from being displayed until July 2025, rendering the dashboard effectively empty or showing no current data. The absence of `sql_execution_summary` data prevents validation of live results, but the static SQL analysis highlights these fundamental structural and data issues. The hardcoded `CASE` statement for `publication_category` further compounds the maintainability challenge. Addressing these issues is paramount for the dashboard's accuracy, usability, and long-term sustainability.",55
af85d56a-2b11-489a-a2fa-8c5c2565f456,KTV Extracts,high,"The 'KTV Extracts' dashboard, focusing on consumer subscription movements, exhibits significant data integrity and maintainability concerns despite its high initial complexity and consolidation scores. A critical observation is the `NULL` values for 'Closing Base Subscriptions' in the primary analysis, which is a key performance indicator, contrasting with a valid sum in the business rules check. The 'Subscription Type Category' metric shows a direct data mismatch, incorrectly classifying 'Digital' delivery types as 'Print Subscriptions' due to incomplete hardcoded logic. Furthermore, the 'Business Segment Category' metric relies on an excessively complex, nested CASE statement, representing a major anti-pattern for scalability and governance. A concerning discrepancy exists with future-dated fiscal year data (FY2026) appearing in the primary analysis, which contradicts the reported `max_report_date` (2025-09-03) and a 'PASS' on the data freshness check, indicating a potential issue with data ingestion or fiscal period calculation.",56
362cc5e9-d421-48f2-bdf3-042b976176aa,DPE Monthly Product Data Report,high,"The 'DPE Monthly Product Data Report' dashboard, while having a good initial consolidation score, exhibits significant anti-patterns in its metric definitions. Core dimensions like 'Publication Category' and 'Publication Order ID' are defined using extensive, hardcoded CASE statements that are duplicated across multiple metrics. This approach severely impacts maintainability, introduces potential for inconsistencies, and indicates a lack of centralized data modeling for these critical business categorizations. The absence of live SQL execution data prevents direct validation but underscores the need for a deeper architectural review.",57
cba3081d-40b7-4d64-a9a2-a3316b192b8e,FY25 The Weekly Times Report,high,"The dashboard 'FY25 The Weekly Times Report' is intended to track advertising performance for 'Weekly Times' campaigns. While the initial AI analysis provided a high-level overview, a deep dive into the SQL logic reveals critical data accuracy issues and significant anti-patterns. Most notably, *every single metric query* includes a `LIMIT 1` clause, which will cause all aggregated sums to be severely understated and incorrect. This fundamental flaw renders the dashboard's reported numbers unreliable. Additionally, channel attribution and campaign filtering are heavily reliant on hardcoded `CASE WHEN LIKE` statements and `WHERE` clauses, indicating a lack of standardized dimensions and poor maintainability. The initial summary also missed a significant portion of the dashboard's metrics, focusing only on conversion subscriptions, while the dashboard also tracks performance metrics like impressions, spend, and recent activity.",58
c17f4598-1eb7-4947-8cbe-c7e09f9a9143,S&C Health - total results,high,"The dashboard's metrics are well-consolidated around a single base table (`t_registration_details_snapshot_summary`) and share common filtering logic, which is a positive for data governance. However, the critical observation is the absence of `SQL Query Execution Summary` data, preventing validation of the SQL logic against live performance or results. Furthermore, all metrics rely on a hardcoded date range (January 1-7, 2024), rendering the dashboard static and not reflective of current business performance. This hardcoding represents a significant anti-pattern requiring immediate attention for the dashboard to be useful for ongoing monitoring.",59
d05b3d29-4437-4ee5-987a-e0109eb9590e,Digi Subsifying,high,"The 'Digi Subsifying' dashboard, despite its high initial consolidation score, exhibits significant anti-patterns in its metric definitions. A pervasive issue is the repetition of complex, hardcoded `CASE` statements for categorizations (e.g., publication types, billing systems) across nearly all 22 metrics. This indicates a lack of centralized data modeling or derived dimensions, leading to high maintenance overhead and potential for inconsistencies. Furthermore, many metrics are hardcoded to a specific fiscal week (Week 39, 2025), rendering the dashboard static and requiring manual updates. The absence of live SQL execution data prevents validation of these assumptions against current data, highlighting a critical area for investigation into data access or query execution. One metric, 'Fiscal Week ID Sum', is explicitly flagged as unusual, suggesting a potential misconfiguration.",60
f9ccd2b5-7e80-4e3f-a00a-770cd45b1441,Editorial AI | User Overview,high,"The analysis is significantly hampered by the absence of a `sql_execution_summary`, which prevents validation of the dashboard's live performance or data accuracy. However, a deep dive into the `metrics_details` reveals critical anti-patterns. All five metrics share identical, highly complex base CTEs, indicating a severe lack of reusability and high maintenance burden. Furthermore, the SQL logic is riddled with hardcoded future dates and specific report dates, which would prevent the dashboard from displaying any current or relevant data. This dashboard is a prime candidate for consolidation into a shared, parameterized data source and requires immediate attention to its date filtering logic to become functional.",61
5515c1c6-18fe-449d-b621-d47631023320,Adpoint Line Items for Financial Accounting,high,"The dashboard exhibits a high degree of data source consolidation, with all 13 metrics drawing from the single `v_adsales_revenue_client` table. This aligns with the initial AI's high consolidation score. However, a critical anti-pattern was identified: an identical and extensive set of hardcoded filtering conditions is repeated across the SQL logic of *every single metric*. This significantly undermines maintainability and governance, despite the underlying data source consolidation. The absence of `sql_execution_summary` data prevents validation of query performance or actual data results, leaving a crucial gap in the analysis.",62
0a4ccf98-dfe7-4bab-b2ed-e2a27ebd9588,Kidspot Daily Update,low,"The 'Kidspot Daily Update' dashboard is a focused, small dashboard with 3 metrics, all designed to provide daily insights using `CURRENT_DATE()` filtering. All metrics pull from the `ncau-data-newsquery-prd.prstn_content_interaction` dataset, indicating a consistent data source. The initial analysis reports a low consolidation score (3) and low complexity (6), which aligns with the dashboard's narrow scope. However, the critical absence of `SQL Query Execution Summary` data prevents any validation of live performance, data volume, or actual query results. This is a significant gap for a comprehensive analysis, making it impossible to confirm if the metrics are performing as expected or if there are any runtime issues.",64
404605d3-dac4-4af9-b43e-b7915ecd7125,Inflated App PVS investigation,high,"The dashboard's primary purpose is to investigate inflated page views. A significant finding is the presence of two distinct 'Filtered Page Views' metrics (v1 and v2) that differ only by their hardcoded exclusion lists for 'standard pages'. This indicates a lack of a centralized, governed definition for 'standard pages', leading to redundant and brittle SQL logic. The absence of SQL execution summary data prevents validation of these metrics against live results, making it impossible to confirm the completeness of the exclusion lists or the impact of the 2,000,001 row limit.",65
d855425b-db68-413f-a814-a27139b0122d,Stale User UAT - id checks against other NewsQuery data,high,"The dashboard 'Stale User UAT - id checks against other NewsQuery data' is designed for UAT in the consumer domain, indicating a potentially critical purpose. It has a moderate complexity (7) and consolidation score (7) with 15 metrics. However, the absence of live SQL execution data (`sql_execution_summary` is empty) severely limits the ability to perform a comprehensive validation of metric performance, data volume, or actual output. A critical and pervasive anti-pattern observed across 12 out of 15 metrics is the use of hardcoded future dates in `WHERE` clauses. This fundamental data retrieval issue means the dashboard would display no data or only future-dated data in a live environment, rendering it currently unfit for its stated UAT purpose and requiring immediate attention.",66
d7e97228-032f-4b2d-b5fd-ec2d822c00d0,Copy of TCS Governance Dashboard [Data Portfolio] V2,high,"The dashboard, focused on ServiceNow incident metrics, exhibits significant data source inconsistencies and anti-patterns in its SQL logic. While the initial analysis reported 0 governance issues, a deeper dive reveals critical areas for improvement. Specifically, one key metric (`Incident Response SLA Rate`) relies on a backup table with a specific partition date, while others use a view, indicating potential data freshness and reliability issues. All metrics also use fragile hardcoded `LIKE` clauses for SLA type identification, which is prone to errors and difficult to maintain. The absence of SQL execution summary data prevents validation of performance or actual query results.",67
1184f09d-0506-4e10-aa79-b2cc9612feec,Mindgames Weekly Sales,high,"The 'Mindgames Weekly Sales' dashboard, while focused on a single business domain (sales) and leveraging a consistent base table (`v_subscription_movement`), exhibits significant anti-patterns related to hardcoded logic. A critical hardcoded list of `sold_in_rate_plan_code` values is repeated across all acquisition-related metrics, creating a high maintenance burden and potential for inconsistencies. Furthermore, several metrics and dimensions contain hardcoded date, year, and channel filters, severely limiting their reusability and requiring manual SQL modifications for any reporting period or filter adjustments. The absence of `sql_execution_summary` data prevents validation of query performance or actual data output, making it impossible to confirm if the current SQL logic is yielding expected results or encountering runtime issues.",68
7311af2c-89f8-4279-97b4-94ddb886964b,Verity 2.0 Cairns Post,medium,"The initial AI analysis reported a high consolidation score (8) for the 'Verity 2.0 Cairns Post' dashboard. However, a detailed review of the metric SQL logic reveals significant anti-patterns that contradict this assessment. Multiple metrics for GA4 events and consumer subscriptions are defined with hardcoded date ranges and specific filter values directly embedded in their SQL. This leads to a proliferation of nearly identical metrics, each for a different time period or specific filter combination, indicating a lack of dynamic parameterization and reusability. Furthermore, all provided SQL queries include a 'LIMIT 10' clause, which is highly unusual for dashboard metrics and suggests either an incomplete definition or an intent for sampling rather than comprehensive data display. The absence of live SQL execution data prevents validation of these observations against real-world performance or results.",69
1f134ccb-ed11-45d8-ac05-916f31640357,News.com.au Daily Update 5.0 Dev2.0,high,"The dashboard 'News.com.au Daily Update 5.0 Dev2.0' presents a critical discrepancy between its stated purpose and underlying implementation. Despite being named a 'Daily Update' dashboard and receiving an initial AI consolidation score of 6, all defined metrics rely on hardcoded `visit_date` filters (e.g., '2025-05-19', '2025-04-01', '2025-05-05'). This anti-pattern fundamentally undermines its 'daily update' functionality, implying a significant manual overhead for daily reporting or the creation of numerous redundant metrics/dashboards. The initial AI assessment of '0 governance issues' is misleading in this context, as hardcoded dates for dynamic reporting are a severe governance and maintenance concern. Furthermore, the complete absence of SQL query execution summaries prevents any validation of live data performance, query success, or actual results, leaving a critical blind spot in the analysis.",70
1091b278-b70b-40d5-af7b-5750a63c662d,Engagement: Subscriber Onboarding & In-Life Program Performance,medium,"The dashboard demonstrates strong data source consolidation, with all identified metrics and dimensions originating from a single BigQuery table (`ncau-data-newsquery-prd.prstn_consumer.newsletter_activity`). Measures consistently apply a 30-day lookback window, indicating a unified reporting period. However, the absence of live SQL execution data prevents validation of these assumptions against real-world performance or potential data discrepancies. Furthermore, several anti-patterns were identified in dimension definitions, particularly the extensive hardcoded `CASE` statement for brand cleaning and the problematic `LIMIT 1` clause in all dimension SQLs, which, if literally applied, would severely limit dashboard functionality.",71
a7a1d3ee-3b79-471c-a04a-22383717538e,Editorial AI - Source Data,high,"The dashboard, 'Editorial AI - Source Data', despite an initial AI assessment of '0 governance issues' and a 'consolidation score' of 7, exhibits critical underlying SQL anti-patterns and a severe data filtering error. All 10 metrics share an identical, complex subquery, leading to significant redundancy and maintenance overhead. More critically, a hardcoded future date filter (`2025-07-01`) in the core data preparation logic means the dashboard is currently designed to display no relevant data, rendering it non-functional for present-day analysis. The absence of SQL execution summary data prevents validation against live results, but the inherent flaws in the SQL logic itself are evident.",72
a318d7d9-e528-475f-8c17-9aefdfac4190,Copy of Test of Consumer - Core Subscription Health Check ,high,"The dashboard's three metrics, designed to monitor table freshness, are built upon an almost identical and highly complex SQL query. This extreme duplication of logic, including hardcoded table names, refresh schedules, and status determination rules, presents a significant maintenance burden and a high risk of inconsistencies. The absence of live execution data prevents validation of the dashboard's current state, but the structural anti-patterns strongly indicate a critical need for consolidation and externalization of metadata.",73
c6d33dfc-2694-44ce-85ae-8fed018197bb,Print to Digital,high,"The dashboard 'Print to Digital' exhibits critical data integrity and maintainability issues, despite an initial AI assessment of '0 governance issues' and a 'consolidation score of 7'. A deep dive into the SQL logic reveals that all metrics, including those described as 'Total Subscriptions', are severely flawed by the presence of `LIMIT 1` clauses combined with extensive `GROUP BY` statements. This fundamentally misrepresents the data, as only a single row (or group) is ever returned, making the 'total' metrics inaccurate and the 'breakdown' metric useless. Furthermore, widespread hardcoding of future dates and specific subscriber IDs renders the dashboard static and quickly obsolete. The absence of `SQL Query Execution Summary` data prevents live validation, but the static SQL itself indicates severe underlying problems that require immediate attention.",74
eef984c7-b528-4716-a506-e8e8bcb7861f,Verity 2.0 SA Weekend Content Review: Tuesday report,high,"The initial AI analysis reported a high consolidation score (8), however, a detailed review of the underlying SQL logic reveals significant anti-patterns indicating poor consolidation in practice. The dashboard relies heavily on hardcoded date ranges for nearly all metrics, requiring manual updates for each reporting period. Furthermore, core metrics like 'Total Interactions' and 'Post Count' are sourced from two different tables (`t_social_summary` and `t_social_interactions_summary`) for different periods, suggesting potential data model redundancy or a lack of a unified data source for social media metrics. This fragmentation will lead to high maintenance overhead and potential inconsistencies.",75
8956e94b-f6d1-46a3-9c7f-87a91fbe98b5,LODs,high,"The dashboard 'LODs' is noted for its high consolidation score (8) at the dashboard level, indicating a focused set of metrics within the advertising domain. However, a deeper analysis of the underlying SQL logic reveals a significant opportunity for *technical consolidation* and improved governance. All four metrics share an identical, complex `WHERE` clause, which is an anti-pattern for maintainability and consistency. This repeated logic, coupled with hardcoded exclusion/inclusion criteria, presents a governance challenge that contradicts the initial assessment of '0 governance issues'. The absence of live SQL execution data prevents validation of performance or actual data output, limiting the depth of this analysis to static code review.",76
56ec5017-2440-42e1-a7dd-3791f557b283,Audience Insights - Growth Performance - DRAFT,high,"The 'Audience Insights - Growth Performance - DRAFT' dashboard, while identified as high in complexity and consolidation by the initial AI analysis, exhibits significant anti-patterns in its metric definitions. A primary observation is the widespread use of hardcoded dates (specifically '2025-04-22' and a fixed range '2024-04-15' to '2025-04-20') across almost all metrics. This severely limits the dashboard's dynamic utility and requires manual updates for daily/periodical reporting. Furthermore, complex `CASE` statements for 'subscriber_type' are duplicated across multiple metrics, indicating a lack of centralized logic or a robust semantic layer. The absence of `sql_execution_summary` data prevents validation of these SQL constructs against live performance or actual data values, making it an immediate area for investigation. The initial AI analysis reporting '0 governance issues' appears to miss these critical hardcoding and duplication anti-patterns.",77
ac6844f3-d867-4726-a3b5-14eed55cb7cb,FY25 - 5.15 Verity one-pager - DRAFT,high,"The initial AI-generated analysis reported a high consolidation score (8) and zero governance issues for this dashboard. However, a detailed review of the underlying SQL for all 13 metrics reveals a significant contradiction. The dashboard is heavily reliant on hardcoded dates and specific dimension values (e.g., mastheads, newsletter email names) within each metric's SQL. This design choice leads to severe de-consolidation, requiring a new metric for every combination of date and dimension, making the dashboard extremely difficult to maintain, scale, and update. This pattern represents a critical anti-pattern for data governance and reusability, directly challenging the initial assessment.",78
1dff8d78-5d94-49fa-a2a5-086e3aaccd35,FY25 Copy of - Adsales Details Report,high,"The dashboard 'FY25 Copy of - Adsales Details Report' exhibits significant consolidation issues at the metric definition level. Multiple dimension metrics are created from the *same base table* (`details_dashboard_archive_FY25_T`) but with different hardcoded filters (e.g., financial year, revenue group subtype, account number, adsize name). This leads to redundant metric definitions, increased maintenance overhead, and a lack of reusability. The absence of SQL execution summary data prevents validation against live query performance or results, making it an immediate area for investigation. The dashboard name itself ('FY25 Copy of...') suggests a history of duplication rather than consolidation.",79
35de2eed-9c03-48a7-8cef-50e2ea1e1235,Dear Rachelle,high,"The dashboard's metrics, while seemingly distinct, exhibit significant anti-patterns in their SQL definitions. Three dimension metrics (`Article Dominant Section 1`, `Article ID`, `Category Topic Path`) redundantly apply the same `categorytopic_path` filter. Furthermore, the `Total Registrations - Federal Election & Specific Websites` metric relies heavily on hardcoded date ranges, specific content keywords, and a static list of websites, making it inflexible and difficult to maintain. This contradicts the initial AI's reported high consolidation score (8) and indicates a strong need for data model consolidation and parameterization to improve maintainability and reusability.",80
4218059f-a15e-4c99-90f5-75f7a1ef6792,Rewards Data,high,"The 'Rewards Data' dashboard, while functional, exhibits significant anti-patterns in its SQL logic that severely impact maintainability, performance, and data accuracy. The initial AI analysis's 'total_governance_issues: 0' is contradicted by the detailed metric review, which reveals widespread hardcoded date filters and redundant base data preparation. The absence of SQL execution summary data prevents validation of performance assumptions but highlights a critical gap in monitoring capabilities.",81
036fca1f-85fc-4041-a6b7-b917bd0d4f92,Verity At-A-Glance: NCA Metros - DT & AA,high,"The 'Verity At-A-Glance: NCA Metros - DT & AA' dashboard, while rated with a reasonable complexity (8) and consolidation score (7) in the initial analysis, exhibits significant anti-patterns in its underlying SQL logic. A critical observation is the absence of a `SQL Query Execution Summary`, which prevents any validation of metric assumptions against live data. Analysis of the detailed metric SQL reveals extensive hardcoding of business rules, particularly in filtering criteria for subscriber, newsletter, and push message metrics. Most notably, the newsletter metrics rely on extremely long and brittle `REGEXP_CONTAINS` patterns for inclusion and exclusion, and the planning metrics contain a hardcoded future date, severely limiting the dashboard's dynamic utility. These issues indicate a high priority for refactoring to improve maintainability, scalability, and ensure data accuracy and relevance.",82
564463c2-6eea-426b-9c38-73e8b0d563f4,SANDBOX VERSION - Paid Consumer Subscriptions Cancellation Dashboard,high,"The dashboard's high consolidation score (9) is contradicted by significant internal SQL anti-patterns, particularly the pervasive duplication of complex filtering logic across all metrics. This indicates a lack of centralized data modeling or view creation, leading to high maintenance overhead and potential inconsistencies. Furthermore, the absence of `sql_execution_summary` data prevents validation of metric assumptions against live query performance or results, highlighting a critical gap in the analysis process.",83
e0552be8-36bd-484d-aa60-b531621651c0,GIC Dashboard,medium,"The 'GIC Dashboard' focuses on audience and brand segmentation within the consumer domain, as indicated by its metrics. While the initial AI analysis reported zero governance issues, a deeper architectural review of the underlying SQL reveals significant anti-patterns related to hardcoded logic and repetitive conditional statements. Specifically, the 'Brand Group' metric relies on a truncated, hardcoded list of brands, posing a high risk for data accuracy and maintenance. The 'Audience Segment Detail' metric employs a repetitive `CASE` statement that could be refactored for improved maintainability. Crucially, the absence of SQL execution summary data prevents validation of these metrics against live performance or actual query results, highlighting a critical gap in observability and the ability to confirm the impact of these coding practices.",84
e2bcf559-c73c-4b2b-beb7-4f69084103a2,Google Case : 54272573,high,"The dashboard 'Google Case : 54272573' is designed to monitor BigQuery job activity and associated costs, specifically focusing on a particular query pattern related to 'sdm_profisee.profisee_data'. While it leverages both BigQuery Audit Logs and INFORMATION_SCHEMA for comprehensive insights, a critical architectural flaw is the pervasive use of hardcoded, fixed date ranges across multiple key metrics. This design choice severely limits the dashboard's long-term utility, rendering it static and requiring constant manual updates to remain relevant. Furthermore, a direct duplication of 'Total Data Cost' metrics (q3 and q6) with minor, inconsistent variations in their date filters highlights a lack of consolidation and introduces potential for data misinterpretation. The absence of live SQL execution data prevents validation of these metrics against actual query performance or results, making it difficult to assess their current accuracy and efficiency.",85
9a4e088f-264b-4a51-a6fc-165ab8c1230a,Campaign Performance - BAU Status,high,"The 'Campaign Performance - BAU Status' dashboard is designed to monitor critical data freshness across source, data warehouse, and presentation layers for advertising campaigns. Despite its high complexity score (8), its low consolidation score (2) is clearly reflected in the metric definitions. A significant anti-pattern observed is the pervasive use of hardcoded `CASE` statements for defining data availability statuses, which increases maintenance overhead and risks inconsistency across similar metrics. A critical logical error was identified in the `data_ingestion_job_status` metric, where a hardcoded string comparison (`'Google Ads' = 'SA360'`) renders a specific 'Green' condition unreachable, and the ordering of `WHEN` clauses is flawed. Furthermore, the 'Data Source Name' and 'Data Source Code' metrics are hardcoded to 'Facebook', despite other metrics querying 'Google Ads' data, indicating a significant lack of true multi-source consolidation at the metric level. The absence of live SQL execution data prevents validation of these observations against actual query performance or results, highlighting a gap in the monitoring capabilities.",86
ab333ebb-1c3d-4a64-8872-facfa657e825,Top 3 Site Sections Value Perception EDM,high,"The dashboard exhibits significant opportunities for consolidation and refactoring due to highly repetitive and complex SQL logic across multiple metrics. A critical observation is the presence of hardcoded future dates in the data filtering, which will prevent the dashboard from displaying current data. Furthermore, the complex, hardcoded `CASE` statements for article topic classification are an anti-pattern, indicating a strong need for a more robust and maintainable data modeling approach. A specific metric, 'Total Engagement Records by Brand', appears to have a significant data mismatch between its business description and the actual SQL implementation, potentially leading to misinterpretation of key performance indicators.",87
35ec2da8-3e63-4f97-90fa-bf9686769718,MRCA Advertising Performance Dashboard - FY26,high,"The dashboard's initial AI-generated consolidation score of 8 appears optimistic when reviewing the detailed metric definitions. Several key performance indicators (KPIs) exhibit significant hardcoding of specific business entities (e.g., publication names, advertiser names, months) directly within their SQL logic. This practice severely limits the reusability and maintainability of these metrics, creating a consolidation anti-pattern despite the dashboard drawing from a single base table. The absence of live SQL execution summary data prevents validation of these observations against actual query performance, data volumes, or runtime issues, making it a critical area for further investigation.",88
8479531e-aa8a-4701-a765-40a427a9deb0,Content Pillars - DRAFT,high,"The 'Content Pillars - DRAFT' dashboard, despite its draft status, exhibits significant anti-patterns in its metric definitions, indicating a high need for refactoring and consolidation. The most critical observation is the pervasive use of `LIMIT 1` in all provided SQL logic snippets, which is highly atypical for dashboard metrics and suggests either the provided SQL is not representative of actual Looker Studio execution or there's a fundamental misunderstanding of how these metrics are used for aggregation. Furthermore, there's extensive reliance on hardcoded `REGEXP_CONTAINS` patterns and complex `CASE` statements for categorizing email types and brands. This approach is brittle, difficult to maintain, and prone to errors as business rules evolve. The dashboard also includes metrics that sum rates, which is explicitly noted as misleading in their business descriptions, indicating potential data misinterpretation. The absence of `SQL Query Execution Summary` prevents validation against live data, making these observations based solely on the provided metric definitions.",89
c22e86d8-835d-4a68-8c10-5d131e225e6b,Verity 2.0 The Mercury: Sunrise Report (Click here to access the full report),high,"The analysis indicates a high potential for consolidation within this dashboard. Two out of three metrics are essentially the same base metric, 'Sum of C-Score Target', but with hardcoded date filters for specific weeks. This pattern leads to metric proliferation and reduced flexibility. Due to the absence of `sql_execution_summary` data, live performance or data validation could not be performed, which is a critical area for investigation.",90
09a871a0-d37a-4851-bafc-8d63d2dc81f8,Friday trading pack charts - Audience Insights - draft,high,"The dashboard's initial analysis indicates a high consolidation score (9), yet the detailed metric SQL reveals a significant anti-pattern: all six metrics are nearly identical copies, differing only in date range and website filters. This contradicts the high consolidation score and presents a critical opportunity for actual consolidation. The repeated, complex SQL logic for audience segments and content categories is hardcoded across all metrics, leading to high maintenance overhead and potential inconsistencies. The absence of live SQL execution data prevents validation of performance impacts but highlights an area for immediate investigation.",91
ee06d96e-a079-4304-ad4a-2c9a13d20ddf,Verity 2.0 Newsroom 2025: Accelerated Newsroom Performance,high,"The dashboard's initial consolidation score of '5' (highly consolidated) appears to be contradictory to the underlying metric definitions. Three out of four metrics are variations of the 'Total C-Score Target' that differ only by hardcoded date ranges, pointing to significant opportunities for consolidation through parameterization. The absence of live SQL execution data prevents validation of query performance or results, limiting the depth of analysis regarding data accuracy or runtime issues.",92
57957536-505f-4507-8062-c7cbe7c46ecf,Verity 2.0 Pulse Check - Monthly v2,high,"The dashboard's primary KPI, 'Net Digital Paid Subscriptions', is defined for a specific historical month (March 2025) but the live data execution summary indicates queries are running for a much more recent period (September 2025) and showing zero net adds, which is flagged as a failure. This highlights a critical mismatch between the metric's static definition and the dashboard's apparent dynamic data display, or a data quality issue for recent periods. Both metrics exhibit significant anti-patterns, relying heavily on hardcoded `CASE` statements for data mapping and fixed values in `WHERE` clauses, severely limiting their reusability and maintainability. This necessitates a high consolidation priority to introduce governed lookup tables and dynamic date parameters.",93
f04cf01a-a59d-4d08-a6a5-1f4a8a3540a9,Verity 2.0 Local,high,"The dashboard 'Verity 2.0 Local' contains two distinct metrics that are, in essence, the same base metric ('Total Daily Target by Section Team') but with different hardcoded date filters. This directly aligns with the dashboard's high consolidation score (8) from the initial AI analysis. The lack of SQL execution summary data prevents validation of query performance or actual data results, but the structural redundancy of the metrics is a clear indicator for consolidation. This pattern suggests a need for parameterization to reduce metric sprawl and improve dashboard flexibility.",94
bccf684d-1761-465f-9353-e26f5a499c26,Interim Adsales Performance Dashboard for FY26,high,"The dashboard, despite an initial high consolidation score, exhibits significant consolidation and coding practice issues. There are explicit duplicate metrics, logical flaws in several calculations leading to guaranteed zero results, and a pervasive anti-pattern of hardcoded `CASE` statements for relative time offsets. The lack of live SQL execution data prevents validation of performance or actual data outcomes, making these observations based purely on static SQL analysis. The identified issues suggest a need for immediate refactoring to improve data integrity, maintainability, and user trust.",95
ec783355-ff58-423e-a8df-83c75e9f77b3,Verity 2.0 Townsville Bulletin : Sunrise Report (Click here to access the full report),high,"The dashboard's initial consolidation score of 9 is strongly validated by the detailed metric analysis. All three defined metrics are functionally identical, differing only by hardcoded weekly date ranges in their SQL `WHERE` clauses. This represents a significant opportunity for consolidation into a single, parameterized metric, drastically improving maintainability and flexibility. The absence of any SQL query execution summary data prevents a comprehensive performance analysis or validation against live query results, which is a critical gap for understanding the dashboard's operational health.",96
28082293-c836-46f0-83f8-b5ce909cd051,SANDBOX VERSION - Commercial Finance Scorecards,high,"The dashboard, despite its high reported consolidation score, exhibits significant anti-patterns in its metric definitions, primarily due to widespread hardcoding of business logic (e.g., channel names, masthead mappings, scenario names, and specific fiscal years) directly within SQL queries. This approach makes the dashboard brittle, difficult to maintain, and prone to errors if underlying business rules or data structures change. The absence of live SQL execution data prevents validation of these metrics against actual performance or data consistency, but the observed patterns strongly indicate a need for a more robust, parameterized, and metadata-driven approach to metric definition. The dashboard appears to be hardcoded for FY26, which limits its reusability for other fiscal periods without manual SQL modifications.",97
db5d30dd-1fbd-4ddf-9ce5-21d28b662ce6,Verity 2.0 The National News Network Daily,high,"The dashboard 'Verity 2.0 The National News Network Daily' exhibits a high degree of hardcoding for dates, mastheads, and publication groups across all its metrics. While the initial AI analysis indicates a high consolidation score (8) and zero governance issues, the detailed metric analysis reveals significant anti-patterns related to hardcoded filters. This severely limits the reusability, flexibility, and maintainability of the metrics, contradicting the notion of high consolidation in practice. The absence of SQL execution summary data prevents validation against live performance or results, highlighting a critical area for investigation.",98
4db22271-c915-4a3b-95f1-57f52f6beaf1,Verity 2.0 Weekly performance report: TABN,high,"The dashboard 'Verity 2.0 Weekly performance report: TABN' exhibits a significant anti-pattern despite its initial high consolidation score (8). Multiple distinct metrics are defined for the same underlying business concept (e.g., 'Total C-Score Target'), with the only differentiation being hardcoded date ranges within their SQL logic. This leads to redundancy, increased maintenance burden, and poor reusability. The absence of live SQL execution data prevents validation of query performance, actual data results, or potential issues arising from the `PARSE_DATE` and `SAFE_CAST` operations in one of the metrics.",99
435b3177-8c9b-458c-9225-9c49bdbb9c98,Exit link from Datalocal auction-sales stories,medium,"The dashboard exhibits strong internal consolidation, with all three metrics deriving from a common base metric (`exit_link_clicks`) and utilizing the same underlying table (`ncau_exit_links`). Two of the three metrics share identical filtering logic (`STRPOS(t0.exit_link, 'datalocal') > 0 AND t0.source_code = 'Adobe WEB'`), demonstrating good reuse and a high consolidation score as indicated by the initial AI analysis. However, the absence of `sql_execution_summary` data prevents any validation of these metrics against live query results, making it impossible to confirm data accuracy, performance, or identify potential discrepancies between defined logic and actual execution. This lack of live data is the primary impediment to a comprehensive analysis.",100
a00f4341-2de3-4d89-8f85-cca805fb10d7,NewsQuery Cost Operation Dashboard-20241105,high,"The 'NewsQuery Cost Operation Dashboard-20241105' is designed to monitor BigQuery operational costs and usage. A primary observation is the presence of two distinct 'Total Cost' metrics (1.4x and 1.5x multipliers) which are nearly identical in their SQL logic, differing only by a hardcoded multiplier and a slightly varied notation for TB conversion. This indicates a significant opportunity for consolidation and parameterization. The base cost per terabyte (6.25) is also hardcoded across multiple cost-related metrics. Without the `sql_execution_summary` data, direct validation of live query performance or output accuracy is not possible, making the absence of this data a critical investigation point.",101
7ffe7054-679e-4e8f-bb3d-01c6e7799899,Engagement data - Audience Insights M&R + TA,high,"The dashboard, 'Engagement data - Audience Insights M&R + TA', exhibits significant opportunities for consolidation and refactoring. A critical finding is the presence of a hardcoded date in a key metric, rendering it static and unusable for dynamic analysis. Furthermore, both metrics heavily rely on complex, hardcoded `CASE` statements for classification and filtering, which is a major anti-pattern indicating a strong need for lookup tables or more robust data modeling. The absence of `sql_execution_summary` data prevents direct validation against live query performance or data mismatches, highlighting a crucial area for investigation into data observability.",102
5fa24f44-3883-4580-8930-bc4ca0bb7430,Verity 2.0 Business Network : Sunrise Report (Click here to access the full report),high,"The dashboard's initial consolidation score of 9 is misleading when examining the detailed metric definitions. While both metrics share a common base metric ID ('total_day_target') and data source, their SQL logic is heavily hardcoded with specific dates (May 2025, July/Aug 2025) and publication groups ('The Australian Business Network'). This anti-pattern indicates a lack of parameterization, leading to a proliferation of highly specific metrics rather than reusable, dynamic ones. The absence of live SQL execution data prevents validation of these metrics, but the hardcoded nature itself poses a significant maintenance and scalability challenge, warranting a high consolidation priority for refactoring.",103
5e8c40fc-c6c2-4e1c-a44b-b779ab9a72f9,Run of Dashboard,high,"The dashboard's metrics, while distinct in their business context (e.g., specific years, publications, or advertiser types), are all derived from the same base table (`v_adsales_revenue_client`) and share a significant amount of common filtering logic. The absence of live SQL execution data prevents validation of these metrics against actual query performance or data consistency, but the static SQL definitions reveal substantial opportunities for consolidation through a shared semantic layer or base views. The current implementation relies heavily on hardcoded values, which impacts maintainability and reusability.",104
3516a531-3188-4e5d-b49c-3150298ebdc7,Verity 2.0 Advertiser: Sunrise Report (Click here to access the full report),high,"The dashboard's single, high-criticality metric, 'Sum of C-Score Target by Publication Group', contains a significant discrepancy: its SQL logic includes hardcoded date filters (2025-05-26 to 2025-06-01), directly contradicting the business description which states the date range is dynamically applied by dashboard controls. This fundamental flaw renders the metric inaccurate for any period outside this specific week and undermines the dashboard's utility. The absence of live SQL execution data prevents validation of the metric's actual performance or data output, making it impossible to confirm if the dashboard is currently displaying any data or if it's consistently showing data only for that hardcoded week.",105
c03dec50-b74e-40c6-a5c8-50fad5ea3f0f,Gen Ai: article summaries,high,"The 'Gen Ai: article summaries' dashboard, despite an initial assessment of '0' governance issues, exhibits significant anti-patterns in its underlying SQL logic. A core 'AI-assisted' article definition, including specific publication groups and date ranges, is hardcoded and duplicated across 12 out of 13 metrics and dimensions. This extensive repetition creates a high maintenance burden and introduces a substantial risk of inconsistency if business rules change. Furthermore, an unnecessary 'image' CTE and join are included in aggregate metrics, adding overhead. The absence of SQL execution summary data prevents validation of query performance or actual results, but the identified code patterns strongly indicate a need for immediate refactoring to improve maintainability and data governance.",106
39e47abe-f145-4ba6-9562-03fc4d6512d4,Verity 2.0 Daily Telegraph: Sunrise Report (Click here to access the full report),high,"The dashboard, despite its 'Daily' and 'Weekly' naming conventions, relies heavily on hardcoded dates within all three metrics, rendering it static and requiring manual updates for each reporting period. The initial AI analysis incorrectly reported zero governance issues, as the detailed SQL reveals significant anti-patterns, including duplicated, hardcoded exclusion lists across multiple metrics and complex, embedded business logic for article scoring. The absence of SQL execution data prevents any validation of query performance, success, or actual data output, which is a critical gap for a production dashboard.",107
736e39be-8b74-442d-bf5a-0b75971e3de0,Verity At-A-Glance: TAUS,high,"The 'Verity At-A-Glance: TAUS' dashboard, despite an initial high consolidation score (8), exhibits significant anti-patterns due to pervasive hardcoded values within its metric definitions. All key metrics are hardcoded to specific future dates and categorical filters (masthead, customer type, scenario), rendering the dashboard static and unsuitable for dynamic, ongoing analysis without manual updates. The absence of `sql_execution_summary` data prevents validation against live query performance or results, but the SQL logic itself indicates a critical need for refactoring to introduce dynamic date parameters and flexible categorical filtering. The current implementation suggests a 'snapshot' dashboard rather than an 'at-a-glance' tool for evolving data.",108
33b41b56-aab7-4a76-bb96-0c891b4b0a1f,Verity 2.0 Education: Sunrise Report,medium,"The dashboard exhibits a strong foundation for consolidation, with both metrics deriving from the same base metric ('total_day_target') and the same underlying table (`cdm_reference_data.subscription_targets`). This aligns with the high consolidation score (7) from the initial AI analysis. The primary distinction between the two metrics lies in the specific filtering applied to `publication_group`. However, the absence of live SQL execution data (`sql_execution_summary` is empty) prevents any validation of the SQL logic against actual performance or results, making it impossible to confirm data integrity or identify runtime issues. The current SQL definitions reveal several hardcoded values that could impact maintainability and scalability if not managed dynamically within the Looker Studio environment.",109
50fdfb08-6d82-4d1d-a41d-de3284ec00b7,Present: FY25 - 5.15 Verity,high,"The dashboard 'Present: FY25 - 5.15 Verity' exhibits a high degree of hardcoded business logic within its metric definitions, particularly for filtering criteria related to mastheads, customer types, and especially newsletter activities. While the SQL logic directly implements the stated business descriptions, the extensive use of hardcoded values and complex `REGEXP_CONTAINS` clauses across multiple metrics creates a significant maintenance burden and severely limits reusability and flexibility. The absence of live SQL execution data prevents validation of performance or actual results, but the static SQL itself highlights a critical need for refactoring towards more dynamic, parameterized, and centralized data definitions to improve governance and reduce complexity.",110
5705039f-1f6f-4c93-aba9-8ce549025d5c,SVOC - SIT QVR data sets - Exploration,high,"The analysis of the 'SVOC - SIT QVR data sets - Exploration' dashboard reveals significant opportunities for consolidation and improvement in coding practices. A critical observation is the absence of live SQL execution data, which prevents direct validation of metric performance or data accuracy. However, the detailed metric definitions expose two major anti-patterns: the repeated implementation of a complex `CASE` statement for subscriber movement classification across multiple metrics, and the pervasive use of hardcoded date ranges. These issues indicate poor maintainability, limited reusability, and contradict the initial AI assessment of '0 governance issues', necessitating a high consolidation priority.",111
d5fd8b83-22d8-478f-8e22-b9e83bda01f2,Percentage of article read,high,"The dashboard 'Percentage of article read' exhibits significant opportunities for consolidation and refactoring due to prevalent hardcoded values and duplicated logic within its metric definitions. A critical observation is the complete absence of live SQL execution data, which prevents any validation of the defined metrics against actual runtime performance or results. This lack of execution data elevates the consolidation priority, as the current analysis relies solely on static SQL definitions, which reveal several anti-patterns. Specifically, metrics are hardcoded for specific content IDs, future date ranges, and a single publication group ('The Australian'), severely limiting the dashboard's dynamic utility and reusability. The reported '0 governance issues' in the initial summary is misleading given these identified coding anti-patterns.",112
63911575-4b9d-45c4-830c-8726e98adb93,Verity 2.0 Weekly performance report: CODE + NSN,high,"The 'Verity 2.0 Weekly performance report' dashboard, despite its moderate complexity and consolidation score, exhibits significant anti-patterns related to hardcoded date ranges and specific business dimensions across all its metrics. This practice severely limits its reusability, maintainability, and scalability, requiring manual updates for each reporting period or change in business scope. The absence of SQL execution summary data prevents validation of the queries against live results, necessitating further investigation into data accessibility or query execution logs.",113
f81b655d-53a4-47f8-a195-c230b57dd77c,Google Search Console,high,"The dashboard's metrics are currently configured with hardcoded future date ranges, rendering them non-functional for current data. While the initial analysis indicates a high consolidation score (8), the underlying SQL reveals a significant anti-pattern: common business logic (e.g., brand categorization) is implemented via repeated, extensive hardcoded `CASE` statements rather than leveraging shared, governed dimensions or lookup tables. This makes the dashboard brittle, difficult to maintain, and prone to inconsistencies if the business logic changes. The absence of SQL execution summary data prevents validation of live performance or error states, but the static SQL itself indicates critical issues.",114
811bb139-3da6-4fa5-8ddc-4b9f263cb1d5,Beyond Words | Production Dashboard - Beta,high,"The dashboard 'Beyond Words | Production Dashboard - Beta' exhibits a high degree of data source consolidation, as all metrics draw from the same `article_voice_engagement_metrics` table. However, a critical anti-pattern observed is the pervasive use of hardcoded and overlapping date ranges across nearly all metrics. This severely limits the dashboard's flexibility, requires manual updates for each reporting period, and indicates a lack of dynamic date filtering implementation. Furthermore, a complex, hardcoded `CASE` statement for categorizing publication groups introduces maintenance overhead and brittleness. The absence of any SQL execution summary data prevents validation of query performance, data volume, or actual results, making it impossible to confirm the dashboard's operational health or data consistency.",115
d381c80a-e345-4120-8950-e85e976e50b6,Verity 2.0 - Prod - PRSTN - Social Summary,high,"While the dashboard initially received a high consolidation score, a deeper analysis comparing metric definitions with live query results reveals significant discrepancies and anti-patterns. Specifically, the hardcoded `CASE` statement for 'Social Platform' is incomplete, leading to 'Other/Unknown' categories where 'Tiktok' is expected. Furthermore, the 'Post Media Type Name' dimension shows inconsistencies between its business description and observed live data values, indicating potential data quality or definition issues. These findings suggest that core categorization logic is not fully aligned with the underlying data, necessitating immediate attention to ensure data accuracy and reliability for this 'Social Summary' dashboard.",116
fb7ea77f-c0b0-490a-9cb2-eb49816cf8fa,ARM,high,"The dashboard 'ARM' exhibits a foundational level of consolidation by utilizing a single underlying view (`v_subscription_base_movement_agg`) for all its metrics. However, this consolidation is significantly undermined by pervasive hardcoded filters for fiscal year, brand, and classification levels within the SQL logic of all metrics. Furthermore, an inconsistency in filtering by `fy_week_of_year` between the 'Q3' metrics and the 'Sunday Subscription Count' introduces potential data discrepancies. The absence of live SQL execution data prevents validation of query performance or actual data results, highlighting a critical gap in observability.",117
21263991-9738-454a-977b-1158587a1525,Circ Snapshot Load Precheck,high,"The 'Circ Snapshot Load Precheck' dashboard is a critical operational tool, as evidenced by its high business criticality and all metrics being KPIs. Its primary function is to monitor data load status and freshness across various circulation and finance-related tables. However, the analysis is significantly limited by the absence of live SQL execution data, which prevents validation of the reported metric logic against actual query performance or results. The detailed metric definitions reveal a pervasive anti-pattern: highly repetitive and hardcoded SQL queries for each table's freshness check, often with varying and inconsistently applied freshness criteria. This approach indicates a lack of a centralized, templated, or metadata-driven data quality monitoring framework, leading to significant maintenance overhead, potential for inconsistencies, and reduced scalability. Consolidating these metrics into a more generic, configurable solution is a high priority to improve reliability and reduce technical debt.",118
43bb6e05-d417-49e0-870f-e51fa1b31b59,Verity 2.0 - Prod - PRSTN - Content Registration Summary,high,"The dashboard, 'Verity 2.0 - Prod - PRSTN - Content Registration Summary', exhibits significant issues that warrant high consolidation priority despite its initial high consolidation score. All three core metrics are configured with hardcoded `SubscriptionDateTime` filters set to future dates (e.g., 2025), which will prevent the dashboard from displaying any current or historical data. Furthermore, a critical anti-pattern is observed where the `CASE` statement logic for deriving 'social referrer' is duplicated across two different metrics, indicating a lack of centralized logic. The absence of `sql_execution_summary` data prevents validation of query performance or actual data output, but the hardcoded future dates strongly suggest the dashboard is currently non-functional.",119
8a7be976-10d2-4657-aa8a-8bcbcb4c4cd7,News.com.au - Best Of & Checkout - Daily Update,high,"The dashboard 'News.com.au - Best Of & Checkout - Daily Update' is critically impacted by fundamental data retrieval issues. All listed metrics show a 'response_id: 404', indicating a complete failure to execute queries or retrieve data. Furthermore, despite being a 'Daily Update' dashboard, all metric SQL queries contain hardcoded future dates, and these dates are inconsistent across different metrics (e.g., '2025-08-26' vs. '2025-07-01'). This renders the dashboard non-functional for its stated purpose and requires immediate attention. The initial AI analysis's 'total_governance_issues: 0' is contradicted by these findings.",120
eb8b311c-ae29-4773-b749-b429715b073d,Verity 2.0 Sport Newsroom : Sunrise Report (Click here to access the full report),high,"The initial AI analysis reported a high consolidation score (9), likely due to both metrics sharing a common `base_metric_id`. However, a deeper dive reveals a significant anti-pattern: the dashboard utilizes two distinct metrics that are nearly identical, differing only by hardcoded date ranges in their SQL logic. This indicates poor dashboard-level consolidation and parameterization, leading to duplicated code, increased maintenance burden, and reduced flexibility. The absence of SQL execution summary data prevents validation of live performance or data integrity, highlighting a critical gap in observability.",121
3c4b6517-cd6a-4138-bd32-09644e44c44a,HS morning report,low,"The 'HS morning report' dashboard appears to be well-structured with a high consolidation score (7) and moderate complexity (6). All four high-criticality KPIs leverage a limited set of data sources, with three out of four metrics sharing the same underlying view (`v_consumer_activity_daily_summary`) and identical filtering logic. This indicates good internal consistency and a degree of data consolidation. However, the absence of `sql_execution_summary` data prevents any live validation of metric performance, data volume, or actual query results, which is a significant gap for a comprehensive analysis. The primary area for improvement identified is the repeated hardcoded filtering logic across multiple metrics, which, while consistent, could impact future flexibility and maintenance.",122
a5ab7569-238a-4229-a402-868a12d75088,Client Heath - Check ,high,"The 'Client Heath - Check' dashboard, while having a moderate consolidation score, exhibits significant anti-patterns in its SQL logic. A critical observation is the complete absence of `sql_execution_summary` data, preventing live data validation and performance analysis. However, a deep dive into the `sql_logic` for all four metrics reveals extensive duplication of complex `CASE` statements and hardcoded lookup tables (via `UNION ALL` CTEs). This design choice severely impacts maintainability, introduces a high risk of inconsistencies, and makes future modifications or extensions cumbersome. The current structure suggests a strong need for refactoring to leverage proper metadata tables and potentially modularized SQL views or functions to improve data governance and reduce technical debt.",123
6dfeb6d8-8d5e-4118-ae57-9597289a7e53,Verity 2.0 Usage,medium,"The 'Verity 2.0 Usage' dashboard exhibits a strong foundation for data consolidation, particularly through its reliance on a dedicated `verity2_user_test` reference table for user and team information. This centralizes key dimensions like AD User Name, Role, Author Team, and Masthead, aligning with the reported high consolidation score (8). The metrics are well-defined and leverage standard BigQuery functions for GA4 data (e.g., UNNEST for event parameters, REGEXP_CONTAINS for event name filtering, DATETIME_TRUNC for date aggregation). However, the absence of live SQL query execution data prevents a comprehensive validation of actual performance, data volume, and potential runtime issues, making it difficult to fully assess operational consolidation and efficiency.",124
a4ae6326-c6de-4270-babd-bd87207b0af1,The Australian x H24,high,"The dashboard 'The Australian x H24' is rated with a high consolidation score (8) in the initial AI analysis, suggesting good metric reuse. However, a deeper dive into the detailed metric SQL logic reveals significant anti-patterns related to hardcoded values and repeated filtering logic across multiple metrics. Specifically, exclusion lists for `subscriber_id_src` and complex `REGEXP_CONTAINS` patterns for `sold_in_source_code` are duplicated. This indicates a need for a higher level of data governance and abstraction to truly achieve consolidation and maintainability. The absence of SQL execution summary data prevents validation of query performance or actual data outcomes, marking a critical area for investigation.",125
a0a0af46-f41f-4236-b6d1-6de8e92e6e23,Quick CVM cohort sizing - ,high,"The dashboard 'Quick CVM cohort sizing -' exhibits a high complexity and consolidation score (both 9), indicating a significant opportunity for optimization. A primary observation is the pervasive use of hardcoded `CASE` statements and `REGEXP_CONTAINS` logic within the SQL definitions for critical business dimensions (Payment Type, Delivery Schedule Type, Subscriber Activity Level, Subscription Tenure Group, and Contract Type). This approach, while functional, introduces significant maintenance overhead, potential for data inconsistencies, and makes future modifications challenging. Crucially, the absence of `sql_execution_summary` data prevents validation of these hardcoded rules against live data, meaning we cannot confirm if all relevant categories are captured or if there are data mismatches. The reported '0 governance issues' should be viewed with caution given the lack of execution data.",126
4114bd43-f752-4628-9b6c-1941b3c0d962,FY26 Campaigns Report (Sandbox),high,"The dashboard, despite being named 'FY26 Campaigns Report (Sandbox)', is fundamentally misaligned as its core metrics and filters are hardcoded to financial years 2024 and 2025. This represents a critical functional error. Furthermore, a pervasive and highly problematic 'LIMIT 1' clause is present in the SQL logic for *all* metrics and filters, which would prevent them from returning complete or correct data (e.g., only one distinct value for filters, or only one row's sum for a measure). The extensive use of long, hardcoded 'NOT IN' lists for exclusions across multiple metrics indicates significant anti-patterns, hindering maintainability and data governance, directly contradicting the initial AI's '0 governance issues' and 'high consolidation' scores. The absence of SQL execution summary data prevents validation against live results, but the identified SQL logic issues are severe enough to warrant immediate attention.",127
9e810f08-0171-451e-a406-6bf7076c4d2f,Verity 2.0 - TAUS Wealth Daily Update,medium,"The dashboard exhibits a high consolidation score (8), effectively grouping metrics into two primary business domains: article/registration data and subscription targets, each leveraging a dedicated core table. However, a critical observation is the pervasive use of hardcoded date ranges across all metrics. Despite the `sql_execution_summary` indicating recent data availability (up to 2025-09-04) in the underlying tables, the dashboard's metrics are querying specific, older, hardcoded dates (e.g., 2025-08-03, 2025-07-01). This fundamental discrepancy means the dashboard, despite its 'Daily Update' name, is not displaying current data, necessitating manual SQL updates for freshness. Further optimization opportunities exist in refining subquery column selections and standardizing date handling.",128
4fc017fc-f405-453a-83c5-027155103330,DRAFT - Test audience size - NBO_subscriber table,high,"The dashboard, currently in 'DRAFT' status, exhibits a high degree of data source consolidation, relying solely on the `subscriber_lcdp` table. However, the analysis of individual metric SQL logic reveals significant anti-patterns, particularly the pervasive use of hardcoded future dates (e.g., 2025-05-06, 2025-05-18) and a hardcoded contact ID. This renders the dashboard static and unusable for current or dynamic analysis, directly contradicting the initial AI's high consolidation score which likely refers to data source usage rather than query logic efficiency or dynamism. The absence of SQL execution summary data prevents validation against live performance or results, highlighting a critical gap in observability.",129
a8f4530d-2788-4494-9ad2-73660bcd7c36,Audience Insights - Funnel Performance ,medium,"The dashboard exhibits a strong foundation for consolidation, with all three metrics deriving from the same base table (`subscriber_base_agg`) and sharing a common `base_metric_id` ('total_subscribers'). This structural consistency aligns with the high initial consolidation score. However, a critical inconsistency in filtering logic for 'Total Subscribers by Masthead' compared to the other two metrics introduces potential data discrepancies. Furthermore, the 'Total Subscribers by Audience Segment' metric relies on a hardcoded CASE statement for categorization, which is an anti-pattern. The absence of live SQL execution data prevents validation of these observations against actual query performance or results, necessitating further investigation.",130
c3fc480a-3d9d-4ea9-96f3-4eab5ec79637,Copy of Consumer-UD - Core Subscription Health Check ,high,"The dashboard aims to provide a consolidated view of data freshness across various critical datasets (Medallia, Audience Insights, prstn_consumer, and general CDM/SDM sources). While the *intent* is high consolidation (reflected in the AI's consolidation score of 9), the *implementation* heavily relies on extensive hardcoded lists and duplicated complex SQL logic. This approach severely undermines true consolidation, creating a significant maintenance burden, increasing the risk of data inconsistencies, and making the dashboard fragile to changes in underlying data sources or monitoring requirements. The absence of live SQL execution data prevents validation of these assumptions and observation of real-world performance impacts.",131
f60ad8ef-829d-4363-b705-c60a305ec777,Verity 2.0 Herald Sun : PM Conference (Click here to access the full report),high,"The dashboard, focused on a single high-criticality KPI ('Total C-Score Target by Publication Group'), is currently rendered ineffective due to a critical anti-pattern: its underlying SQL query contains a hardcoded date range set in the future (June 9-15, 2025). This prevents the dashboard from displaying current or relevant data, making it static and unusable for its intended purpose of performance monitoring. Furthermore, the absence of any SQL execution summary data means there's no live validation of the query's performance or actual results, necessitating further investigation into its operational status.",132
9b27e204-fd9a-4032-8669-58b6f23bfef,Verity 2.0 Cairns Post : Sunrise Report (Click here to access the full report),high,"The initial AI analysis reported a high consolidation score (9), but a detailed review of the metrics reveals a significant anti-pattern. All three metrics are essentially the same 'C-Score Target' measure, differentiated only by hardcoded weekly date ranges in their SQL logic. This indicates poor consolidation practices, leading to redundant metric definitions and high maintenance overhead. The dashboard's reported low complexity score (2) is misleading, as this design choice introduces unnecessary complexity in metric management. Furthermore, the absence of SQL execution summary data prevents validation of query performance or actual data retrieval.",133
567db886-3b54-47d1-bfe5-b972c2cc0449,Adsales Performance Dashboard - FY25 PDFs Final,high,"The dashboard, despite its high initial consolidation score, exhibits significant opportunities for further data model consolidation and SQL logic refactoring. A pervasive anti-pattern is the repetition of `CASE WHEN` statements for filtering by fiscal year offsets and the redundant creation of 'k' (thousands) metrics via `SAFE_DIVIDE(..., 1000)`. The most critical finding is the presence of a highly complex, hardcoded metric (`gross_revenue_complex_conditions_sum`) that embeds intricate business logic directly into the SQL, indicating a lack of standardized definitions and a potential governance risk. The absence of `sql_execution_summary` prevents validation against live query performance or results, necessitating further investigation into data observability.",134
5e3be025-a96e-4f5d-8172-dfef07e60f6d,Commercial Finance Scorecards (Forecast Version),high,"The 'Commercial Finance Scorecards (Forecast Version)' dashboard, despite its high complexity (score 9) and consolidation potential (score 8), exhibits significant anti-patterns in its metric definitions. All 59 metrics query the same underlying table, but each metric's SQL logic independently hardcodes the fiscal year (2025) and redundantly executes a subquery to determine the current fiscal week. Additionally, budget metrics are hardcoded to a specific 'CM' masthead. These issues severely impact maintainability, flexibility, and query efficiency. The absence of SQL execution summaries prevents live data validation, but the structural inefficiencies are evident and warrant immediate attention for optimization and parameterization.",135
e642b3f9-9711-44c8-b2d8-959ded9f5b0d,OFFICIAL EDIT - Audience Insights - Adds & Cancels Performance ,high,"The analysis of the detailed metric definitions reveals a critical and systemic issue: almost all metrics, including key performance indicators (KPIs) and dimensions, contain a `LIMIT 1` clause in their SQL logic. This fundamentally breaks the intended functionality of a dashboard, preventing proper aggregation, full data display, and dynamic filtering. For instance, the 'Total Subscription Movement Count (Cancels, Filtered)' KPI, despite its name, will only ever return a sum based on a single row, or a single row's value, rather than an aggregated total across the dataset. Similarly, dimensions will only ever show one example value. Furthermore, this KPI is heavily hardcoded with specific dates and categorical values, severely limiting its reusability and general applicability. The 'Audience Segment (Adds)' metric also relies on an extensive hardcoded CASE statement, indicating a need for a more robust, maintainable lookup structure. The absence of live SQL execution data prevents validation of these observations against actual query performance or results, but the SQL logic itself points to severe functional limitations.",136
246977b9-22df-4780-b0ad-f575607cd32d,Health today,high,"The primary observation is the absence of live SQL query execution data, which critically prevents validation of the dashboard's metrics against real-world performance and resource consumption. This lack of data elevates the investigation priority. However, based on the detailed metric definitions, all metrics and dimensions (Total Daily Subscription Target by Section Team, Target Date, Section Team, Daily Target by Publication Group, Website, Week) consistently originate from a single BigQuery table (`ncau-data-newsquery-prd.cdm_reference_data.subscription_targets`). This indicates a strong level of data source consolidation at the logical layer, aligning with the initial AI analysis's 'consolidation_score' of 7. The dashboard's specific filters (e.g., 'Health' for Section Team, excluding 'The Australian' for Website), as noted in the initial analysis, appear to be applied at the dashboard or chart level rather than being hardcoded into the metric SQL, which is a good practice for metric reusability and maintainability.",137
bb705701-76b0-40eb-bc6f-0159956fda7a,Verity 2.0 NT News : Sunrise Report (Click here to access the full report),high,"The 'Verity 2.0 NT News : Sunrise Report' dashboard is highly focused, containing only one critical metric: 'Total C-Score Target by Publication Group'. While the initial analysis indicates a high consolidation score (9) and low complexity (2), a critical anti-pattern was identified in the metric's SQL logic: a hardcoded date range. This renders the dashboard static and effectively obsolete for ongoing 'Sunrise Report' purposes, requiring immediate attention. Furthermore, the absence of any SQL execution summary data prevents validation of the query's performance or actual data output, highlighting a significant gap in observability.",138
c16a956e-a495-4678-bc4d-cb7009ab8899,Puzzles Engagement,low,"The 'Puzzles Engagement' dashboard exhibits excellent consolidation, with all six metrics deriving from a single source table (`puzzles_engagement_data`) and consistently applying `SUM()` aggregations on either `subscriber_count` or `page_view_count` across various dimensions. This aligns perfectly with its high consolidation score (6) and indicates a well-structured data model. The SQL queries are simple and direct, reflecting a low complexity in data retrieval logic. However, the absence of `sql_execution_summary` data prevents any validation of these metrics against live query performance or actual data values, limiting the depth of this analysis to structural observations only.",139
73153654-dd99-4f67-839d-a986a52ca1e2,Monthly Executive Summary 2.0,high,"The dashboard, 'Monthly Executive Summary 2.0', is reported with a high consolidation score (8) by the initial AI analysis. However, a deeper dive into the detailed metric SQL reveals significant anti-patterns, including hardcoded date ranges and repeated, hardcoded filter criteria across multiple metrics. This contradicts the high consolidation score and indicates a high maintenance burden, potential for outdated data, and a lack of true reusability in the underlying logic. The absence of SQL execution summary data prevents validation of live query performance or results, highlighting a critical gap in observability.",140
53ec39c2-f93b-4025-a7cb-4c06d3cefa6e,Brands Review Dashboard,high,"The 'Brands Review Dashboard' exhibits significant opportunities for consolidation and refactoring. Key dimensions like 'Ad Type Group' and 'Site Name' are defined using extensive, hardcoded CASE statements directly within metric SQL, leading to poor maintainability. This issue is compounded by critical revenue metrics (`revenue_fy2026_digital_taste_q123`, `revenue_fy2024_digital_taste_q123`) that duplicate these complex CASE statements, resulting in massive code redundancy. The 'Same Time Last Year Revenue' metric also contains intricate, nested business logic. The absence of SQL execution summaries prevents validation against live performance data, but the structural issues alone indicate a high priority for refactoring to improve governance, consistency, and maintainability.",141
3ee20092-1897-49b7-8bcd-4157d5f816eb,AdSales Data for Pacing Report ,high,"The 'AdSales Data for Pacing Report' dashboard, while focused on a critical business domain (advertising revenue), exhibits significant anti-patterns in its metric definitions. The primary 'Gross Revenue' metric, along with other key dimensions, relies heavily on extensive hardcoded exclusion lists for publications and specific financial years/weeks. This approach severely impacts maintainability, scalability, and data governance. Furthermore, the presence of an 'unusual aggregation' like 'Sum of Financial Week' suggests potential misinterpretation of data usage or a Looker Studio artifact that needs investigation. The absence of live SQL execution data prevents validation of these metrics against actual query performance or results, highlighting a critical gap in the analysis.",142
d828e66e-2476-4e31-91af-3a202a45f99d,Historic Closing Base and Revenue,high,"The dashboard 'Historic Closing Base and Revenue' demonstrates a consistent data source (`v_subscription_base_movement_agg`) across all its metrics and dimensions, which is a positive sign for data consolidation. However, the absence of `sql_execution_summary` data prevents validation of the SQL logic against live results, necessitating manual verification. A critical area for improvement is the pervasive use of complex, hardcoded `CASE` statements for defining key business dimensions (`Product Group`, `Masthead Group`). This anti-pattern significantly increases maintenance burden, introduces brittleness, and hinders scalability. Furthermore, an unnecessary `LEFT JOIN` is present in all measure calculations, indicating potential for query optimization. The hardcoded fiscal year range across all queries also points to a lack of dynamic filtering.",143
dd0544cd-634f-43bd-a385-158c78dace66,Product Revenue Tracking Report,high,"The dashboard's core filtering logic, based on 'Publication Group', is consistently applied across multiple dimensions as described in the initial AI analysis. However, this logic is implemented via a highly repetitive and hardcoded CASE statement directly embedded in the SQL of six different metrics. This anti-pattern significantly impacts maintainability, scalability, and data governance, contradicting the initial AI assessment of '0 governance issues'. The absence of SQL execution data prevents validation of performance implications but highlights a critical area for architectural improvement.",144
73aa273f-1632-484a-b0eb-c1132725d861,Verity 2.0 Daily Snapshot,low,"The 'Verity 2.0 Daily Snapshot' dashboard, with a high initial consolidation score of 8, appears well-structured with two high-criticality KPI metrics sourced from dedicated target tables. However, a critical observation is the complete absence of SQL query execution summary data. This prevents any validation of the dashboard's live performance, data accuracy, or the actual consolidation effectiveness. While the dashboard's design suggests good consolidation, its operational health and data integrity cannot be confirmed without live execution insights. The primary focus should shift from further consolidation to validating the existing setup.",145
9edf8948-86f2-40ac-9bce-1cd4a7289c8a,Sky News Dashboard (Paywall),medium,"The 'Sky News Dashboard (Paywall)' demonstrates excellent structural consolidation, with all five defined metrics sourcing data from a single BigQuery table (`ncau-data-newsquery-sit.qvr_consumer.skynews_closing_base_fct`) and applying a consistent date filter (`@DS_END_DATE`). This indicates a well-designed and centralized data model for the dashboard's core metrics. However, the complete absence of SQL query execution summaries prevents a comprehensive validation of these metrics against live performance, data integrity, or actual query results, thereby limiting the ability to identify runtime issues, data mismatches, or performance bottlenecks. This lack of execution data elevates the priority for investigating the data collection process itself.",146
1b29c0eb-ab01-4e6f-b3f6-8161f5d3c669,Verity sdm salesforce subscrip - WEB_ONL100 FY24,high,"The dashboard's initial AI-generated consolidation score of 7 appears misleading when analyzing the underlying SQL. While all three metrics use the same base table, their SQL logic is highly duplicated, differing primarily by hardcoded date ranges and specific content filters. This indicates a significant opportunity for consolidation and refactoring. The absence of SQL execution summary data prevents validation of query performance or identification of runtime issues, making it a critical area for investigation.",147
4473a333-74f4-463b-81e7-151f93013906,Verity 2.0 Weekly performance report: HS & SHS,high,"The dashboard's initial AI analysis reports a high consolidation score (8) and zero governance issues. However, a detailed review of the underlying SQL for all 5 metrics reveals significant anti-patterns related to hardcoded dates, date ranges, and specific publication/website names ('Herald Sun'). This directly contradicts the reported consolidation score and indicates a high potential for maintenance burden and limited reusability. The dashboard's name 'Weekly performance report' further highlights the need for dynamic date filtering, which is currently absent. Crucially, the absence of any SQL query execution summary prevents validation of performance or actual data output, leaving a critical blind spot in the analysis.",148
f502f44a-e283-405f-ab8f-6a641edb4194,FY25 Campaigns Report,high,"The initial AI analysis indicated a high consolidation score (8), but a detailed review of the metric SQL logic reveals significant anti-patterns and opportunities for consolidation. Specifically, there is extensive hardcoding of financial years and long 'NOT IN' clauses for filtering, leading to duplicated logic across multiple metrics. This contradicts the initial consolidation assessment and suggests a high priority for refactoring. The absence of SQL execution summary data prevents validation of live performance or data consistency, marking a critical area for investigation.",149
f9b52275-5924-4afb-8222-2c55854183ba,Finance Health - Check,high,"The analysis of the 'Finance Health - Check' dashboard was severely hampered by persistent '403 Access Denied' errors when attempting to execute the underlying SQL queries against the `your-gcp-project-id.bdm_finance.__TABLES__` metadata table. This critical issue prevented any live data validation of the dashboard's metrics. Despite the inability to validate live data, a review of the provided SQL logic for the three metrics reveals significant anti-patterns, including extensive hardcoding of table lists and filter values, and substantial duplication of complex logic across multiple metrics. These issues indicate a high need for consolidation and refactoring to improve maintainability, flexibility, and data governance.",150
5506c033-2f12-4464-b45b-4a12b7849ed6,CP-RoyMorgan_Data,medium,"The primary finding is the complete absence of SQL query execution data, which prevents any validation of the dashboard's metrics against live results. While the initial analysis indicates no governance issues and a moderate consolidation score, the lack of execution data means these assessments cannot be confirmed or further elaborated upon. All metrics appear to source from a single table (`adsales_revenue_pricing`), which is a positive indicator for data consolidation at the source level, but operational validation is currently impossible.",151
6196cc2e-ba25-4e80-8d4e-29602d889639,App Adoption Accelerator,high,"The 'App Adoption Accelerator' dashboard, despite its medium complexity (7) and consolidation score (5), exhibits critical underlying SQL anti-patterns that severely limit its utility and data accuracy. The most pervasive issue is the widespread use of `LIMIT 1` in nearly all metric and dimension SQL definitions, which fundamentally prevents proper aggregation and display of comprehensive data. Additionally, key measures rely on hardcoded dates, rendering the dashboard static and non-dynamic. The extensive `CASE` statement for 'Masthead Category' also indicates a lack of proper data modeling or lookup table utilization. The absence of `sql_execution_summary` prevents live validation, but the identified SQL patterns strongly suggest that the dashboard is not functioning as intended for dynamic, aggregated analysis.",152
9ecab5db-180b-480c-a819-d10e5b8d263e,Requests from Gad,high,"The dashboard's initial AI-generated consolidation score of 9 (high) is directly contradicted by the detailed metric analysis. All five metrics are variations of 'SPV Target', differing only by hardcoded date ranges in their SQL queries. This represents a significant anti-pattern, indicating poor metric consolidation and a high potential for maintenance overhead. The absence of live SQL execution data prevents validation of query performance or actual data results, limiting the depth of this analysis to static code review.",153
1f63540f-8268-4e9f-83a3-3acf63da5da5,Travel monthly snapshot - IPSOS,high,"The dashboard's initial consolidation score of 8 is misleading. While all metrics correctly source from a single table (`ipsos_mom_audience_view`), the underlying SQL logic for each metric is highly unconsolidated. Metrics are duplicated with hardcoded date ranges (March 2025, July 2025) and device types ('Tablet', 'PC/Laptop, Smartphone, Tablet'). This hardcoding leads to metric proliferation and makes the dashboard static and difficult to maintain or extend for new periods/dimensions. A critical anti-pattern was identified in the 'All Devices' filter, which uses an equality check against a comma-separated string, likely leading to incorrect or missing data if the 'Device' column stores individual device types. The absence of live SQL execution data prevents validation of these potential data issues.",154
cbed6cf2-50c3-494c-a4be-4d21d6ad9dac,National Sports Newsroom: Daily Report ,high,"The dashboard is highly focused, presenting a single, high-criticality KPI ('Weekly SPV Target by Website'). While the initial analysis indicates a high consolidation score (9) for the metric itself, the complete absence of SQL query execution data prevents any validation of its live performance, data quality, or actual usage. This lack of operational insight makes it impossible to confirm if the dashboard is functioning as expected or if the metric is truly consolidated and reliable in practice, elevating it to a high priority for investigation rather than further consolidation.",155
7af6d106-46fc-4721-8a0c-3da32bc27707,Cadets,high,"The dashboard 'Cadets' contains three metrics. A significant finding is the presence of two nearly identical 'Total Events' metrics, differing only by a single day in their hardcoded end date. This indicates a clear anti-pattern of duplicated SQL logic, which directly contradicts the initial AI's high consolidation score of 8. This suggests that the initial AI analysis may not fully account for deep SQL logic reusability. Furthermore, the absence of SQL query execution summary data prevents any validation of metric performance, data volume, or consistency against live query results, limiting the depth of the analysis regarding actual data behavior.",156
a7df2367-af28-4183-b5f8-70806ad88772,NCS Triggered SMS and post-engagement - DRAFT,high,"The 'NCS Triggered SMS and post-engagement - DRAFT' dashboard, while functional and consistently filtering for 'API Trigger' messages, exhibits significant opportunities for consolidation and improved data governance. The primary concern is the pervasive use of duplicated, hardcoded CASE statements for deriving key dimensions like 'message_category' and 'publication_abbreviation' across multiple metrics. This anti-pattern leads to increased maintenance overhead, potential data inconsistencies (e.g., incomplete publication abbreviations), and hinders scalability. Furthermore, several aggregation metrics rely on static, future-dated filters, which limits the dashboard's utility for ongoing, dynamic analysis. While the `sql_execution_summary` indicates successful query execution and data freshness, the underlying architectural choices warrant immediate attention to enhance maintainability, accuracy, and future adaptability.",157
c1ecb281-a103-4831-8a43-d303111e02ec,Looker Studio Reporting - Query Performance,high,"The 'Looker Studio Reporting - Query Performance' dashboard, while drawing from a single, consistent BigQuery `INFORMATION_SCHEMA` source, exhibits critical anti-patterns in its SQL logic that severely undermine its ability to provide a comprehensive and accurate view of query performance. The most pervasive issue is the widespread use of `LIMIT` clauses in aggregation and dimension metrics, which arbitrarily truncates data, rendering many visualizations incomplete and misleading. Additionally, inconsistent date filtering across related metrics creates potential for user confusion and makes cross-metric comparisons unreliable. The absence of live SQL execution data prevents validation of these observations against actual query performance or data integrity, highlighting a critical gap in the analysis process and elevating the priority for immediate investigation and remediation.",158
d3bcf796-2396-4a6f-b0a3-da0b7f299a58,Publisher and Product Performance Dashboard - FY25 v2,medium,"The dashboard's metrics are all sourced from a single, consistent BigQuery table (`asl_finance_derived.adsales_performance`), which is a strong foundation for data consolidation. However, the absence of live SQL execution data prevents validation of query performance, actual data values, or potential discrepancies. An observation from the detailed metric analysis is the presence of a hardcoded filter for 'financial_month = 1' in one of the key dimensions, which introduces rigidity and potential maintenance overhead for future fiscal periods. This suggests a need for improved parameterization or dynamic date handling.",159
180028f3-3485-45df-b0df-f690cbb6f2e9,The Australian Report Marketing,high,"The dashboard 'The Australian Report Marketing' is flagged with high complexity (8) and a high consolidation score (9) by the initial AI analysis. However, a deeper dive into the 58 detailed metrics reveals a significant anti-pattern: widespread use of hardcoded `CASE` statements for classification and filtering. This leads to a proliferation of highly similar metrics, making the dashboard difficult to maintain, scale, and govern. For example, numerous channel-specific subscription metrics are created as distinct fields rather than being derived from a single 'Total Subscriptions' metric filtered by a 'Channel Classification' dimension. The absence of live SQL execution data prevents validation of these metrics, but the structural issues related to hardcoding are evident. The initial high consolidation score appears to be at odds with the observed hardcoding, suggesting a potential gap in how 'consolidation' is currently measured, as it doesn't seem to fully account for the maintainability and scalability implications of such metric definitions. Refactoring these hardcoded definitions into reusable dimensions and filters is a high priority for true consolidation.",160
b8ff9b19-a3c3-4b05-a4a1-d6626d5783da,Verity 2.0: NSN Weekly Subs dashboard,high,"The analysis of the 'Verity 2.0: NSN Weekly Subs dashboard' reveals a critical dependency on hardcoded date ranges within all defined metrics. This significantly limits the dashboard's dynamism and utility for ongoing weekly analysis, making the 'Weekly Subs' designation misleading for its current implementation. Furthermore, the absence of SQL query execution summaries prevents any validation of metric performance or actual data output against live results, creating a significant blind spot in understanding the dashboard's operational health and data accuracy. The initial high consolidation score (8) appears to be based on metric definition rather than dynamic implementation, as the hardcoded dates introduce a major anti-pattern for a 'weekly' dashboard.",161
0db8e1f9-6d55-4d0d-a4b7-04f2c1c1f855,NewsPass Decay - DRAFT,high,"The 'NewsPass Decay - DRAFT' dashboard, despite its high initial consolidation score, exhibits significant opportunities for data model consolidation and SQL optimization. A critical observation is the pervasive duplication of complex CTE logic across almost all defined metrics. This anti-pattern suggests that the dashboard's underlying data preparation is highly inefficient, leading to redundant computations and increased maintenance burden. The absence of SQL execution summary data prevents validation against live performance, but the structural issues alone indicate a high priority for refactoring to improve performance, reduce cost, and enhance maintainability.",162
a62fa89c-fc4d-48d7-83e7-a673894fc85,Platform Spend Report,high,"The 'Platform Spend Report' dashboard, while drawing from a single data source (`campaign_performance_fct`), exhibits significant opportunities for logical consolidation and improved maintainability. The initial AI analysis reported a 'consolidation_score' of 8 and 'total_governance_issues' of 0, which appears to refer to data source consolidation rather than internal metric logic. Our detailed analysis reveals pervasive hardcoded date filters, repeated `CASE` statements for categorization (source systems, campaign types, masthead descriptions), and redundant rolling date logic across numerous metrics. This indicates a high maintenance burden, potential for data inconsistencies, and a lack of adherence to best practices for data modeling and metric governance. The absence of live SQL execution data prevents validation of these observations against real-world performance or data values, making these findings critical areas for immediate investigation and remediation.",163
a5d7d240-afbf-4f2d-b228-565c10dceb18,Updated Postcode Report ,high,"The dashboard 'Updated Postcode Report' exhibits a high consolidation score from the initial AI analysis, which is technically achievable given all metrics draw from a single base table (`subscription_base`) with identical core filtering. However, a deeper dive reveals significant opportunities for *technical* consolidation and improved data governance. The initial AI analysis correctly flagged the 'summing IDs' metrics as unusual, which is a critical anti-pattern. Furthermore, a repeated, hardcoded `CASE` statement for deriving 'state from zip' across multiple metrics presents a major maintenance and accuracy risk. The absence of live SQL execution data prevents validation of query performance or actual data values, making these observations based purely on static SQL logic.",164
a2edd9c0-9f0c-45f4-b481-6ed9e4a3f11d,PACMAN Dashboard - FY25,high,"The 'PACMAN Dashboard - FY25' demonstrates strong data source consolidation, with all metrics drawing from a single table (`dv_exclude_product_l3_and_l4`). However, a significant anti-pattern exists in the metric definitions: six out of seven metrics related to 'Total Expense' utilize repetitive and hardcoded `CASE` statements to filter by `Margin_Level`. This indicates an opportunity for substantial logical consolidation and improved maintainability. The absence of `sql_execution_summary` data prevents validation of live query performance or results, highlighting a critical gap in the analysis process.",165
5da65dbf-b1cc-467b-85fc-3c82ea5c9f13,DT Verity At-A-Glance,high,"The dashboard 'DT Verity At-A-Glance' presents a mix of consumer activity metrics and C-score targets. While the initial AI analysis suggests a high consolidation score (7), a deeper dive into the SQL logic reveals significant anti-patterns, primarily the pervasive use of hardcoded dates and filter values (e.g., 'Standard Paid', 'Digital', 'DT Masthead'). This hardcoding severely limits the dashboard's reusability, dynamism, and true consolidation, requiring manual updates for any change in reporting period or filter criteria. Furthermore, the absence of live SQL execution data prevents validation of these assumptions against real-world performance or data integrity issues. The inclusion of a distinct 'C-Score Target' metric from a different data source also warrants investigation into the dashboard's overall thematic coherence.",166
e380f99e-2ef3-40ec-a3ec-bc35491cc0bb,GL and SubSnapFact Revenue Extract,high,"The 'GL and SubSnapFact Revenue Extract' dashboard effectively retrieves financial data, and its core data quality checks (earned amount, data freshness) pass according to the `validation_sql` results. However, a deeper analysis of the detailed metric definitions reveals a significant reliance on hardcoded exclusion lists for subscription classifications and specific fiscal periods within key 'earned amount' metrics. While the initial AI analysis assigned a high consolidation score, likely due to all metrics sourcing from a single table, the internal logic within these metrics is highly fragmented and not consolidated. This approach severely limits reusability, maintainability, and scalability for future reporting needs or different timeframes, warranting a high consolidation priority for refactoring.",167
3d2c67c3-cd34-4afb-ba2c-1c4dc2cd9e90,Engagement: NewsPass Turnaround Program Performance,high,"The 'Engagement: NewsPass Turnaround Program Performance' dashboard, despite its moderate complexity and consolidation scores, is critically flawed by the pervasive use of hardcoded future date ranges (2025) across *all* defined metrics. This renders the dashboard non-functional for displaying current or historical performance data, directly contradicting its 'Performance' designation. The initial AI analysis reported '0 governance issues,' which is misleading given this fundamental data integrity problem. The absence of any SQL query execution summary further limits the ability to validate query performance or actual data retrieval, making it impossible to confirm if the queries would even return data for the specified future dates or if there are other underlying execution issues. This dashboard requires immediate attention to become a usable asset.",168
a982df7c-f75a-4f0e-bd2a-da716941d156,Verity 2.0 - CODE No Bs,high,"The dashboard, 'Verity 2.0 - CODE No Bs', initially assessed with a high consolidation score (8), presents significant opportunities for technical consolidation and improved maintainability. While the dashboard utilizes a limited set of base metrics, the underlying SQL queries frequently employ hardcoded date ranges and repeated filtering logic across multiple metrics. This anti-pattern contradicts the 'No Bs' implied by the dashboard name, indicating a lack of dynamic parameterization and centralized filter management. Crucially, the absence of SQL execution summary data prevents validation of query performance or results against live environments, necessitating further investigation into data collection processes.",169
2104a3f5-9424-4087-a928-e67fecae789a,Circulation Performance Dashboard,high,"The 'Circulation Performance Dashboard' exhibits significant data integrity and maintainability issues despite its high reported consolidation score. A critical observation is the pervasive mismatch in fiscal year filtering: the initial CTE (`OSandFACT`) in nearly all metrics consistently filters for `FY2025` (`gl_hierarchy_code = 'FY2025'`), while subsequent `WHERE` clauses or business descriptions for many metrics (e.g., 'Total Volume', 'Budget Amount (Current Week)', 'Volume (Mon-Fri, Thousands)') explicitly refer to `FY2026` or `202602`. This fundamental inconsistency will lead to empty or incorrect results for these metrics. Furthermore, the dashboard heavily relies on repeated, complex `CASE` statements for deriving 'day of week' and 'channel group' dimensions, indicating a lack of centralized dimension management. The 'current week' budget metrics also use hardcoded dates, rendering them static rather than dynamic.",170
7b5f16b7-e7eb-4989-97fe-2a2e74100bfe,Weekly Marketing comms sends,medium,"The 'Weekly Marketing comms sends' dashboard demonstrates good consolidation at the data source level, drawing all metrics from a single `newsletter_activity` table. This aligns with its high initial consolidation score. However, a significant anti-pattern exists in the `newsletter_brand_formatted` metric, which uses a complex, hardcoded `CASE` statement for data standardization. This approach undermines logical consolidation, maintainability, and scalability, indicating a need for improved data governance around dimension transformations. The absence of SQL execution summary data prevents a deeper analysis of query performance and runtime validation of metric assumptions.",171
a934f5eb-3b42-46f4-bd22-815444731247,NewsQuery Rewards redemption data test,medium,"The analysis of the 'NewsQuery Rewards redemption data test' dashboard is significantly hampered by the absence of `sql_execution_summary` data, preventing any live data validation or performance insights. Based solely on the provided metric definitions, both metrics (`Total Redemptions by Offer` and `Detailed Redemptions by Member and Transaction Time`) draw from the same `plus_rewards` table and consistently apply a `MAX(dw_partition_date)` filter, indicating a consolidated data source and consistent partitioning logic. However, one metric exhibits a highly inefficient and convoluted date/time conversion anti-pattern that warrants immediate attention for optimization and maintainability.",172
52dd1ac1-19b5-4695-a7e6-632ef7a9dba3,Consumer Finance Landing Page,low,"The dashboard 'Consumer Finance Landing Page' is small, containing only three metrics, all sourced from the same `digital_subscriptions` table within the `ncau-data-newsquery-prd.asl_finance_derived` dataset. This indicates good internal consolidation for the current scope. However, the absence of any SQL query execution summary data prevents validation of the metric logic against live results, making it impossible to confirm data accuracy or performance. A potential anti-pattern was identified in the dimension definition for 'Scenario', which uses a `LIMIT 100` clause, risking incomplete data representation.",173
f353b933-30eb-4853-9976-0d35371db7d7,Month End Reporting Reconcilation,high,"The 'Month End Reporting Reconcilation' dashboard exhibits a high degree of consolidation in its design. All three core metrics ('Total TM1 Amount', 'Total Tableau Actual Amount', and 'Total Absolute Variance') are derived from the exact same source table (`dv_tableau_vs_tm1_monthly_expenses`) and apply an identical filtering condition on `publication_code`. This consistency is crucial for reconciliation dashboards, ensuring that comparisons are made on a unified dataset. However, the absence of SQL query execution summary data prevents a comprehensive validation of the dashboard's operational health, such as query performance or actual data results, which is a critical gap for a full consolidation assessment.",174
6daaeb09-c31b-423e-a67c-50d8dcea3ba6,Content Performance Report,high,"The 'Content Performance Report' dashboard, while drawing from a single primary fact table (`campaign_performance_fct`), exhibits significant opportunities for consolidation and improved data governance. The absence of `sql_execution_summary` data prevents live validation of metric performance or data discrepancies. However, the detailed metric definitions reveal pervasive anti-patterns, including repeated hardcoded filters and numerous calculated fields that could be consolidated into a more flexible and maintainable semantic layer. This hardcoding inflates the number of distinct metrics (27) and indicates a high technical debt, making future modifications or extensions challenging and error-prone.",175
9060d6e1-ee05-438a-9bae-b80814a5e065,Verity 2.0 - Network Syndication Performance yesterday,high,"The dashboard, named 'Verity 2.0 - Network Syndication Performance yesterday', is severely impacted by hardcoded logic within its single metric. The SQL query uses static future dates (2025-06-12 to 2025-06-13) and a hardcoded Collection ID, rendering it irrelevant for 'yesterday' performance tracking and limiting its reusability. Furthermore, the `UNNEST` pattern for `RefArticleID` and `RefType` may lead to an incorrect calculation of unique combinations if these fields are intended to be corresponding array elements. The absence of a SQL Query Execution Summary prevents validation of the query's runtime behavior or output, necessitating immediate investigation into its execution status and data integrity.",176
61eeb098-9394-4e79-a43b-064edb830a79,FNL Performance Report,high,"The 'FNL Performance Report' dashboard, despite a reported complexity of 8, exhibits significant opportunities for consolidation and improved maintainability. While all metrics leverage a single base table (`campaign_performance_fct`), a pervasive anti-pattern of repeated, hardcoded `CASE` statements for derived dimensions (e.g., 'Seasonal vs. Performance', 'Channel', 'Brand', 'Fiscal Quarter Year') and individual metrics for each source system (e.g., 'TikTok Clicks', 'Google Clicks') leads to redundancy and makes future modifications cumbersome. The absence of `sql_execution_summary` prevents live data validation, but the SQL logic itself points to these structural inefficiencies. This approach hinders scalability and increases the risk of inconsistencies if business rules change, making the reported 'consolidation_score' of 6 seem optimistic given the identified anti-patterns.",177
e5702a4e-27f6-42cc-8cd8-0b5ff84421e4,Paid Consumer Subscriptions Acquisition Dashboard,high,"The dashboard exhibits excellent data source consolidation, drawing all metrics from a single, well-validated BigQuery table (`acquisitions_cancellations_movements`). However, this strong data consolidation is undermined by a severe lack of *logic consolidation* within the dashboard's metric definitions. Complex, hardcoded `CASE` statements for dimensions like 'Subscription Type' and 'Masthead Grouping' are repeatedly embedded directly into the `WHERE` clauses of multiple measure metrics. Furthermore, the 'Product Grouping' dimension features excessively nested and redundant logic. This anti-pattern creates significant maintenance debt, increases the risk of inconsistencies if business rules change, and makes the dashboard brittle despite its consolidated data source.",178
89140d65-10c7-4de8-9dfa-f5585b101519,Verity 2.0 - SC Health 7 DAY,high,"The dashboard 'Verity 2.0 - SC Health 7 DAY' exhibits a critical consolidation issue: its two primary metrics, despite the dashboard's name implying a consistent 7-day window, utilize hardcoded and *different* 7-day date ranges in their SQL logic (July 2025 vs. March/April 2025). This fundamentally undermines the dashboard's purpose of providing a consolidated 7-day view and makes direct comparison or aggregation of these metrics misleading. The absence of SQL execution summary data prevents validation of query performance or actual results, highlighting a gap in observability.",179
5d551155-3caa-466b-a1ef-01d0cfa95966,PTC - Topic Authority,low,"The 'PTC - Topic Authority' dashboard is characterized by its simplicity, containing only one high-criticality metric, 'Total Unique Contacts'. Its low complexity and consolidation scores indicate it is a highly focused dashboard that does not present an immediate priority for consolidation efforts. However, a significant impediment to a comprehensive analysis is the complete absence of SQL query execution summary data. This prevents any validation of the metric's live performance, data consistency, or identification of potential anti-patterns against its defined SQL logic. The primary focus for this dashboard should shift from consolidation to investigating the data collection process.",180
56c2d7df-a806-42fd-a626-09f428503c5b,Woolworths Rebranding,high,"The initial AI analysis reported a high consolidation score (7) for the 'Woolworths Rebranding' dashboard. However, a detailed review of the SQL logic for all five metrics reveals a pervasive anti-pattern of hardcoded date ranges and specific 'rebranding' filters. This significantly limits the reusability and dynamic capabilities of the dashboard, directly contradicting the notion of high consolidation and indicating a high maintenance burden for future reporting periods or different rebranding initiatives. The absence of SQL execution summary data prevents validation of query performance or actual data output, leaving critical areas for investigation regarding data integrity and query efficiency.",181
36c94aef-cf82-466b-9b8f-6a3a6580e059,Hackathon- AI-2025,low,"The dashboard is exceptionally simple, featuring only one low-criticality dimension. The initial analysis indicates high consolidation and low complexity. However, the absence of SQL execution summary data prevents validation of the metric's live performance or data completeness. A notable observation in the SQL logic is the `LIMIT 10` clause, which, if applied in production, would severely restrict the 'Agreement ID Source List' dimension, potentially leading to incomplete data for filtering or analysis, contradicting its stated purpose.",182
c4f27694-e6b3-4064-9231-f6c31b0bb9c1,Tech Platform Dashboard (Prod),medium,"The 'Tech Platform Dashboard (Prod)' demonstrates strong consolidation for its core engagement metrics, leveraging a single underlying data source (`an_daily_channel_summary_enriched_nca`) and a dynamic 'Selected Engagement Metric' using a CASE statement. This approach minimizes data redundancy and simplifies dashboard design. However, a critical hardcoded date filter (`date > '2024-06-19'`) in these metrics significantly limits historical data visibility and requires manual updates, overriding the dashboard's dynamic date range. Furthermore, the 'Distinct Content Count' metric stands out as an outlier, featuring highly complex SQL, a different data source, and embedded hardcoded logic (e.g., client exclusions, a hardcoded fallback URL for thumbnails). The absence of a `sql_execution_summary` prevents validation of these observations against live query performance or results, making a full assessment of consolidation effectiveness challenging.",183
6ee6cea9-d444-437d-96c9-cf93a94aad6b,Verity - Prod - Newsroom display - The Chronicle,medium,"The dashboard, focused on 'The Chronicle', contains two highly similar metrics that apply identical hardcoded filtering logic for the 'Chronicle' website. While the initial AI analysis reported no governance issues, this pattern indicates a clear opportunity for internal metric consolidation and improved reusability. The absence of SQL execution summary data prevents validation of live query performance or data consistency, leaving an important gap in the analysis.",184
33798d51-b7fb-4d59-84da-e004f442c841,BSG - Health Check,high,"The 'BSG - Health Check' dashboard, despite its high consolidation score in the initial AI analysis, exhibits significant anti-patterns and logical inconsistencies upon deeper review of its metric definitions. Key 'Overall Table Health Status' metrics are misleading as they only display the status for a single, hardcoded example table, not an aggregate. The definition of 'healthy' tables is inconsistent between business descriptions and SQL implementation, potentially misrepresenting data health. Furthermore, extensive hardcoding of table names and refresh rules within SQL queries severely impacts maintainability and scalability. The absence of `sql_execution_summary` prevents live data validation, making these observations critical areas for immediate investigation and refactoring.",185
6f1c8731-02da-464f-b146-bf2947860735,Programmatic Sales_NQ Data,medium,"The analysis of the 'Programmatic Sales_NQ Data' dashboard reveals a significant reliance on hardcoded filter values within the SQL logic for multiple metrics. While the initial AI analysis indicates a good consolidation score (7/10), the pervasive hardcoding of `PortfolioParentGroup`, `TransactionType`, `FinancialYear/Quarter`, and `PortfolioChildGroup` values across several metrics suggests a lack of reusability and potential for maintenance overhead. This pattern indicates an opportunity for improved data modeling and parameterization to enhance dashboard flexibility and consolidation. Crucially, the absence of live SQL execution data prevents validation of metric performance or data accuracy, making it an immediate area for investigation.",186
ca71779e-655c-4fda-0000-c32970fc283a,Verity FY26 - Testing newsroom screen & possible new KPIs,high,"The dashboard's metrics, while seemingly distinct, reveal a pattern of hardcoded business logic, particularly for filtering mastheads, customer types, and categorizing subscriber mosaic groups. The `business_rules_sql` sample data indicates that the hardcoded `CASE` statement for 'subscriber_mosaic_group' is incomplete or outdated, as observed groups ('High Society', 'Solo Budgets') are not explicitly defined in the metric's SQL. This suggests a significant risk of data miscategorization and a lack of centralized governance for key business dimensions. The high number of unique mastheads (10282) observed in the `structure_sql` further highlights the need for standardized lookup tables and parameterized filtering to improve maintainability and data consistency across the dashboard and potentially other reporting assets.",187
7a21f833-eb54-4580-b152-669a9cc02dd9,FY25 Metro Report,high,"The 'FY25 Metro Report' dashboard, despite a reported 'consolidation score' of 8, exhibits significant opportunities for data model consolidation and SQL optimization. A pervasive anti-pattern is the repetition of complex filtering logic across nearly all metrics sourced from `campaign_performance_fct`. Furthermore, numerous metrics rely on extensive hardcoded `CASE` statements for categorization (e.g., campaign categories, channels, mastheads), which is difficult to maintain and prone to errors. The absence of live SQL execution data prevents direct validation of these queries, but the structural issues are evident. The dashboard's reported '0 governance issues' appears to contradict the observed anti-patterns, suggesting a need to enhance governance rule definitions.",188
762b4ea1-2978-4ce6-8308-6eff1fc3422f,Adsales Sports Dashboard,medium,"The 'Adsales Sports Dashboard' demonstrates a high initial consolidation score, likely due to all metrics sourcing from a single table (`adsales_sports_revenue`). However, the detailed metric analysis reveals significant opportunities for improving code maintainability and reusability. Multiple metrics employ repeated, complex `CASE` statements and hardcoded filters, indicating a lack of centralized logic definition within the Looker Studio data source or upstream data model. The absence of live SQL execution data prevents validation of performance or actual data consistency, making further investigation crucial.",189
f63bfd08-fe1d-464a-a78c-a7f7fbaca71c,FY25 Copy of - Team Sales Performance,high,"The analysis of the 'FY25 Copy of - Team Sales Performance' dashboard is significantly limited by the absence of live SQL execution data, preventing direct validation of metric performance or data consistency. However, a deep dive into the detailed metric definitions reveals a pervasive reliance on hardcoded `CASE` statements for categorization, ranking, and dynamic grouping. This anti-pattern is particularly evident in dimensions like 'Revenue Group Level 2 Industry Pillar' and 'Dynamic Ad Type or Industry Group', leading to duplicated logic, high maintenance overhead, and reduced flexibility. Furthermore, several metrics, such as 'Sum of Financial Month Numbers' and 'Sum of Product Group Rankings', are explicitly noted as having 'unclear business utility', suggesting potential misconfigurations or artifacts that should be reviewed for removal to streamline the dashboard and improve data clarity.",190
b51acdd5-4bf9-4de0-9c2f-a0bbd529ddf7,Verity 2.0 DT Weekend Content Review: Tuesday report,high,"The dashboard 'Verity 2.0 DT Weekend Content Review: Tuesday report' exhibits significant inflexibility due to pervasive hardcoded date ranges and specific filter values within its metric SQL. This directly contradicts the initial AI analysis's high consolidation score (8) and suggests a critical need for immediate refactoring to enable dynamic reporting and improve reusability. Crucially, the absence of SQL execution summary data prevents validation of query performance or actual data results, making it an urgent area for investigation. The dashboard, as currently defined by its SQL, would only display data for specific future dates, rendering it non-functional for current reporting.",191
789ba6af-d662-4bbe-a27c-e2ea9551305d,Print to Digital - NT News,high,"The 'Print to Digital - NT News' dashboard, while focused on key subscription metrics, suffers from critical hardcoding issues. All metrics use static, future-dated ranges (e.g., 2025), rendering the dashboard irrelevant for current performance monitoring. Furthermore, the core 'Adds', 'Cancels', and 'Net Adds/Cancels' metrics, despite querying the same underlying view, employ redundant filtering logic and inconsistent `LIMIT` clauses, indicating a lack of consolidated metric definitions and potential for maintenance overhead. The underlying data appears robust and passes validation checks, but the dashboard's current implementation prevents dynamic, real-time insights and suggests a high need for refactoring and consolidation.",192
c00fff03-f644-4725-90db-35b254793268,Verity 2.0 - Daily Digital Retro - HS,high,"The dashboard 'Verity 2.0 - Daily Digital Retro - HS' exhibits significant opportunities for consolidation and improved data architecture practices. Despite an initial AI-generated consolidation score of 8, a detailed review of the SQL logic reveals extensive hardcoding of dates, date ranges, and categorical filters (e.g., 'Herald Sun', 'Consumer', 'Print-only'). This leads to substantial metric duplication, where the same base metric is redefined multiple times solely due to different hardcoded filter values. The absence of live SQL execution data prevents validation of query performance or results, but the observed anti-patterns strongly suggest high maintenance overhead and limited reusability. The dashboard's current structure is highly static, making it inflexible for dynamic analysis or user-driven exploration.",193
435638dc-cebd-41fe-8e93-f4a0e2f0f5a9,Audience Insights PRSTN - Medallia VOC survey dashboard,medium,"The dashboard, while initially assessed with a high consolidation score, presents significant opportunities for further data model and metric logic consolidation. A key observation is the repeated use of complex, hardcoded `CASE` statements across multiple metrics to categorize CSAT scores. This leads to redundant SQL, potential for inconsistencies (as seen in 'Exclude' category handling), and reduced maintainability. All metrics also rely on hardcoded date ranges, limiting dynamic analysis and requiring manual updates. The absence of SQL execution summary data prevents direct validation against live performance or actual data values, necessitating further investigation into data accessibility or prior processing.",194
56e7262f-a638-469d-a174-fab6a8a65226,FY25 Regionals Report,high,"The 'FY25 Regionals Report' dashboard, while leveraging a single underlying fact table, presents significant opportunities for consolidation and optimization at the metric definition level. A complex, identical `WHERE` clause is hardcoded across all 26 metrics, creating a substantial maintenance burden. Furthermore, a pervasive anti-pattern exists where numerous dimension and measure metrics rely on hardcoded `CASE` statements for classification, most notably in the inefficient creation of separate channel-specific subscription metrics. This directly contradicts the initial analysis's claim of zero governance issues and indicates a high priority for refactoring to improve maintainability, query performance, and data consistency. The absence of `sql_execution_summary` data prevents direct validation of performance impacts but the identified patterns strongly suggest inefficiencies.",195
c393a5a0-4e52-4bfe-b791-47d1aee087e9,Personalisation - Analytics - AWS,high,"The 'Personalisation - Analytics - AWS' dashboard, despite its high reported consolidation score of 9, exhibits significant underlying SQL anti-patterns. All 13 detailed metrics provided share an almost identical, complex set of Common Table Expressions (CTEs) and hardcoded logic. This extreme duplication of query logic across metrics indicates a critical need for data model consolidation and refactoring into shared, reusable views. The current approach severely impacts maintainability, increases the risk of data inconsistencies, and likely leads to inefficient query execution, especially given the repeated 30-day lookback window calculations.",196
aaeee404-9b2c-4665-9228-999b01c5fc70,Adsales Details Dashboard CONS WA,high,"The 'Adsales Details Dashboard CONS WA' demonstrates strong structural consolidation (score 8) by sourcing all its data-driven metrics from a single BigQuery table (`ncau-data-newsquery-prd.asl_finance_derived.details_dashboard`). This centralized data source is beneficial for consistency and governance. However, a critical anti-pattern identified across most data-driven metrics is the pervasive hardcoding of specific filter values (e.g., 'CONSORTIUM WA', '2025', 'May', 'Jun') directly within the SQL queries. This design choice severely limits the dashboard's reusability and dynamic filtering capabilities, effectively rendering it a static snapshot tailored to a very specific context rather than a flexible analytical tool. While the dashboard is consolidated in terms of its data origin, its logical rigidity necessitates a high priority for refactoring to enable broader applicability and true consolidation across different portfolios or timeframes. The absence of `sql_execution_summary` data is a significant gap, preventing any validation of query performance, cost, or actual data results against live execution.",197
77631717-5cc6-4903-87bd-7314bf461243,Free & Complimentary SuperCoach Extract,medium,"The dashboard's core metrics for 'Free Trials' and 'Complimentary' SuperCoach subscriptions are well-validated by the live data, confirming the presence of relevant data and successful query execution. The `validation_sql` explicitly confirms data quality and recency. However, there's an opportunity for further consolidation and simplification of record-counting metrics, as several share highly similar SQL logic differing only in the grouping dimension or a minor fiscal year filter. This suggests potential for a more dynamic or parameterized approach within Looker Studio or the underlying data model.",198
8f142224-196a-4d47-b234-491eeecf59fa,NX DASHBOARD,high,"The dashboard exhibits strong consolidation at the base metric definition level, with all 'Gross Revenue' metrics consistently deriving from the same source table (`v_adsales_revenue_client`) and core filtering logic (`xtend_flag = 'Y' AND revenue_transaction_status IN ('Billed', 'Booked')`). This aligns with the initial AI's high consolidation score. However, a significant anti-pattern observed is the creation of distinct metrics for specific financial years (e.g., 2024, 2025) and quarters, rather than leveraging dynamic dashboard filters or parameters. This approach, while functionally correct, introduces unnecessary metric proliferation and will lead to increased maintenance overhead as new financial periods arise. Crucially, the absence of live SQL execution data prevents validation of query performance, actual data volumes, or potential runtime errors, leaving a critical gap in the analysis.",199
d7412673-0af1-4efe-8374-ca475b001fb6,Finance OS datasource template report,high,"The dashboard, 'Finance OS datasource template report', is in the finance domain and initially scored high on consolidation (9/10). However, a deeper analysis of the underlying SQL reveals a significant anti-pattern: the core `OSandFACT` CTE is duplicated verbatim across all three metrics. This duplication indicates a lack of true SQL-level consolidation, leading to potential performance inefficiencies, increased maintenance overhead, and higher query costs. The absence of `sql_execution_summary` data prevents validation of live performance or data accuracy, highlighting a critical area for investigation. The dashboard's reliance on hardcoded period filters ('CP', 'PY') also limits its flexibility.",200
6a9da673-c8cd-4bd5-8743-77da4afcfa78,TDD DATA - AUDIO DASHBOARD,high,"The dashboard exhibits a significant consolidation anti-pattern, with two distinct metrics that are functionally identical except for hardcoded, future-dated time ranges. This contradicts the initial high consolidation score (8) and indicates a fundamental design flaw. The live data further reveals that these metrics are querying data from 2025, while the latest available data is from April 2024, leading to a `data_freshness_check: FAIL` and rendering the defined metrics currently non-functional or displaying empty results.",201
9ba99d6a-b418-433f-9b7c-ec7430af6e8f,CODE Sport Report Marketing,high,"The dashboard 'CODE Sport Report Marketing' is designed to track marketing acquisitions and subscriptions for 'CodeSport', featuring 27 metrics. A critical finding is the complete absence of SQL execution summary data, which severely limits the ability to validate the dashboard's metrics against live query performance, cost, or actual data returned. This prevents confirmation of whether the defined SQL logic is executing as expected or encountering runtime issues.

Analysis of the detailed metric data reveals a significant anti-pattern: a high degree of SQL query repetition, particularly for acquisition metrics. These metrics frequently employ `SUM(CASE WHEN ...)` statements to categorize acquisitions based on specific 'sold_in_channel' or 'sold_in_source_channel' values from the `v_subscription_movement` table. This approach leads to substantial code duplication, making the dashboard difficult to maintain and susceptible to inconsistencies if channel definitions evolve. The 'Other BAU Acquisitions' metric further exemplifies this by using a lengthy, hardcoded `NOT IN` list that even contains duplicate values.

Additionally, all metrics across both underlying tables (`v_subscription_movement` and `campaign_conversion_fct`) utilize hardcoded date ranges or fiscal years. This design choice means the dashboard will rapidly become outdated, necessitating manual SQL modifications to reflect current reporting periods. There's also an observed inconsistency in how the 'CodeSport' entity is filtered (`masthead = 'CS'` vs `masthead_group_description = 'CodeSport'`) across the two primary data sources, which could lead to data discrepancies if not perfectly aligned.",202
8dd0c610-0845-410c-b2f1-1d01043b9908,B2B Customer Extracts,medium,"The dashboard's initial analysis indicated a high consolidation score (8) and zero governance issues. However, the critical absence of live SQL execution data (`sql_execution_summary` is empty) prevents any validation of these claims or the performance of the dashboard's metrics. A detailed review of the metric SQL reveals a pervasive `LIMIT 100` clause on most dimension queries, which, if applied to dashboard filters, could lead to incomplete data representation for users. Furthermore, common date filtering logic (`SAFE_CAST(rev.bill_date AS DATE) > '2018-07-01'`) is redundantly applied across multiple metrics, indicating an opportunity for improved maintainability and consistency through consolidation into base views or materialized views. These findings suggest that while the underlying data model might be well-structured (as implied by the consolidation score), the implementation of certain metrics could benefit from refinement, contrary to the initial assessment of zero governance issues.",203
c794898d-8468-454e-97c7-de1fa293c759,VERITY AT A GLANCE - [CMWEEKLYVIEW + QUESTWEEKLY VIEW ] Verity 2.0 - Prod - At-a-Glance,high,"The initial AI analysis reported a high consolidation score (8), but a deeper dive into the detailed metrics reveals a significant anti-pattern: multiple instances of the same base metric (`subscription_day_target`, `c_score_weekly_target`) are created solely to accommodate different hardcoded date ranges. This indicates poor metric reusability and a lack of parameterization, which inflates the number of distinct metrics and makes the dashboard less maintainable and scalable. The absence of `sql_execution_summary` data prevents validation of these metrics against live performance or results, highlighting a critical gap in the analysis pipeline.",204
e33ad43b-7f46-4dd7-bfd4-bd53657e4538,Paid Consumer Subscriptions Cancellation Dashboard,high,"The analysis of the 'Paid Consumer Subscriptions Cancellation Dashboard' reveals a critical absence of live SQL execution data, preventing direct validation of metric assumptions. However, a deep dive into the detailed metric definitions highlights significant anti-patterns related to hardcoded logic and extensive duplication. Specifically, complex categorization logic for 'Subscription Category' and 'Publication Group' is embedded directly within multiple metric definitions, leading to severe maintainability challenges and a high risk of inconsistency. The dashboard's high complexity and consolidation scores are likely a direct consequence of these architectural issues, necessitating immediate attention for refactoring and consolidation.",205
d110a146-283a-4836-a1db-94ef302d9d90,BEYOND WORDS - dev 2,high,"The 'BEYOND WORDS - dev 2' dashboard, despite an initial AI assessment of '0 governance issues', exhibits significant opportunities for consolidation and code optimization. A deep dive into the 38 metrics reveals widespread repetition of complex `WHERE` clauses across multiple data sources (Adobe and BeyondWords). This anti-pattern leads to high maintenance overhead and potential for inconsistencies. Furthermore, the reliance on `REGEXP_CONTAINS` for event parsing in clickstream data indicates a need for improved data modeling. The absence of live SQL execution data prevents validation of performance impacts but strongly suggests that query efficiency could be improved through proposed consolidations.",206
a7a0f9fb-9e07-4931-8127-a7944660b5c9,Verity 2.0 - PRD - Video Summary,high,"The dashboard 'Verity 2.0 - PRD - Video Summary' exhibits significant anti-patterns related to hardcoded date ranges and a critical data quality issue with the 'sum of averages' calculation. Despite an initial high consolidation score, the lack of dynamic date filtering severely limits its utility and reusability. The absence of SQL execution summary data prevents validation against live performance or data discrepancies, necessitating further investigation into data pipeline and Looker Studio configuration.",207
85af3509-d3b5-433d-83d2-d49a89ad4f0b,Video Dashboard (Julie),high,"The 'Video Dashboard (Julie)' demonstrates a foundational level of consolidation by sourcing all its metrics from a single BigQuery table (`v_adsales_revenue_client`). This is reflected in its initial high consolidation score. However, a deeper architectural analysis of the underlying SQL reveals significant anti-patterns that undermine true consolidation and introduce considerable maintenance overhead. Specifically, complex and extensive hardcoded `CASE` statements are used to derive key dimensions like 'video_type' and 'targeting_type', and long lists of publication exclusions are repeated verbatim across almost all metrics. Additionally, specific business logic, such as GM names and financial weeks, is hardcoded. The absence of live SQL execution data (`sql_execution_summary` is empty) prevents validation of these assumptions against actual data values or performance metrics, but the structural issues alone indicate a high priority for refactoring to improve maintainability, accuracy, and scalability. The initial AI assessment of '0 total_governance_issues' is challenged by these identified anti-patterns.",208
5645b0e9-2850-4984-b808-b90bcb74ed92,Verity Newsroom display - Code Sports,low,"The dashboard is highly consolidated with a single, critical metric. However, the SQL logic for the 'Daily Website Target (Code Sports)' metric contains a hardcoded date ('2025-07-02'), rendering the dashboard static and unable to display current daily targets dynamically. This significantly limits its utility for a 'daily' metric. The absence of a SQL execution summary prevents validation of live data performance or results.",209
87651b69-c43e-471f-9c4b-98df1208a844,Programmatic Sales Patches,high,"The dashboard 'Programmatic Sales Patches' is designed around core advertising metrics and dimensions, all sourced from a single table (`programmatic_cal_month`). While the base dimensions and aggregate measures are well-defined, the presence of two highly specific, hardcoded aggregation metrics (`paid_impressions_guaranteed_cw_jun2025` and `revenue_gross_guaranteed_cw_jun2025`) indicates a significant anti-pattern. These metrics are rigidly filtered by transaction type, advertiser, and a future specific month (June 2025). This approach severely limits the dashboard's flexibility and scalability, suggesting that specific data slices are being created as new metrics rather than leveraging dynamic filtering capabilities within the dashboard. The absence of `sql_execution_summary` data prevents live validation of query performance or results, making this analysis based solely on the provided metric definitions.",210
d200e676-935c-4ae4-abad-abf3addd82c2,EDV POC PW,high,"The analysis reveals significant limitations in the 'EDV POC PW' dashboard, warranting a high consolidation priority. Crucially, the absence of live SQL execution data prevents validation of metric performance and results, necessitating immediate investigation. All five metrics are severely constrained by a 'LIMIT 100' clause, rendering the dashboard unsuitable for comprehensive analysis beyond a small sample. Furthermore, multiple metrics rely on hardcoded date ranges and a specific subscription ID, indicating a lack of dynamic filtering and reusability. The initial assessment of 'total_governance_issues: 0' is misleading, as these hardcoded values and data limitations represent critical governance and maintainability concerns.",211
3c161a70-2994-4beb-958e-29e06f9053c4,Verity 2 - Monitoring Dashboards,high,"The 'Verity 2 - Monitoring Dashboards' dashboard, despite its high complexity score, exhibits significant opportunities for consolidation and refactoring. A primary observation is the widespread use of hardcoded date ranges, rendering several key monitoring metrics (e.g., subscription timestamps, package order events) static or future-dated, rather than providing real-time operational insights. Furthermore, there are clear anti-patterns in the SQL logic, including extensive repeated complex `CASE` statements for classification and large `UNION ALL` blocks for metadata, indicating a strong need for shared views or dedicated lookup tables. The absence of live SQL execution data prevents validation of performance or actual data values, but the structural issues are evident.",212
6575ef79-5264-4580-998a-8150e679f565,Verity 2.0 Sports Live Streams: Weekly Wrap (Click here to access the full report),high,"The dashboard exhibits strong consolidation at the data source level, with all metrics deriving from the same base table (`subscription_targets`) and a common base metric (`total_day_target`). However, the utility of this 'Weekly Wrap' dashboard is severely undermined by the pervasive use of hardcoded date ranges and specific string filters within its aggregated metrics. This makes the dashboard static and not truly reflective of current weekly performance. Furthermore, the absence of live SQL execution data prevents validation of these metrics against real-world query performance or results, highlighting a critical gap in the analysis pipeline.",213
0e05b4ce-cb33-488a-8537-b9e68a844e2e,Acquisitions - Extracts,high,"The dashboard 'Acquisitions - Extracts' is reported with a high consolidation score (9) and complexity (8). While all metrics indeed source from a single table (`acquisitions_cancellations_movements`), a deeper analysis of the SQL logic reveals significant anti-patterns related to logical consolidation. Specifically, complex business rules for product and masthead classification are hardcoded and duplicated across multiple metrics, leading to a high maintenance burden and risk of inconsistency. The initial AI analysis reported '0 governance issues', which contradicts the observed SQL anti-patterns, indicating a gap in the automated governance assessment. Furthermore, the absence of `sql_execution_summary` data prevents validation of these metrics against live results, necessitating further investigation into data integrity and query performance.",214
a6b35c09-d774-4509-95d0-4e3c05417e57,MLOPS - GCP AI Usage Summary,high,"The 'MLOPS - GCP AI Usage Summary' dashboard presents three highly related GCP cost metrics, all sharing a common base SQL structure. The initial AI analysis indicates a high consolidation score (8), which is strongly supported by the detailed metric data. All metrics rely on an identical hardcoded list of project IDs and a `FULL JOIN` to a project metadata table. Two metrics further filter projects using fragile string matching (`STRPOS`) on the metadata table. A critical observation is the absence of `SQL Query Execution Summary` data, which prevents validation of the SQL logic against live performance or results. This means the analysis is based purely on static SQL review, highlighting several anti-patterns related to hardcoding and inefficient data categorization that could be significantly improved through consolidation and better data governance.",215
743c6721-7b52-4c74-ae92-c60c9a76602a,FY25 The Australian AOD Report,high,"The dashboard, while rated with high complexity and consolidation by the initial AI analysis, exhibits significant internal consolidation challenges. A deep dive into the detailed metric SQL reveals widespread use of repeated, hardcoded filters and complex, duplicated CASE statements for data classification. This anti-pattern severely impacts maintainability, scalability, and consistency across metrics. The absence of live SQL execution data prevents direct validation of metric outputs but highlights a critical area for investigation. The dashboard effectively combines data from different business domains (article subscriptions and marketing campaign performance) but does so with brittle, embedded logic rather than centralized, reusable components.",216
127587ca-3bf2-4367-809c-ce91aca8fb52,Verity - Prod - Newsroom display - TABN,low,"The dashboard 'Verity - Prod - Newsroom display - TABN' is highly consolidated with a score of 9 and focuses on a single, high-criticality KPI: 'Total Daily Subscription Target by Publication Group'. While the initial AI analysis suggests a clear purpose, the absence of `sql_execution_summary` data prevents validation of the metric's live performance or data consistency. The SQL logic itself contains a hardcoded date and a `LIMIT 10` clause, which are potential anti-patterns requiring investigation to ensure data completeness and dynamic filtering.",217
3b23bf1a-c212-49a1-afa1-558ec7ed6b19,Print Subscription Summary,high,"The 'Print Subscription Summary' dashboard effectively consolidates metrics around print and paid subscriptions, drawing from a consistent set of core data sources within the `ncau-data-newsquery-prd` project. This indicates a strong foundation for data source consolidation. However, the absence of live SQL execution data prevents validation of metric performance and data accuracy, which is a critical gap. A significant observation from the detailed metric definitions is the prevalence of repeated, complex hardcoded business logic for 'finance_recognition' and highly specific, time-bound data adjustments. While the data sources are well-consolidated, the internal logic within the metrics themselves requires substantial consolidation and externalization to improve maintainability, reduce technical debt, and ensure consistent application of business rules.",218
cf714dce-529a-49ba-94b8-ddb12643c494,FY25 Performance Executive Dashboard,high,"While the dashboard effectively leverages a common base view (`v_subscription_base_movement_agg`) for a majority of its metrics, the actual metric definitions suffer from extensive hardcoding. Complex, identical `WHERE` clauses are repeated across numerous base metrics, and critical business logic for derived dimensions (e.g., `Customer_Type`, `Subscription_Rate_Plan_Group`) is embedded in long, fragile `CASE` statements. This significantly undermines the initial high consolidation score (8), indicating a substantial maintenance burden and a high risk of inconsistency due to the absence of a centralized, governed semantic layer for common filters and business rules. The live data validation confirms the underlying data structure is sound, but the dashboard's construction practices are highly inefficient.",219
7ada02b8-e93e-41d8-9a7e-05013ff81247,Unmapped Revenue NPV,high,"While the core financial metrics ('Total LGR (NPV Filtered)' and 'Total Relative FY Month Offset (NPV Filtered)') exhibit consistent filtering logic and appropriate data types (BIGNUMERIC) for financial calculations, a critical anti-pattern was identified in the dimension and timestamp metrics. The 'LIMIT 1' clause in the SQL queries for 'Derived GM / Sales Region', 'Derived GSD / Sales Team', and 'Data Load Timestamp' renders these metrics effectively useless for their intended purpose of grouping/filtering or monitoring overall data freshness. This directly contradicts the initial AI analysis's '0 governance issues' and significantly impacts the dashboard's usability and data integrity. The absence of SQL execution summary data prevents validation of live performance or actual query results, necessitating further investigation.",220
c67409c3-3e67-4d5a-8472-34a3aa704cf6,NewsGPT Analytics,high,"The dashboard 'NewsGPT Analytics' is reported with a high consolidation score (9), yet the underlying SQL for all five metrics reveals significant duplication and hardcoded values. Each metric, despite being a variation of 'Total GCP Cost', contains nearly identical CTEs and only minor differences in filtering logic (date ranges, specific project substrings, and critically, different hardcoded lists of project IDs). This indicates a severe lack of true consolidation, leading to high maintenance overhead and potential for inconsistencies. Furthermore, all attempts to execute the SQL queries failed due to 'Access Denied' errors, rendering the dashboard non-functional and preventing any validation of data accuracy or completeness.",221
0546f07c-bb7b-4ec0-aba8-06c738dd12ec,Verity 2.0 Messenger Weekly Subs and C-Score dashboard,low,"The dashboard exhibits strong data consolidation, with both metrics drawing from the same `cscore_targets` table and sharing a common `c_score_target_sum` base metric. This aligns with the initial AI analysis's high consolidation score (7) and indicates a well-structured data foundation. However, the critical absence of SQL query execution summary data prevents any validation of live performance, data volume, or actual query results. This lack of operational insight makes it impossible to confirm the dashboard's real-world health, data accuracy, or identify potential runtime issues, despite its sound design.",222
e0746d13-dad7-4ba1-aabc-d3b8e82cef54,FY25 Copy of AdSales Data for Pacing Report ,low,"The dashboard exhibits strong data source consolidation, with all five metrics drawing from a single BigQuery table (`adsales_performance_archive_FY25`). This aligns with the initial AI analysis's high consolidation score (7). However, the absence of SQL query execution summary data prevents a comprehensive validation of metric logic against live results. A key finding from the detailed metric analysis is the use of a hardcoded CASE statement for month-to-numeric conversion, indicating a potential area for improved maintainability and governance, despite the dashboard's overall low complexity.",223
4d8074b2-17a8-48ba-babe-c536359b1f64,Final_Draft Adsales Performance Dashboard - FY25 20241127,medium,"The dashboard demonstrates strong data source consolidation, with all metrics pulling from a single, well-defined `adsales_performance` table within the `asl_finance_derived` dataset. This is a significant positive for data consistency and maintenance. However, a critical anti-pattern was identified: nearly all measure and dimension metrics include `LIMIT` clauses in their SQL definitions. If these represent the actual Looker Studio field definitions, they severely restrict the dashboard's ability to display aggregated data or dimensional breakdowns, contradicting the typical purpose of a performance dashboard. The absence of live SQL execution data prevents validation of actual query performance or results.",224
f84749df-19c4-4af7-b29fcefddb6a,$99 Dollar/12M PAYG/EOFY Contracts,high,"The dashboard, focused on specific contract types and churn prediction, exhibits significant technical debt due to pervasive hardcoding and redundant SQL logic across all its metrics. The use of future dates (2025) in filters suggests either a forward-looking analysis or a critical need for dynamic date parameters. A major functional flaw exists in the 'Churn Group' metric, where a `LIMIT 1` clause prevents it from serving as a proper categorical dimension. The high complexity and consolidation scores from the initial AI analysis are likely reflective of the business domain's intricacy rather than the underlying data architecture's efficiency or reusability.",225
b821747c-3075-4a4b-b4a5-c12a548b4e1b,CVM dashboard,medium,"The 'CVM dashboard' effectively tracks customer value management metrics, with all underlying SQL queries executing successfully and data appearing consistent. However, a significant anti-pattern exists where the complex `CVM_Status` categorization logic is duplicated across two key metrics. While the `CASE` statement correctly maps all 7 unique CVM flags identified in the live data, its repetition indicates a lack of centralized definition, hindering maintainability and future scalability. Additionally, a brand-specific metric uses a hardcoded filter for 'TB', which, while functional, limits the dashboard's flexibility for multi-brand analysis without metric duplication. The dashboard's current consolidation score of 7 reflects this potential for improvement through architectural refactoring.",226
b3eace25-3ec3-427a-839f-0639faf377ea,Regression Source Data Analysis,medium,"The dashboard 'Regression Source Data Analysis' primarily focuses on 'The Australian' masthead and specific years (2025, up to 2027), indicating a narrow scope or a need for broader parameterization. All metrics consistently draw from a single source table (`ncau-data-newsquery-prd.sbx_fda_noncorefin.dt_regression_data`), which is a positive aspect for data consolidation. However, a significant observation is the presence of multiple 'unusual aggregations' where the 'Year' or 'Week' dimensions are summed (e.g., 'Total Year Sum for The Australian', 'Total Year Sum by Week', 'Total Week Sum by Week'). These metrics are flagged as low business criticality, suggesting they might be for internal data validation, debugging, or are simply misconfigured. Their true business purpose requires clarification. The absence of SQL execution summaries prevents any validation of metric performance or actual data outputs, which is a critical gap for a comprehensive analysis of data consistency and potential mismatches.",227
abd763c6-2364-490c-b801-5bfbbf69b2d4,Programmatic & Performance Team and Streaming Team FY26(vs Target),high,"The analysis of the 'Programmatic & Performance Team and Streaming Team FY26(vs Target)' dashboard reveals significant opportunities for consolidation and improvement in SQL coding practices. A critical observation is the absence of live SQL execution data, which prevents validation of metric outputs against real-world results. However, a static review of the SQL logic uncovers pervasive anti-patterns, including extensive code duplication across all metrics, the use of `LIMIT 1` on aggregate 'Total' metrics (which will lead to fundamentally incorrect results), and widespread hardcoding of filter values and complex CASE statements. The dashboard's complexity is artificially inflated by these issues, indicating a strong need for refactoring into shared, governed data sources or views.",228
46ddebb6-f504-44ef-86dc-924a51de34bf,OPERATIONAL REPORT,high,"The 'OPERATIONAL REPORT' dashboard, while drawing from a single source table (`sdm_sfnca.opportunity`), exhibits critical data integrity and usability issues. The initial AI analysis reported '0 governance issues', which is directly contradicted by the detailed metric review. A major anti-pattern is the pervasive use of `LIMIT 1` on all dimension metrics, rendering them functionally useless for analytical purposes. Furthermore, inconsistent date filtering across different metrics will lead to fragmented and unreliable data views. The absence of live SQL execution data (`sql_execution_summary` is empty) prevents validation of performance or actual query results, highlighting a potential gap in monitoring or data collection.",229
eb904391-4d82-4b02-4f99-5eef7336117f,Martini Dashboard,low,"The Martini Dashboard exhibits a strong design pattern for metric consolidation, with both metrics (`Video Media Starts (Portrait)` and `Video Media Starts (Portrait, News.com.au)`) deriving from the same base table (`video_gam_daily_agg_fct`) and sharing common filtering logic. This indicates good reusability and a clear hierarchy of metrics, aligning with the high initial consolidation score. However, the absence of SQL query execution summary data prevents validation of actual query performance, data volume, or identification of runtime issues, which is a critical gap for a comprehensive consolidation analysis.",230
6d3aa90f-e0e3-4462-9032-286b434adfe8,SWG - Subscription Volume,high,"The dashboard, 'SWG - Subscription Volume', exhibits a high degree of metric similarity and relies heavily on hardcoded values for dates and rate plans. While the initial AI analysis indicates a high consolidation score (8), the detailed SQL logic reveals significant opportunities for further consolidation and parameterization. The absence of `sql_execution_summary` data prevents validation of live query performance or results, necessitating further investigation into data collection processes.",231
003ea399-8d01-4613-91ef-e27f1254bda8,Verity 2.0 Masthead Performance vs Targets,medium,"The dashboard 'Verity 2.0 Masthead Performance vs Targets' exhibits a high degree of data source consolidation, with all four metrics drawing from the same `subscription_targets` table in `ncau-data-newsquery-prd.cdm_reference_data`. This aligns with its initial consolidation score of 8. However, a significant anti-pattern identified is the pervasive use of hardcoded date ranges within the SQL logic for all metrics. Critically, one metric (`total_daily_target_by_publication_group_by_publication_group`) uses a different end date (`2025-06-29`) compared to the others (`2025-04-08`), introducing potential data inconsistency and maintenance overhead. The absence of any SQL query execution summary data prevents validation of live performance, query success, or actual data values, making it impossible to confirm the accuracy or completeness of the reported targets in a live environment.",232
9d62354b-6993-4829-9de4-f12bf37befab,Newsquery BAU,high,"The 'Newsquery BAU' dashboard is well-consolidated in its data source, with all three metrics deriving from the same `cloudaudit_googleapis_com_data_access_*` table and utilizing an identical BigQuery cost calculation formula. This consistency is a strong positive. However, a significant anti-pattern observed across all metrics is the repeated, hardcoded `WHERE` clause for filtering `principalEmail` based on specific user categories (e.g., 'consumer', 'verity', 'bsg'). This redundancy indicates a high priority for further consolidation and refactoring into a centralized user categorization mechanism, such as a lookup table. The `sql_execution_summary`'s `business_rules_sql` validates that these user categories are indeed present and active in the data. Additionally, one specific metric (`bq_billed_cost_quarterly_specific_bsg_user`) contains a hardcoded future date ('2025-01-01'), which limits its utility for ongoing 'Business As Usual' monitoring and should be parameterized or made dynamic.",233
4a1b4017-aa80-42f5-a2ae-1bdb57fcb135,Adsales Performance Dashboard - FY25 PDFs FINAL,high,"The initial AI analysis assigned a high consolidation score (9), however, a deeper dive into the metric definitions reveals significant opportunities for consolidation and refactoring. A pervasive anti-pattern is the repeated use of `CASE WHEN` statements across numerous 'Gross Revenue' and 'SS LGB' metrics to filter by `relative_fy_year_offset`, `relative_fy_month_offset`, and `is_future_period_flag`. This indicates a lack of centralized time-based logic. Furthermore, many metrics are simply base metrics divided by 1000 (e.g., `_k` metrics), which could be handled by presentation formatting. Critical issues were also found in dimension definitions, with most dimensions using `LIMIT 1`, severely restricting their utility. The `SQL Query Execution Summary` was empty, preventing validation of live data performance or actual usage patterns.",234
0cbe9a87-5f64-4e05-b993-a508e99ecdcd,S+C morning health report,high,"The dashboard is highly focused, featuring a single, high-criticality metric. However, the absence of SQL query execution data prevents any validation of the metric's underlying logic or performance against live data. The metric's SQL logic contains hardcoded filter values, which is an anti-pattern for maintainability and scalability, especially for a 'high' business criticality metric.",235
34cd05a8-37bb-4a61-b1f5-c782a32bffb3,BAU Dashboard,high,"The 'BAU Dashboard' demonstrates strong data source consolidation, with all metrics drawing from a single BigQuery table (`ncau-data-newsquery-prd.prstn_jira.jira_integrated_dashboard`). This is a positive indicator for maintainability and performance. However, the analysis is critically hampered by the complete absence of live SQL query execution data, preventing validation of the provided `sql_logic` against actual dashboard usage. A significant concern arises from the `LIMIT 1` clause present in the `sql_logic` for all dimension metrics, which fundamentally contradicts how dimensions are typically used in a dashboard (e.g., for filtering, grouping, or displaying multiple values). This discrepancy, coupled with hardcoded data exclusions for 'L03 Department', indicates potential data integrity or definition issues that were not captured by the initial AI analysis's '0 governance issues' report.",236
a6c0f7df-8da6-44dc-bf50-72a907020ebc,Cluster by Engagement Level & Tenure Groupings,high,"The dashboard 'Cluster by Engagement Level & Tenure Groupings' exhibits significant opportunities for consolidation and optimization. A major anti-pattern identified is the repeated, complex subquery logic across multiple core metrics, including 'Distinct Subscriptions by Cluster Name' and 'Distinct Subscribers by Cluster Name'. This repetition indicates a lack of data model consolidation or inefficient Looker Studio data source configuration, leading to potential performance issues, maintenance overhead, and inconsistency risks. Furthermore, the 'Sum of Subscription IDs by Active Days' metric is a clear data modeling anti-pattern, as summing IDs rarely provides business value and suggests an incorrect treatment of an identifier as a measurable quantity. The absence of `sql_execution_summary` data prevents validation of live query performance or results, highlighting a critical area for further investigation.",237
8ea43b00-837f-4d0f-9c52-5c5f451785ea,Switch and Reactivation - From -> To Details Extract,high,"The analysis reveals significant architectural and operational concerns for the 'Switch and Reactivation - From -> To Details Extract' dashboard. Critically, the `sql_execution_summary` is empty, meaning there is no live data to validate the dashboard's performance or accuracy, which is a high-priority investigation point. Architecturally, all 14 metrics exhibit highly redundant SQL, duplicating the same `FROM`, `JOIN`, and `WHERE` clauses. Additionally, the 'Acquisition Masthead Category' metric relies on hardcoded `CASE` statements for categorization, which is an anti-pattern for maintainability and scalability. Despite the dashboard's high consolidation score (8) in the initial AI analysis, the underlying SQL practices indicate substantial room for optimization and governance improvements.",238
e1ee24c8-128c-4276-a251-ac722571b97b,Tableau Looker and Newsfact,high,"The dashboard 'Tableau Looker and Newsfact' aims to track job execution, but its underlying SQL queries exhibit significant anti-patterns. The most critical finding is the pervasive hardcoding of date ranges and user classification logic directly within each metric's SQL, rendering the dashboard static and non-dynamic. Furthermore, an identical 'base_data' Common Table Expression (CTE) is redundantly defined across almost all metrics, leading to high maintenance overhead and potential for inconsistencies. The absence of `sql_execution_summary` data prevents live validation of these metrics, but the structural issues in the SQL itself indicate a strong need for immediate refactoring and consolidation to ensure data freshness, maintainability, and scalability.",239
6e1a98d6-289f-44d8-b6b9-c0965640412c,Occupancy Dashboard usage logs,medium,"This dashboard, focused on Looker Studio usage logs, exhibits a good base consolidation score (7/10) as indicated by the initial AI analysis, with related metrics sharing common underlying logic (e.g., `latest_usage` CTE). However, the absence of live SQL execution data prevents validation of performance or actual results. Analysis of the SQL logic reveals a hardcoded division name in one metric, which is an anti-pattern for maintainability and reusability. Additionally, the 'Month of Latest Dashboard Usage' metric's SQL logic appears ambiguous for its stated purpose, potentially returning multiple months instead of a single latest month, warranting clarification.",240
ec72cb0e-78f9-45d1-805f-4aef62ea9780,Verity 2 - PRD - SFMC Marketing Email Sends,high,"The dashboard's reported consolidation score of 9 and zero governance issues are significantly contradicted by the detailed metric analysis. A pervasive anti-pattern of extremely long, hardcoded, and *inconsistent* REGEXP filters is present across a majority of the metrics. This severely impacts maintainability, introduces potential data discrepancies, and makes future modifications highly error-prone. The presence of two distinct filtering logics (e.g., `_q1_2_5_6` vs. `_q3`) for seemingly similar 'Standard Filter' metrics is a critical governance and data integrity concern.",241
0071d646-565a-46be-b47c-e78a85d5cee7,Verity 2.0 Metro Business Network: Sunrise Report,high,"The dashboard exhibits good structural consolidation, with both metrics deriving from the same base metric ('total_daily_target') and the same source table (`subscription_targets`). However, a critical anti-pattern is the pervasive use of hardcoded future dates (July 2025) and a specific 'Metro Business' team filter within the SQL logic for both metrics. This severely limits the dashboard's dynamic utility for a 'Sunrise Report' which typically implies current or recent data. The empty SQL execution summary prevents validation of query success or data presence, highlighting a significant blind spot in the analysis.",242
c44e51ad-f0c4-4a5e-bb7c-00044deaa278,Cost to Serve Dashboard,high,"The 'Cost to Serve Dashboard' exhibits significant opportunities for consolidation and improved maintainability. A primary observation is the complete absence of live SQL execution data, which prevents validation of metric assumptions against real-world performance or results. Analysis of the detailed metric SQL reveals pervasive anti-patterns, including extensive hardcoding of fiscal months and service models across numerous metrics. This redundancy leads to metric sprawl and high maintenance overhead. Furthermore, the dashboard relies on brittle string concatenations for date filtering and uses a static 'current_fiscal_month_id' column, which may lead to stale 'future' calculations. Addressing these issues is critical for the dashboard's long-term accuracy, performance, and scalability.",243
db1deb9c-ce2b-4d07-b194-b278597339b5,Follow Button Results,high,"The dashboard's underlying SQL queries exhibit significant anti-patterns, primarily the verbatim duplication of complex CTEs across all 17 metrics. This leads to inefficient data processing, high maintenance overhead, and potential for inconsistencies. A critical issue was identified in the 'subscriber_activity' CTE, which filters data using a future date ('2025-07-29'), likely resulting in empty or incorrect data for related metrics. Furthermore, presentation-layer breakdowns are hardcoded into the SQL via UNION ALL, which should ideally be handled by Looker Studio's native dimension capabilities. Despite an initial high consolidation score, the technical debt and potential data inaccuracies warrant a high priority for consolidation and refactoring of the data model.",244
e830291d-dabb-421d-87cc-4241cc7502ad,Market Share,high,"The 'Market Share' dashboard, despite its high initial consolidation score, exhibits significant underlying data governance and maintainability issues. All calculated metrics rely on complex, hardcoded logic for date ranges, owner classifications, and media types, making them static, difficult to update, and prone to errors. The absence of live SQL execution data prevents validation of performance or actual data results. Furthermore, the use of different source tables (`smi_datasource` vs. `smi_industry_data`) for metrics derived from the same base (`gross_media_spend`) suggests potential data model inconsistencies. The initial AI analysis's '0 governance issues' is misleading given the prevalence of anti-patterns in the SQL.",245
a8fe6bb0-3cbf-4d6e-8838-fa6e6dce447f,Pacing Dashboard,high,"The 'Pacing Dashboard' is critically impacted by severe anti-patterns in its core metrics. All three high-criticality revenue metrics (`Projected Revenue`, `Revenue Net Year Ago`, `Revenue Net Month Ago`) contain hardcoded dates (specifically '2025-07-15'), rendering the dashboard non-functional for current pacing analysis. Furthermore, all four defined metrics, including the dimension, inappropriately include a `LIMIT 1` clause, which severely restricts their reusability and flexibility for any analysis beyond single-value displays. The absence of live SQL execution data prevents validation of query performance or actual data output, making it impossible to confirm if these metrics are returning any data at all, or if they are performing efficiently.",246
d4d68a71-2b12-4caf-bc6b-96fc2d18a025,Adsales Details Dashboard,high,"The 'Adsales Details Dashboard' is severely limited in its current form due to extensive hardcoding within its core dimension metrics. Both 'Sort Caption' and 'Publication Date' metrics, intended for filtering or selection, are statically defined for specific financial periods and portfolio groups. This renders the dashboard non-dynamic and non-reusable without manual SQL modifications, directly contradicting their described business purpose. The absence of SQL execution summary data prevents validation against live performance or usage patterns, highlighting a critical gap in observability for this dashboard.",247
c637fc4f-d352-4401-a60c-1c1bf7e527a9,FY24 The Weekly Times Report,high,"Despite an initial high consolidation score (8) from the AI-generated summary, a detailed review of the metric SQL reveals significant opportunities for further consolidation and improved maintainability. All metrics share identical base table (`campaign_performance_consol`) and core `WHERE` clause filters, making them ideal candidates for a common base view or CTE. Furthermore, the pervasive use of hardcoded `CASE WHEN` statements for categorizing `source_system_name` and `campaign_type` represents a major anti-pattern, indicating a need for lookup tables or more dynamic dimensional modeling. The absence of live SQL execution data prevents direct validation but highlights an immediate area for investigation into data pipeline health.",248
07de4dcd-194f-42aa-87bf-ee79996fb768,Verity 2.0 Local Last week's performance,high,"The dashboard 'Verity 2.0 Local Last week's performance' exhibits strong data source consolidation, as all metrics draw from the same `subscription_targets` table. However, the metrics themselves are highly specialized and static, defined by hardcoded date ranges and specific filtering criteria (e.g., `REGEXP_CONTAINS` for websites). This contradicts the dashboard's 'Last week's performance' name, as the dates are fixed in 2025. The initial AI's high consolidation score likely refers to data source usage rather than metric reusability or dynamic capabilities. The absence of `sql_execution_summary` prevents validation against live query performance or results, which is a critical gap in understanding the dashboard's operational health.",249
b80779c9-a393-4f32-adc1-605745ac8957,Verity 2.0 - Active Paid Closing Base - Engagement and Demographic Deep Dive - DRAFT,high,"The analysis was significantly hampered by the absence of live SQL execution data, preventing direct validation of metric assumptions against real-world query performance or results. Despite the initial AI assessment indicating a high consolidation score (7) and zero governance issues, a deeper review of the detailed metric SQL reveals pervasive hardcoding of dates, mastheads, and specific exclusion lists across multiple metrics. This severely limits the reusability and flexibility of the dashboard, making it highly specific to particular dates and business units. This contradicts the initial consolidation score and highlights significant underlying governance and maintainability challenges that were not captured by the initial AI scan. The 'DRAFT' status of the dashboard suggests an opportunity to address these issues before wider deployment.",250
a42a8045-0c60-4346-bfd2-6d2b5839ebec,Verity 2.0 NNN Weekly Performance Report,high,"The dashboard's initial AI analysis indicated a high consolidation score (8), but a deeper dive into the metric definitions reveals significant opportunities for further consolidation and improved maintainability. Specifically, two 'Daily Target' metrics are nearly identical, differing only in the specific column being summed from the same source table. A critical observation is the complete absence of `SQL Query Execution Summary` data, which prevents validation of query performance, actual data usage, or real-world consolidation benefits. Furthermore, all metrics rely on hardcoded date ranges, severely limiting the dashboard's flexibility and requiring manual updates for each new fiscal year or reporting period. The SQL structure across all metrics, characterized by deeply nested subqueries and generic column aliases, points to a potential anti-pattern in query generation or design, impacting readability and maintainability.",251
3e28affe-dc1b-43b8-b7aa-bd7cb3572084,Digital Subscriptions - Extracts,high,"The dashboard, while focused on a single business domain ('finance'), exhibits significant anti-patterns in its SQL logic, leading to a low actual consolidation score despite the initial AI's high rating. The primary issue is the pervasive use of repeated, complex, hardcoded `CASE` statements for categorizing publications and products. A critical observation is the absence of SQL execution summaries, preventing validation against live data. Furthermore, one key metric pulls from a different dataset, introducing potential data inconsistencies. The presence of 'unusual' summed metrics (`fy_week_of_year`, `fy_quarter_of_year`) suggests potential misconfiguration or placeholder logic.",252
a73d4bb7-1fbe-4686-b2f1-f401e260038c,Envision Dashboard,high,"The initial AI analysis reported a high consolidation score (9/10) and no governance issues for the 'Envision Dashboard'. However, a deeper architectural review of the detailed metric SQL reveals significant anti-patterns and critical functional bugs that contradict this assessment. Multiple metrics contain highly complex, duplicated, and hardcoded logic, indicating a severe lack of underlying data model consolidation. Most critically, several dimension metrics include a 'LIMIT 1' clause, which would prevent them from functioning correctly in Looker Studio, rendering them unusable for filtering or grouping. This suggests a fundamental misunderstanding of Looker Studio's data source configuration or a copy-paste error, leading to a high priority for consolidation and refactoring.",253
3d387428-38ed-4de6-81a0-f75f3e904118,Subscriber Linked Google Account Engagement,high,"The analysis of the dashboard's metrics reveals significant issues that prevent it from displaying current or relevant data. The `sql_execution_summary` is empty, preventing validation against live data. More critically, two out of three key metrics (`Unique Consent Subscribers (Filtered Period)` and `Unique Engaged Subscribers (Filtered Period)`) contain hardcoded date filters set to future months (May 2025 and April 2025 respectively). This means the dashboard, as currently defined by the SQL, would display no data or only future-dated projections, rendering it non-functional for current operational insights. Additionally, the `Monthly Unique Consent Subscribers` metric uses a `LIMIT 100` clause, which could arbitrarily truncate historical trend data, hindering comprehensive analysis.",254
87f8ac55-5642-48ed-a7e7-f56dffb4ff94,Core Web Vitals : Monthly Chrome UX Market Data,high,"The dashboard's stated purpose of analyzing 'Monthly Chrome UX Market Data' is fundamentally undermined by a critical anti-pattern: *all* metric SQL queries include a `LIMIT 1` clause. This means the dashboard will only ever display data from a single arbitrary row, making any aggregations or trend analysis impossible and rendering the data presented as largely meaningless for its intended business context. Furthermore, while the initial AI analysis assigned a high consolidation score (9), likely due to a single underlying data source, the detailed metric review reveals a significant code consolidation issue. The complex `CASE` statements used to derive 'Site Name' and 'Site Network/Category' are hardcoded and repeatedly duplicated across multiple metrics (`site_name`, `site_network`, `good_lcp_density_news`, `poor_inp_density_news`). This repetition creates a high maintenance burden and risk of inconsistency, indicating a strong need for a centralized lookup mechanism. The absence of SQL execution summary data prevents validation of live query performance or actual data output.",255
b167b958-958d-4085-8e39-77dec324fdfb,Verity At-A-Glance: Google Referral Trend Watch,high,"The dashboard's metrics are predominantly defined with hardcoded dates and specific dimension values (e.g., 'CM' masthead). This design choice severely limits its dynamic reporting capabilities and will inevitably lead to a proliferation of similar metrics over time, directly contradicting the initial AI's high 'consolidation score' from a dynamic reporting perspective. The absence of SQL execution summary data is a critical gap, preventing any validation against live performance or results, and making it impossible to confirm data accuracy or query efficiency.",256
c4796c36-94d3-4cbf-9762-4f2a492454bb,SVOC Customer Interaction draft analysis,high,"The dashboard's metrics are consistently built upon a single base metric ('total_interactions') and query the same underlying table, which aligns with the initial high consolidation score. However, a critical anti-pattern was identified: all metrics use a hardcoded date range ('2024-09-01' to '2024-09-07'). This severely limits the dashboard's dynamic utility and reusability for ongoing analysis, contradicting the spirit of a highly consolidated and flexible dashboard. Furthermore, the complete absence of SQL execution data prevents any validation of query performance, data consistency, or real-world data patterns, indicating a fundamental gap in data observability for this dashboard.",257
45bc0813-2c47-4f36-bcac-ed638ce69ce2,Live Dashboard,high,"The dashboard 'Live Dashboard' contains three metrics that are all variations of 'Total Video Media Starts'. While semantically related, their underlying SQL implementations are highly redundant, differing only by hardcoded date ranges and brand filters. This indicates a significant opportunity for consolidation into a single, parameterized metric, which would drastically improve maintainability and flexibility. The initial AI-generated 'consolidation_score' of 9 appears to reflect the semantic similarity of the metrics rather than the efficiency or consolidation of their technical implementation. The absence of SQL execution data prevents performance validation but highlights an area for investigation into data collection processes.",258
d8104888-c324-42d8-a9b1-c065ba1c622,NQ Cost Operation Dashboard Non-Prod,low,"The dashboard, 'NQ Cost Operation Dashboard Non-Prod', is extremely simple, containing only one metric: 'Total Cost for Dev BigQuery'. This metric is precisely defined with hardcoded filters for a specific project ('ncau-data-newsquery-dev') and service ('BigQuery'). While the metric definition and its SQL logic are consistent, the complete absence of SQL query execution data prevents any validation of live performance, data accuracy, or identification of runtime issues. Given its singular focus, the dashboard inherently achieves a high consolidation score (10) as there are no other metrics to consolidate.",259
712ca6fe-b491-4a01-af6e-1495fb3c7d12,Finance Data Checks,medium,"The 'Finance Data Checks' dashboard appears to be well-defined with a high consolidation score (5/5) and low complexity (2/5), indicating its metrics are likely focused and potentially reusable for finance data quality checks. The metrics themselves are straightforward aggregations or dimension selections from specific views, suggesting a clear purpose. However, a critical observation is the complete absence of SQL Query Execution Summary data. This prevents any live validation of the dashboard's metrics against actual query performance or results. Without this crucial information, it's impossible to confirm if the defined SQL logic accurately reflects runtime behavior, identify potential data mismatches, or assess query efficiency. Consequently, the analysis of coding practices is limited to the theoretical SQL definitions, where no immediate anti-patterns or hardcoded logic issues were identified based solely on the provided `sql_logic` strings.",260
a1b901e6-c4fb-44bc-955a-3a7070c15829,Revenue Movement,high,"The analysis of the 'Revenue Movement' dashboard reveals significant opportunities for data model consolidation and logic refactoring. While the dashboard's core metrics are identified, the absence of live SQL execution data prevents validation of query performance or data integrity. A key observation is the prevalence of complex, hardcoded `CASE` statements, particularly for revenue categorization, which indicates a need for a more robust, centralized data definition layer to improve maintainability, scalability, and data governance.",261
c9b68cfe-7e00-4414-beaf-839ae216cc14,Verity 2.0 Pulse Check - Weekly v2,high,"The dashboard, 'Verity 2.0 Pulse Check - Weekly v2', is highly focused with only one identified metric. A significant observation is the complete absence of SQL query execution summary data, which prevents validation of the metric's live performance or data consistency. The primary metric, 'Verity User Entries by Role and Masthead', relies heavily on hardcoded business logic within its SQL definition, specifically for mapping 'VerityUsageMasthead' to 'Masthead_ID'. This anti-pattern indicates a high priority for refactoring to improve maintainability, scalability, and data governance, aligning with a need for internal logic consolidation rather than dashboard-level consolidation.",262
ef665693-433c-4236-8c1f-77174b969b2c,Audience Insights - Closing Base,high,"The 'Audience Insights - Closing Base' dashboard, while initially assessed with a high consolidation score, presents significant opportunities for improvement in its underlying SQL logic. A critical observation is the extensive hardcoded `CASE` statement used for audience segmentation, which is an anti-pattern for maintainability and scalability. Furthermore, the absence of `sql_execution_summary` data prevents validation of query performance and actual data output, necessitating further investigation into the data pipeline and query execution environment. The dashboard's reliance on hardcoded date ranges within the SQL also limits its dynamic reusability.",263
a731f74e-c559-426f-aec8-f601f87cb69,Verity 2.0 Herald Sun: Sunrise Report (Click here to access the full report),high,"The dashboard, 'Verity 2.0 Herald Sun: Sunrise Report', exhibits significant opportunities for consolidation and refactoring, particularly concerning its core article scoring logic. While the dashboard's complexity score is 8, indicating intricate calculations, the detailed metric analysis reveals severe anti-patterns of repeated, nested, and hardcoded SQL logic across multiple metrics (`Calculated Article Score Value`, `Article Score Level`, `Article Scored Status`). This design choice drastically increases maintenance burden, reduces reusability, and could impact query performance. The absence of live SQL execution data (`sql_execution_summary` is empty) prevents validation of these observations against actual runtime behavior or performance metrics, making the identified architectural issues even more critical to address proactively.",264
0c50ad01-a1a6-49a6-895f-4c2002a12173,Retentions Dashboard version 1.0,high,"The 'Retentions Dashboard version 1.0' is reported with a high consolidation score (8), yet a detailed review of its 11 metrics reveals a significant anti-pattern: extensive hardcoding of dates and specific filters (e.g., 'The Australian' masthead). This practice severely limits the reusability and dynamic capabilities of the dashboard, contradicting the reported consolidation score and necessitating frequent manual updates. The core logic for various cancellation counts is repeated across multiple metrics, differing only by hardcoded date ranges or masthead filters. Furthermore, the `sql_execution_summary` was empty, preventing validation of live query performance or actual data values against the defined metrics. This lack of live data insight is a critical gap for a comprehensive analysis.",265
28a297fc-7185-4ac9-9003-0c6cd0b48a5c,Leaderboard - Video & Tubi,high,"The dashboard, while focused on advertising revenue, exhibits significant opportunities for consolidation and improved coding practices. A critical observation is the presence of a future-dated filter ('2025-08-01') in a key revenue metric, which would cause it to return zero for all current/past data. Furthermore, despite the initial analysis reporting '0 governance issues', a detailed review of the SQL logic reveals extensive hardcoding and repeated complex WHERE clauses across multiple metrics, indicating a high need for refactoring and centralized logic. The absence of live SQL execution data prevents validation of current metric outputs, but the static code review highlights several potential data anomalies and anti-patterns that could lead to inaccurate or unmaintainable results. The 'Sum of Financial Months' metric's business utility is also questionable, as noted in its own description.",266
dd095fe1-af0e-477f-955d-ec2d58af2b80,Lifestyle monthly snapshot - IPSOS,high,"The 'Lifestyle monthly snapshot - IPSOS' dashboard, despite its name implying dynamic monthly updates, is fundamentally built upon highly static and hardcoded SQL queries. Each of the 12 metrics explicitly defines specific dates (e.g., April 2025, August 11 2025) and dimensional filters (e.g., Category='News', Device='Smartphone'). This design necessitates manual updates for every reporting period and for each new segment, severely impacting maintainability and scalability. The initial AI analysis's high consolidation score (9) appears to be based on all metrics sourcing from the same table, but it fails to capture the severe lack of consolidation in the *implementation logic*. The absence of SQL execution data prevents any validation of live performance or data integrity, making it an immediate area for investigation.",267
83a1c0b2-67b2-4d3e-8bc4-98a9f3683ad1,CVR Source Code,high,"The analysis of the 'CVR Source Code' dashboard reveals significant opportunities for improvement in data governance and SQL coding practices, despite the initial AI analysis reporting zero governance issues. The most critical observation is the complete absence of `sql_execution_summary` data, which prevents validation of metric assumptions against live query performance or results. However, a review of the detailed metric SQL logic uncovers several anti-patterns: notably, hardcoded date ranges and channel lists in a key aggregated metric, and the pervasive use of `LIMIT 10` on dimension and aggregation queries, which can lead to incomplete data representation. These issues indicate a high priority for refactoring to improve flexibility, maintainability, and data accuracy.",268
35b59adf-a1d7-4673-ad92-77cf87d13b7d,Engagement: Abandoned Cart Lead Nurture Program Performance,high,"The dashboard exhibits a significant consolidation anti-pattern with four out of five metrics being duplicates that only differ by hardcoded date ranges. This leads to metric proliferation and increased maintenance overhead. The initial AI's consolidation score of 7 appears optimistic given this observation. Furthermore, the lack of SQL execution data prevents validation of query performance or actual results, making it an area for immediate investigation. The relevance of the 'Subscription' and 'Newsletter' metrics to an 'Abandoned Cart Lead Nurture Program' also requires clarification.",269
38809f41-7138-4b94-94d1-ae919b2d9517,Adpoint Line Items for Financial Accounting V2,high,"The dashboard 'Adpoint Line Items for Financial Accounting V2' operates within the finance domain, drawing all its metrics from a single source table (`v_adsales_revenue_client`). While the initial AI analysis reports a high consolidation score (7), a deeper dive into the metric SQL reveals significant anti-patterns related to hardcoded and repeated filtering logic across multiple metrics. This suggests a conceptual consolidation (single data source) but a lack of technical consolidation (code reusability). The absence of `sql_execution_summary` data prevents validation against live performance, making it a critical area for immediate investigation. The pervasive `LIMIT 10` clause in all provided SQL queries is highly unusual for a production dashboard and requires urgent clarification.",270
6de90f2a-b3f3-46fe-a4fe-13474b2d6618,PACMAN AND EXCLUDE LOD,high,"The dashboard 'PACMAN AND EXCLUDE LOD' exhibits a strong foundation for data consolidation, with all identified metrics sourcing from a single BigQuery table (`ncau-data-newsquery-prd.sbx_fda_corefin.dv_pacman_running_expense`). This centralized data source is a key strength, aligning with the high consolidation score (9) from the initial AI analysis. However, the absence of live SQL execution data (`sql_execution_summary` is empty) critically limits the ability to validate the performance, accuracy, and real-world behavior of these metrics. A significant anti-pattern identified is the repetitive use of hardcoded `CASE` statements across multiple 'Running Expense' metrics, which, while functional, introduces redundancy and maintenance overhead. Addressing these coding practices would further enhance the dashboard's long-term maintainability and scalability, building upon its already consolidated data model.",271
e6d054c7-c65a-442d-b2a7-4afd6e4884da,Content owned vs sourced report,high,"The dashboard's primary analysis query failed due to missing parameters, indicating a critical setup issue. A significant anti-pattern is the pervasive hardcoding and duplication of a large `SourceDomainMapping` array and complex attribution logic across multiple metrics, leading to high maintenance overhead and potential inconsistencies. Furthermore, the 'Total Articles Published (Overall)' metric's SQL appears to only count syndicated articles, directly contradicting its business description, and contains a suspicious `LIMIT 1` clause. Despite a high reported consolidation score, the underlying SQL reveals significant opportunities for code consolidation and refactoring, and critical data quality issues (future dates) were observed.",272
2a7c146f-7170-4d91-8508-f0a5d2e55e7c,On platform Winback reporting,high,"The 'On platform Winback reporting' dashboard, despite its high initial complexity and consolidation scores, exhibits significant anti-patterns in its SQL logic. A primary concern is the pervasive use of hardcoded date ranges, often extending into the future, and critically, these ranges are inconsistent across related metrics (e.g., `data_as_of_date` vs. `report_date`). Furthermore, the dashboard heavily relies on complex, hardcoded `REGEXP_CONTAINS` clauses for classifying 'winback' related email and SMS activities, which severely impacts maintainability and scalability. The absence of live SQL execution data prevents validation of these assumptions against real-world query performance or data completeness, highlighting a critical gap in the analysis process.",273
c8a235fc-4d8d-4b33-9f7f-813c0effdf36,Subscription Snapshot Load Precheck,high,"The 'Subscription Snapshot Load Precheck' dashboard serves a critical operational function by monitoring the freshness of various data sources. While the dashboard's high consolidation score (8) suggests a degree of reusability in its base metrics, a deeper analysis of the underlying SQL reveals significant anti-patterns. Specifically, the repeated hardcoding of `source_entity_name` filters for the `sdm_profisee.profisee_data` table and the overly complex `UNION ALL` structure for `cdm_profisee.offplatform_volume_rates` indicate a high potential for maintenance overhead and inefficiency. The absence of live SQL execution data prevents validation of these metrics' performance or actual output, making the identified coding practices a high priority for review and potential refactoring to improve maintainability and efficiency.",274
aca2f032-b796-49a2-89fe-781ca947aa33,Circulation Performance Dashboard,high,"The 'Circulation Performance Dashboard' is currently non-functional as all its core metrics fail due to a fundamental SQL error related to missing columns (`l04_publication_code`, `l06_publication_code`) in the primary fact table. Beyond this critical issue, the dashboard exhibits significant anti-patterns, including extensive hardcoding of fiscal periods and publication groupings via complex, unmaintainable CASE statements. This hardcoding not only renders the dashboard static and quickly outdated but also indicates a lack of proper dimension modeling, leading to potential data inaccuracies and high maintenance overhead. Furthermore, there's a potential mismatch between the fiscal year data the dashboard expects (FY2025) and the data available in the underlying tables (FY2026), suggesting a need for immediate updates or dynamic period handling.",275
cf86d117-5f64-4598-bb01-814b58006415,Interim Adsales Performance Dashboard for FY26 - PDFs,high,"The dashboard, despite its high complexity and initial consolidation score, exhibits significant opportunities for improvement in its underlying metric definitions. A critical observation is the pervasive use of hardcoded dates and lists within the SQL logic, which severely impacts maintainability and data accuracy over time. The absence of `sql_execution_summary` data prevents any validation of these metrics against live query performance or actual data consistency, leaving a crucial gap in understanding the real-world impact of these anti-patterns.",276
48a09c73-18f8-4e25-a22f-61398f34ab2a,Verity 2.0: NSN Weekly Subs - NRL,high,"The 'Verity 2.0: NSN Weekly Subs - NRL' dashboard, despite an initial high consolidation score, is critically impacted by hardcoded date ranges within all its metrics' SQL logic. This renders the dashboard static and unable to display current or dynamic data, fundamentally undermining its utility for 'Weekly Subs' analysis. The absence of SQL execution summary data prevents validation of query performance or results, highlighting a critical gap in monitoring capabilities.",277
42b711d5-6567-46b6-bf11-0f33e66e297e,Elton's alert dashboard - TEST,high,"The dashboard's metrics, while logically grouped (Adds, Cancels, Net Activity), are severely constrained by hardcoded date and categorical filter values ('2025-05-04', 'Standard Paid', 'Non-Print', 'CM' masthead). This static nature significantly limits the dashboard's reusability, scalability, and ability to provide dynamic insights for different time periods or segments. The absence of any SQL execution summary data is a critical observation, preventing validation of the metric definitions against live performance or potential data discrepancies, and indicating an immediate need for investigation into data collection processes.",278
41f3dfc4-db10-4e4a-9627-1261e9286fd0,Verity 2.0 Daily C-Score report: TABN,medium,"The dashboard, 'Verity 2.0 Daily C-Score report: TABN', exhibits a high consolidation score (6), with all defined metrics and dimensions sourcing from a single table (`cdm_reference_data.cscore_targets`). This indicates a well-structured data foundation. However, a critical gap in the analysis is the complete absence of SQL query execution summary data, which prevents any validation of the dashboard's live performance, query success rates, or actual data returned. Furthermore, a significant anti-pattern observed in the `sql_logic` for several metrics and dimensions is the pervasive use of `LIMIT` clauses. This practice, particularly for dimensions like 'Publication Group' and 'Week Ending Date', severely truncates the data presented to users, potentially leading to incomplete or misleading insights. The 'C-Score Target (Raw)' metric also uses a `LIMIT 1`, which is unusual for a 'raw' measure and could misrepresent the underlying data.",279
cbd888c3-e42d-4740-9dc4-2b1d774b85c6,Verity 2.0 SA Automated Scorecard,high,"The initial AI analysis assigned a high consolidation score (8), but a detailed review of the metrics reveals significant anti-patterns. Specifically, there are three distinct GA4 event count metrics that differ only by hardcoded date ranges, indicating a lack of dynamic date filtering. Furthermore, three separate metrics are defined to count records from the *exact same* reference table with identical SQL logic. This suggests a high degree of metric duplication and poor consolidation practices, directly contradicting the initial assessment and pointing to a need for immediate refactoring to improve maintainability and efficiency.",280
db85d1ac-5987-469f-978a-5334af29f7aa,CodeLite Dashboard,medium,"The 'CodeLite Dashboard' demonstrates a clear separation of concerns, focusing on two distinct business areas: subscription movements and newsletter activity. Each area primarily leverages a single source table (`subscription_movement` and `newsletter_activity` respectively), which is a positive indicator for data consolidation at the source level. The dashboard's initial consolidation score of 8 suggests a well-structured approach. However, the absence of live SQL execution data prevents validation of actual query performance or data integrity. The hardcoded 'acquisition' filter for subscription metrics, while specific to the current metric definition, suggests a potential area for future data model consolidation if broader subscription movement analysis (e.g., churn, renewal) becomes necessary.",281
2cdcf36b-a99b-4beb-88a6-a28d238f6c1f,DOM - cancels by refferer by month,high,"The dashboard 'DOM - cancels by refferer by month' exhibits a strong structural consolidation, with all metrics sourcing from a single BigQuery table (`consumer_churn_model_daily`) and effectively leveraging base metrics (e.g., `total_records`, `pcsid_occurrence_count`) for derived aggregations. This aligns with its high initial consolidation score (6). However, a critical governance issue was identified: one key metric (`pcsid_occurrence_count_by_referrer_filtered_cancel_date`) contains a hardcoded date filter (December 2024). This directly contradicts the dashboard's stated purpose of showing monthly trends and renders the data static and potentially misleading for ongoing analysis. The initial AI analysis reported 0 governance issues, which is disproven by this finding. The absence of `sql_execution_summary` data prevents validation of query performance or actual data values, limiting the depth of this analysis.",282
7bf93024-7b75-4803-be97-60132f017c00,Wagering Report,high,"The 'Wagering Report' dashboard, despite an initial AI assessment of '0 governance issues', exhibits numerous critical anti-patterns and hardcoded logic within its 33 metrics. The most significant observation is the pervasive use of `LIMIT 1` or `LIMIT 10` clauses across almost all metric SQL definitions, which, if executed literally, would severely compromise the accuracy and completeness of aggregated dashboard data. Furthermore, the extensive use of `CASE` statements to categorize data (e.g., by source system or acquisition channel) indicates a strong need for proper dimension modeling and lookup tables. The absence of live SQL execution data (`sql_execution_summary` is empty) prevents direct validation of these issues in a live environment, but the documented SQL logic points to a high maintenance burden, potential for data inconsistencies, and a significant opportunity for consolidation and refactoring.",283
7ab2395e-d246-4e16-b376-dd763ecefecb,Verity 2.0 Weekly DT reporter pack,high,"The analysis of the 'Verity 2.0 Weekly DT reporter pack' dashboard reveals critical data integrity and maintainability issues. Most notably, all metrics, including those intended to show 'Total Events' and 'Total Verity Users', are capped by a `LIMIT 100` clause, which will lead to severely understated and incorrect aggregate values. Furthermore, several 'Total Events' metrics rely on hardcoded date ranges, making the dashboard static and requiring manual updates for each reporting period. The absence of `sql_execution_summary` data prevents validation of query performance or actual data returned, but the identified SQL anti-patterns are significant enough to warrant immediate attention. The dashboard's high consolidation score (9) is undermined by these fundamental implementation flaws.",284
2adc554c-f88a-4f22-8e40-0a3bafc68994,project_habit_newsletters,medium,"The dashboard's metrics are conceptually well-consolidated, all deriving from a 'unique subscribers' base and operating on the same source table (`project_habit_newsletters`). This aligns with the initial high consolidation score (8). However, the critical absence of live SQL execution data prevents any real-world validation of these metrics or their performance. A significant anti-pattern identified is the hardcoded list of 'masthead' values in one of the key metrics, which introduces maintenance overhead and limits the dashboard's adaptability. This suggests an opportunity for improved data modeling and governance, despite the dashboard's current structural consolidation.",285
abb028b6-2752-4264-a22b-0b0810340515,Consumer Loyalty Dashboard,high,"The 'Consumer Loyalty Dashboard' exhibits significant opportunities for consolidation and refactoring, despite an initial AI-generated consolidation score of 7. The detailed metric analysis reveals critical anti-patterns, including hardcoded date filters, duplicated complex `CASE` statements for business logic (Loyalty Score, Churn Score), and an overly convoluted `UNION ALL` structure in its most critical metric. The reported '0 governance issues' by the initial AI analysis is a major discrepancy, indicating a gap in the automated governance detection. The absence of SQL execution summary data further limits real-time validation, necessitating deeper investigation into the dashboard's underlying data pipeline and logic.",286
ba78bbd6-7358-4088-b37a-23c1dd22fb28,Verity 2.0 Courier Mail : Sunrise Report (Click here to access the full report),high,"The dashboard exhibits significant opportunities for consolidation and refactoring due to highly repetitive and hardcoded SQL logic across all metrics. The same complex filtering conditions and core calculation for 'Article Value Score' are duplicated in each metric's SQL. Furthermore, the hardcoded date '20250813' makes the dashboard static and unsuitable for a 'Sunrise Report' which implies daily or recent data. The absence of `sql_execution_summary` prevents live data validation, but the structural issues in the provided SQL are clear anti-patterns. The `LIMIT 1` clause in two dimension-like metrics (`article_value_category` and `article_scored_status`) is highly suspicious and suggests these metrics may not be functioning as intended for aggregation or grouping.",287
da5dcd47-2e80-45e8-94b8-5b71d81182f5,Failed Payment Dashboard - Prod v1.0,medium,"The dashboard's two metrics, while distinct in their output, share a common underlying data source (`fp_all_trans`) and a significant portion of their SQL logic (the `driver` CTE for identifying latest transaction attempts within 60 days). This indicates a good foundation for consolidation, aligning with the initial AI's high consolidation score (9). However, the second metric introduces hardcoded logic for excluding specific payment gateways, which poses a maintenance risk. Crucially, the absence of `sql_execution_summary` prevents any validation of live data performance, query execution success, or actual data consistency, making it impossible to confirm the dashboard's real-world operational status or identify performance bottlenecks.",288
ae3044ce-064d-4d74-90fc-2cf45afa04ee,Verity 2.0 - Collection History - Network Audience,medium,"The dashboard, 'Verity 2.0 - Collection History - Network Audience', exhibits a high degree of consolidation (score 9) around a single `content_id`. All three defined metrics (`Content Reference ID`, `Adjusted Ingest Date`, `Content ID (Filtered)`) consistently query the same `capi_collection` table and apply an identical hardcoded filter for `content_id = 'da836743742cbf2daadbbe4a0ca6f530'`. While this ensures data consistency for the specific content item, it severely limits the dashboard's reusability for analyzing other content without manual SQL modifications. A critical observation is the complete absence of SQL query execution summary data, which prevents any validation of query performance, actual data retrieval, or identification of runtime issues. This lack of live data insight hinders a comprehensive assessment of the dashboard's operational efficiency and data integrity.",289
51c14ec4-1d06-4dcc-9dad-6ff771fa2534,Digital Inventory Report,high,"The dashboard exhibits strong data source consolidation, with all metrics drawing from a single BigQuery table (`ncau-data-newsquery-prd.asl_advertising.adsales_revenue_pricing`). However, there is a significant lack of *logical* consolidation within the metric definitions. Complex business logic, such as financial year calculations and 'Sold' status categorization, is repeatedly hardcoded across multiple metrics. This anti-pattern increases maintenance overhead, introduces potential for inconsistencies, and hinders reusability, despite the underlying data being consolidated. The absence of SQL execution data prevents validation of performance or actual data values.",290
57a6a6b6-710d-4258-968d-35ab9a7704e5,Verity 2.0 Gold Coast Bulletin : Sunrise Report (Click here to access the full report),high,"The dashboard 'Verity 2.0 Gold Coast Bulletin : Sunrise Report' exhibits a critical anti-pattern in its metric definition, despite a high reported consolidation score. All three 'Total C-Score Target' metrics are fundamentally the same calculation, differentiated only by hardcoded weekly date ranges within their SQL queries. This indicates a significant lack of dynamic date filtering or parameterization, leading to redundant metric definitions and poor scalability. The absence of any SQL execution summary data prevents validation of live query performance or results, necessitating immediate investigation into data retrieval mechanisms for this analysis.",291
eda51dbb-3cc6-46c2-b1f7-8189b682760a,VERITY AT A GLANCE - [QLD REGIONAL WEEKLYVIEW ] Verity 2.0 - Prod - At-a-Glance,high,"The dashboard's primary metrics, 'Total Website Target' for different weeks, are implemented with hardcoded date ranges directly within their SQL definitions. This design choice, while functional, represents a significant anti-pattern that leads to code duplication and a lack of flexibility, contradicting the initial AI's high consolidation score (9) which likely only considered the base metric name. Each new reporting week necessitates the creation of a new, near-identical metric. A critical observation is the complete absence of SQL query execution summary data, which prevents any validation of these metrics against live performance, query costs, or actual data results. This lack of observability is a major impediment to understanding the dashboard's operational health and efficiency.",292
705edcb5-737a-4600-b1a7-11870177f97a,Programmatic Impact Reporting,high,"The dashboard, 'Programmatic Impact Reporting', exhibits a high degree of potential for metric consolidation. All three defined metrics are dimensions, sourced from the identical BigQuery table (`v_adsales_revenue_client`), and share a significant portion of their filtering logic (e.g., excluding 'Medium Rare Content Agency', filtering by 'Billed' or 'Booked' status). The primary differences lie in hardcoded year values (2024 vs. 2025), specific revenue types/systems, and a highly specific data load datetime. This pattern suggests that multiple distinct metrics have been created where a single, parameterized metric could serve the same purpose, significantly improving maintainability and reducing redundancy. The absence of SQL execution summary data prevents validation of query performance or actual data output, leaving an area for further investigation.",293
781e9cc0-5786-4221-94f2-e8e5691588a5,Code Postcodes,high,"The 'Code Postcodes' dashboard exhibits significant opportunities for consolidation due to pervasive hardcoding and repetitive SQL logic. Multiple metrics are essentially variations of a base metric, differentiated only by hardcoded dates, mastheads, customer types, and especially postcode prefixes. The pattern of creating distinct metrics for each postcode prefix (e.g., '2%', '3%', '4%') using `STARTS_WITH` clauses is a prime anti-pattern. While the initial AI analysis reported a high consolidation score (8), this appears to refer to the metrics drawing from a single table (`subscriber_base_agg`), rather than the efficiency and maintainability of the metric definitions themselves. The absence of live SQL execution data prevents validation of query performance or actual results, but the static SQL logic itself clearly indicates a need for refactoring towards dynamic parameterization and a more robust data model.",294
be4575e4-3850-46e2-9ba9-73a4393c5d2a,Finance - unearned revenue (dev),high,"The dashboard 'Finance - unearned revenue (dev)' is flagged with a high complexity (8) and consolidation score (9) by the initial AI analysis. However, a deep dive into the SQL logic reveals significant anti-patterns, primarily the pervasive use of hardcoded dates and repeated calculation logic across multiple metrics. This directly contradicts the high consolidation score, indicating that the dashboard is highly static and not truly consolidated in terms of dynamic data retrieval or code reusability. The empty `sql_execution_summary` prevents validation against live data, but the static nature of the queries suggests that the dashboard would only display data for specific, fixed historical periods, rendering it unsuitable for ongoing or dynamic financial reporting without manual SQL modifications. The 'dev' suffix might explain some of these issues, but they represent critical areas for improvement before production deployment.",295
cdf7be2f-dfa9-481b-9f1b-21e4941bb103,FY24 Metros Report,high,"The 'FY24 Metros Report' dashboard, despite a high initial consolidation score, exhibits significant opportunities for further data model consolidation and SQL optimization. A primary observation is the complete absence of live SQL execution data, which prevents direct validation of metric assumptions against real-world performance. However, a deep dive into the detailed metric SQL reveals pervasive anti-patterns: identical, complex `WHERE` clauses are hardcoded across numerous acquisition metrics, and extensive `CASE WHEN` statements are used for categorizing channels and sources. This indicates a strong need for a more robust, centralized data model, potentially leveraging a semantic layer or well-defined views, to improve maintainability, reduce redundancy, and enhance data governance. The dashboard also pulls data from different GCP environments (production vs. staging) for related business domains, which warrants investigation.",296
b815ae9f-506c-40f8-b23d-8c42d6ebe90a,States & Communities Report Marketing,high,"The 'States & Communities Report Marketing' dashboard exhibits a high degree of complexity and a strong need for consolidation. Multiple core acquisition metrics are derived from the same base table (`subscription_base_movement_agg_snap`) using distinct `CASE` statements for channel categorization, but share identical, hardcoded `WHERE` clauses. Similarly, campaign metrics (`campaign_performance_fct`) and subscriber metrics (`t_subscription_details_snapshot_summary`) also show repetitive filtering logic. A significant anti-pattern observed is the pervasive use of complex, nested `CASE` statements within calculated fields (e.g., `product_group_dimension`, `campaign_code_dimension`, `article_section_dimension`) for categorization, which are brittle, difficult to maintain, and indicate a strong need for dedicated lookup tables. The absence of SQL execution summary data prevents validation of live query performance or success, making it an immediate area for investigation.",297
5e816a83-a077-4fdb-9b1f-bdaf0d527a62,Editorial AI - data discovery,high,"The dashboard 'Editorial AI - data discovery' aims to track critical AI article processing metrics. While the initial AI summary reports a high consolidation score (8) and zero governance issues, a deeper analysis of the underlying SQL reveals a critical flaw: all metrics are filtered by a hardcoded future date ('2025-07-01'). This renders the dashboard non-functional for current data, directly contradicting the reported governance status. Furthermore, the SQL exhibits significant repetition of complex Common Table Expressions (CTEs) across all metrics, indicating a lack of underlying data model consolidation and potential performance inefficiencies. The hardcoded event types also limit flexibility. The dashboard's logical consolidation of metrics is good, but its technical implementation is severely flawed and inefficient.",298
4bd7954c-5a94-4fb6-92e1-ed152b1cf7b3,Copy of Interim Adsales Performance Dashboard for FY26,medium,"The dashboard's low consolidation score (2) is primarily driven by the 'Publication Category (Sundry/Non-Sundry)' dimension, which relies on a hardcoded list of values within a CASE statement. This anti-pattern presents a clear opportunity for consolidation into a governed lookup table, improving maintainability and data consistency. A critical observation is the absence of live SQL execution data, which prevents validation of metric logic against real-world query performance or results, necessitating further investigation into data retrieval mechanisms.",299
0823e425-5885-4fd6-b89e-5c9508f3cf1d,Verity 2.0 - Prod - PRSTN - Article Summary,high,"The dashboard, despite its reported high consolidation score (10) and low complexity (1), relies on a single, high-criticality metric ('Total Subscription Targets by Financial Year') that contains a hardcoded date filter for January 2025. This significantly limits its utility and contradicts the broader date ranges observed in the underlying data (`structure_sql` shows data from 2020-2026) and the `primary_analysis_sql` sample data (showing June 2025 dates). This suggests a critical mismatch between the metric's definition and the dashboard's potential for dynamic, comprehensive reporting, or indicates a very specific, static purpose for this dashboard that isn't immediately apparent from its name.",300
703f95f0-c89e-43cb-b26f-f479b7065be,FY26 Video Dashboard (Julie),high,"The dashboard demonstrates a foundational level of consolidation by utilizing a consistent base CTE (`base_adsales_revenue`) across all metrics, ensuring a unified data source and initial filtering logic. However, the initial AI analysis's claim of '0 governance issues' is contradicted by a deeper dive into the SQL. Multiple metrics exhibit significant anti-patterns, specifically extensive and duplicated hardcoded `CASE` statements for data mapping and complex `STRPOS`/`NOT IN` clauses for exclusions. These patterns indicate a high priority for refactoring to improve maintainability, scalability, and data governance. The absence of SQL execution summary data prevents a performance-based validation of these observations, limiting the analysis to code structure and best practices.",301
4d5e906e-84b0-4825-ad1f-ebaf86acd462,Audience Insights - Cancels Performance - DRAFT,high,"The dashboard 'Audience Insights - Cancels Performance - DRAFT' exhibits a strong foundation for consolidation, with all metrics deriving from a common base metric ('total_subscriber_movements') and a single source table (`subscriber_cancels`). This is reflected in its high initial consolidation score of 9. However, a deeper analysis reveals significant anti-patterns in the implementation of specific metrics, primarily the pervasive use of hardcoded date ranges and complex, hardcoded business logic for masthead classification and referrer filtering. The absence of SQL execution summary data prevents validation against live results, but the identified hardcoding issues severely limit the dashboard's dynamism, reusability, and maintainability, making it unsuitable for ongoing, self-service analysis without significant manual intervention. Addressing these hardcoding issues is a high priority to realize the full benefits of the underlying consolidated data model.",302
61cc5171-703d-44b5-acd7-e9db7cf81778,Commercial Finance Scorecards,high,"The 'Commercial Finance Scorecards' dashboard, while focused on SuperCoach Plus, exhibits significant anti-patterns in its metric definitions. The most critical finding is the pervasive use of hardcoded dates and complex, inefficient subqueries within calculated fields for date filtering, which will lead to rapid obsolescence and high maintenance overhead. Additionally, the repeated hardcoded 'masthead = 'SC'' filter across numerous financial metrics indicates a lack of parameterization or a need for a more flexible data model. The initial analysis's 'total_governance_issues: 0' is contradicted by these findings, highlighting the need for deeper architectural review. The absence of SQL execution summary data prevents validation against live performance, but the static SQL logic itself reveals substantial areas for improvement.",303
c32d96e5-38f4-48a8-9b70-3d89a83f03aa,Circulation Insights,medium,"The 'Circulation Insights' dashboard, while having a high initial consolidation score (8), presents significant opportunities for further consolidation and improved maintainability. All three metrics derive from the same base table (`v_asl_circulation_dq_check`) and perform a simple `SUM(amount)`. The primary differences lie in highly specific and hardcoded `WHERE` clauses for fiscal years, weeks, and revenue types. This pattern suggests that these three distinct metrics could potentially be consolidated into a single, more dynamic metric utilizing dashboard parameters or a configuration table for filtering, thereby reducing redundancy and simplifying future updates. The business description also mentions a 'dashboard parameter' for amount/volume, which is not reflected in the provided SQL, indicating a potential disconnect or a specific snapshot of the SQL.",304
4d991729-7225-4b31-bb6c-1f06ceceeb9a,Verity 2.0 - TAUS Health Last Week,high,"The dashboard 'Verity 2.0 - TAUS Health Last Week' contains three metrics, two of which (`Total Health Registrations (Wide Date Range)` and `Health Registrations by Source, Article, and Date (Weekly)`) query the same base table (`t_registration_details_snapshot_summary`) and apply identical hardcoded filters for 'The Australian' website and 'Health' topics. This indicates a strong opportunity for consolidation into a more generalized and parameterized registration metric. The third metric, `Subscription Targets Count (Weekly)`, operates on a different dataset and business concept, making it less directly consolidatable with the registration metrics. A significant observation is the absence of `SQL Query Execution Summary` data, which prevents direct validation of metric performance or identification of data mismatches from live execution. This necessitates framing findings as observations based on the provided SQL logic. The presence of complex hardcoded logic for derived fields (e.g., social referrer grouping, article display string) further highlights the need for a more consolidated and governed data model, potentially leveraging lookup tables or upstream transformations to improve maintainability and reusability.",305
744cc917-29e9-4af7-b811-3043e3ced208,MGR BIOps,high,"The initial AI analysis indicates a high consolidation score (9), suggesting well-defined and reusable metrics. However, a deeper dive into the detailed metric SQL reveals a significant anti-pattern: all metrics are heavily hardcoded for a specific month (July 2024) and a specific list of BI team members. This directly contradicts the notion of high consolidation and reusability, making the dashboard static and requiring manual updates for ongoing use. The empty `sql_execution_summary` prevents validation against live data, highlighting a critical area for investigation into data accessibility or query execution.",306
6596264e-ca48-4ca6-8871-77d1e0d29b28,Verity 2.0 NSN LAST WEEK,medium,"The dashboard 'Verity 2.0 NSN LAST WEEK' is reported to have a high consolidation score (5/5) with only two metrics. However, the provided SQL Query Execution Summary is empty, preventing validation of live data performance or consistency. A critical observation is the hardcoded date range within the 'GA4 Page View Events by User Name' metric's SQL logic, which directly contradicts the dashboard's 'LAST WEEK' naming convention and severely limits its utility for dynamic reporting. This hardcoding necessitates immediate attention to ensure the dashboard provides current and relevant data.",307
a1000c87-d7d3-44f6-8edb-b27930b363f8,Pagination Dashboard,high,"The initial AI analysis reports a high consolidation score, likely due to all 19 metrics sourcing from a single BigQuery table (`pagination_combined`). However, a detailed review of the `sql_logic` for each metric reveals significant de-consolidation at the metric definition level. The dashboard suffers from pervasive anti-patterns, including repeated, complex hardcoded `CASE` statements and extensive `IN`/`REGEXP_CONTAINS` clauses for filtering publication details and classifying regions. This approach leads to severe maintenance overhead, potential for data inconsistencies, and a lack of scalability, as evidenced by the creation of distinct metrics for different fiscal years (2025 vs. 2026) and regions (Metros, Regionals, All). The current implementation, while using a single data source, is highly inefficient and brittle from a code governance perspective.",308
19891283-911c-4528-b830-c99e4cb76155,Verity 2.0 Daily C-Score report: DT,medium,"The dashboard is highly focused, tracking a single, high-criticality KPI ('Total C-Score Target'). The AI summary accurately describes this metric, and its business description aligns with the detailed metric data. However, a significant observation is the hardcoded date range within the metric's SQL definition. This anti-pattern limits the metric's reusability and flexibility, suggesting a need for parameterization. The absence of SQL execution summary data prevents validation of live query performance or actual data patterns, making it difficult to assess real-world usage or identify further optimizations.",309
4c177d0d-6534-4cff-a966-31c6df560a99,Monthly News Event Traffic,high,"The initial AI analysis indicated a high consolidation score (8), suggesting good reusability of metrics. However, a detailed review of the metric definitions reveals a significant anti-pattern: all metrics are highly duplicated with hardcoded dates and specific filter values ('Donald Trump' topic, 'newscomau' brand exclusion). This directly contradicts the notion of high consolidation at the logic level and indicates a high maintenance burden. The dashboard, despite its name 'Monthly News Event Traffic', is static for specific months (March 2025, July 2025) and specific events, requiring manual updates for each new reporting period or event. The empty `sql_execution_summary` prevents validation against live query performance or actual data values, but the structural issues are evident.",310
1b9efa96-31e0-4a43-9f74-c5d0da8c5e42,Genome - The Advertiser enagement,high,"The analysis of 'Genome - The Advertiser enagement' dashboard is significantly hampered by the absence of live SQL execution data, preventing direct validation of metric outputs. However, a detailed review of the SQL logic for all three high-criticality metrics reveals consistent and pervasive anti-patterns: hardcoded report dates and extensive use of `STRPOS` for filtering categorical dimensions. This indicates a high risk of data staleness, maintenance burden, and potential for inconsistencies if the underlying data or business rules change. The duplication of filtering logic across multiple metrics also suggests a lack of reusability and potential for consolidation, warranting a high consolidation priority.",311
52c11c9c-052a-4e45-9cda-8fecd87d7964,Team Sales Performance - FY26 (Interim)(with Pluto Reporting Date),high,"The dashboard exhibits significant opportunities for consolidation and refactoring. A major anti-pattern is the verbatim duplication of a complex Common Table Expression (CTE2) across numerous daily metrics, leading to redundant code and increased maintenance burden. Furthermore, several metrics rely on extensive hardcoded CASE statements for classification and categorization, which are brittle and difficult to manage. The presence of two distinct data sources (`adsales_revenue_performance_daily` and `asl_finance_derived.adsales_performance`) for similar 'Gross Revenue' metrics suggests potential data consistency challenges and a need for clear data governance. The absence of live SQL execution data prevents validation of query performance or actual data output, highlighting a critical area for immediate investigation.",312
c51835dc-61f0-4277-ab19-e374508dccd2,Last 6 months - highest subscriber usage,high,"The dashboard's metrics are severely limited by extensive hardcoding of `YearMonth` and specific email addresses/substrings directly within the SQL queries. This makes the dashboard static, non-reusable, and requires manual modification for any change in reporting period or target subscriber. Despite the initial AI analysis reporting '0 governance issues', the detailed metric SQL reveals significant anti-patterns related to hardcoded logic and lack of parameterization. The absence of SQL execution summary data prevents validation of query performance or actual data output, highlighting a critical gap in observability.",313
59390a9a-e996-46b9-8151-cada4cafef65,Verity At-A-Glance: Vic/tas titles,high,"The dashboard 'Verity At-A-Glance: Vic/tas titles' exhibits a high consolidation score (9) and complexity (8), which is strongly supported by the detailed metric analysis. Almost all metrics contain pervasive hardcoding of specific dates, date ranges, and categorical filter values (e.g., masthead, scenario type, product category). This leads to significant metric duplication and reduced reusability. For instance, 'Net Consumer Activity' is defined twice for different mastheads ('TM' and 'HS') and date ranges, and 'Total Additions', 'Total Cancels', and 'Net Planning Activity' share nearly identical complex date logic and filters. The absence of SQL execution data prevents validation of query performance or actual data retrieval, but the metric definitions themselves clearly indicate a need for extensive parameterization and consolidation to improve maintainability and flexibility.",314
d240dd2c-82d6-4c48-b6b9-c0965640412c,occupancy,high,"The 'occupancy' dashboard exhibits high complexity and a strong need for consolidation, as indicated by its scores and the detailed metric analysis. A significant anti-pattern is the verbatim duplication of a large `base_report_data` Common Table Expression (CTE) across all five metrics. This redundancy leads to inefficient queries, increased maintenance overhead, and a higher risk of inconsistencies. Furthermore, complex, hardcoded `CASE` statements for deriving 'Level_05' and 'states' from raw string fields are repeated, suggesting a lack of proper data modeling or lookup table utilization. The absence of live SQL execution data prevents validation of metric outputs and identification of runtime issues, highlighting a critical area for immediate investigation before further consolidation efforts.",315
c412242b-14aa-4045-84f0-b8c3b5594898,Missing PCSID deep dive,high,"The primary finding is that all attempts to query the underlying data table (`nau-data-nprod-dataservices.App_Usage.test_extract_missing_pcsid_prop14`) failed due to a 403 Access Denied error. This renders the dashboard currently unusable and prevents any validation of the defined metrics against live data. Based on the metadata, several metrics utilize hardcoded logic for filtering by 'cm android', which could lead to maintenance issues and lack of flexibility if other platforms need to be analyzed or if the platform naming convention changes.",316
dc9bcf46-d0a0-4501-8eb6-607f061379d9,Looker workspace test,high,"The 'Looker workspace test' dashboard, despite an initial consolidation score of 9, exhibits significant opportunities for consolidation due to pervasive SQL anti-patterns. All metrics share nearly identical, complex SQL logic, including hardcoded table metadata and refresh rate rules. This redundancy severely impacts maintainability, scalability, and potentially performance. The absence of live SQL execution data prevents validation of assumptions, but the structural issues in the SQL are clear and warrant immediate attention for refactoring.",317
a1c16d3b-d19a-4abd-b96c-7a87580815db,Verity data for finance scorecard - DRAFT,low,"The dashboard 'Verity data for finance scorecard - DRAFT' demonstrates strong consolidation practices, with all listed metrics sourced from a single, well-defined 'calendar_dim' table. This aligns with the high consolidation score (8) and indicates a well-structured data foundation for time-based dimensions. No significant coding anti-patterns, such as hardcoded values or overly complex CASE statements, were identified in the provided SQL logic. However, the complete absence of SQL query execution summary data prevents any validation of live performance, data integrity, or actual usage patterns. All listed metrics are dimensions with 'low' business criticality, suggesting this dashboard primarily provides foundational time-based slicing capabilities rather than core financial KPIs. The 'DRAFT' status of the dashboard name further supports this interpretation, implying it might be a preparatory or supporting dashboard.",318
05d7819d-3d0d-44b4-9701-0ac35c5643fa,Audio Dashboard,high,"The 'Audio Dashboard' exhibits significant opportunities for consolidation, particularly within its gender-based audience metrics. Three distinct metrics ('Total Value for Male Audience', 'Total Value for Female Audience', 'Total Value for Other Gender Audience') are derived from the same base table and factor, differing only by hardcoded 'level' values and identical hardcoded date ranges. This redundancy indicates a strong need for metric consolidation. Furthermore, all four metrics on the dashboard rely on hardcoded date ranges, limiting their dynamic utility and requiring manual updates for time-series analysis. The absence of SQL execution summary data prevents live validation, necessitating further investigation into data source connectivity and query performance.",319
7abef7bf-a809-4e7a-85dc-68f1f1dd60de,CG// Cancellations History,high,"The 'CG// Cancellations History' dashboard, while focused on a single business domain and leveraging a single source table (`subscription_cancellation_history`), exhibits significant opportunities for data model consolidation. All four metrics apply identical, complex hardcoded filtering logic for `classification_level_2` and `masthead` directly within their SQL queries. This repetition is a clear anti-pattern, increasing maintenance burden and risk of inconsistency. Furthermore, one metric uses a hardcoded `CASE` statement for data transformation. The critical absence of live SQL execution data prevents validation of these hardcoded values against actual data distributions, identification of potential performance bottlenecks, or confirmation of query success, making it a primary area for immediate investigation.",320
4e1ed0ba-1904-40e6-9841-57377cd9cb53,DCR Volumetrics Gaps - Company-level,medium,"The dashboard 'DCR Volumetrics Gaps - Company-level' primarily relies on a single source table (`ipsos_daily_gaps`) for its core volume and gap metrics. While this ensures data consistency across these related metrics, the underlying data model, where each news source's volume is a distinct column, leads to repetitive metric definitions in Looker Studio. The absence of live SQL execution data prevents validation of query performance or actual data values, making it a critical area for immediate investigation.",321
2a7796ef-1ee1-46d5-ab21-dee8ec3ac155,AI at Scale App,high,"The 'AI at Scale App' dashboard, while small with only two metrics, exhibits significant data governance and maintainability issues due to repeated hardcoded logic. Both metrics rely on an identical hardcoded list of GCP project IDs, and one metric uses a hardcoded CASE statement for environment classification. A critical discrepancy was found in the date filtering logic for the 'Non-Production' cost metric. The absence of SQL execution summary data prevents validation of performance or live data accuracy, highlighting a key area for investigation in the data collection pipeline.",322
3e772890-cbb1-4939-8441-1e1a1463042c,Senior Executive Report,high,"The 'Senior Executive Report' dashboard, while rated with a high initial consolidation score, presents significant opportunities for technical consolidation and improved maintainability. A critical observation is the widespread use of hardcoded `CASE WHEN` statements for essential business classifications (e.g., 'Masthead Classification', 'Campaign Classification') across numerous metrics. This leads to duplicated logic, increased risk of inconsistencies, and higher maintenance overhead. Furthermore, the absence of `sql_execution_summary` data prevents any validation of these metrics against live query performance or actual results, highlighting a critical gap in the analysis process. The initial AI analysis reported '0 total governance issues', which directly contradicts the clear anti-patterns identified through a detailed review of the SQL logic.",323
155c4518-72bf-4309-a0e9-240dd564f421,Portfolio Performance Dashboard,high,"The Portfolio Performance Dashboard, initially assessed with a high consolidation score (9) and complexity (8), appears to be well-structured at the data source level. All seven defined metrics consistently draw from the same BigQuery table (`ncau-data-newsquery-prd.asl_finance_derived.adsales_performance`). This indicates a strong foundation for data consolidation, leveraging a single source of truth for sales performance metrics. The use of `relative_fy_year_offset`, `relative_fy_quarter_offset`, and `stly_flag` in the SQL logic suggests a robust and consistent approach to defining time-based metrics (current, last, same time last year). However, the complete absence of `sql_execution_summary` data prevents any live validation of these metrics, making it impossible to confirm query performance, data accuracy, or identify potential runtime issues. This lack of live execution data elevates the consolidation priority to 'high' for further investigation.",324
6a26c78f-0070-4fb3-88b8-691ee4a4485a,Circ Budget Revenue Weekly Report,high,"The 'Circ Budget Revenue Weekly Report' dashboard, while operating within a single finance domain and utilizing a consistent core fact table (`v_asl_FCT_finance_os_aggregated`), exhibits significant anti-patterns that severely hinder maintainability, scalability, and data governance. The initial AI-generated analysis incorrectly reported '0' governance issues, whereas a detailed review of the SQL logic reveals extensive hardcoding and repetition. Specifically, complex `CASE` statements for publication mapping and sales channel categorization are duplicated across nearly all 9 metrics. Furthermore, the 'Adjusted Daily Volume' metrics contain highly intricate, hardcoded calculation logic with a critical logical flaw (`OR (TRUE)`), indicating a high risk of inaccurate reporting. The absence of live SQL execution data prevents validation of current dashboard performance or data accuracy, but the inherent structural issues in the SQL demand immediate attention for refactoring and consolidation.",325
f79368a4-e0e4-4e11-89f6-352a9aedf50d,Wine EDM Newsletter Reporting,high,"While the dashboard's metrics are highly consolidated around a single source table (`newsletter_activity`), there are significant opportunities for semantic and logical consolidation. A large number of metrics are duplicated solely to apply a 'Wine' filter, which could be handled more efficiently at the dashboard or data model level. Furthermore, complex, hardcoded `CASE` statements are extensively used for categorization and revenue calculation, leading to duplicated logic and maintainability challenges. The initial AI-generated consolidation score of 8 appears to reflect data source consolidation but overlooks the logical and semantic fragmentation within the dashboard's metric definitions.",326
a4975f7b-4ea2-49f2-bb3c-213a94741b78,Business Dash,high,"The initial AI-generated analysis indicates a high consolidation score (9) and zero governance issues. However, a detailed review of the SQL logic for the 28 metrics reveals significant anti-patterns that severely undermine consolidation and governance. Specifically, numerous metrics are created for individual channel and source-channel combinations using hardcoded `CASE` statements and `WHERE` clauses, leading to high maintenance overhead and inflexibility. The absence of a `SQL Query Execution Summary` and the presence of `LIMIT 100` in all provided SQL queries prevent validation against live data, suggesting these might be sample queries rather than production ones, which itself is an area for investigation.",327
61f1feb4-fc3e-4bee-b987-84c86cfe6425,Digital - Publications and Products Monthly ,high,"The dashboard 'Digital - Publications and Products Monthly' presents significant opportunities for data model consolidation and improved maintainability. A critical observation is the absence of SQL execution summary data, which prevents validation of metric logic against live query performance or results. However, the detailed metric definitions reveal a pervasive anti-pattern: a complex `CASE` statement for 'Revenue Type Grouped' is hardcoded and repeated across multiple metrics. Additionally, several key metrics hardcode specific financial years (2024, 2025), necessitating annual manual updates. Addressing these patterns would substantially enhance the dashboard's robustness, scalability, and ease of maintenance.",328
bb0005fc-e838-471c-a79c-157d08e8b75e,Official Habit Tracker Dashboard,low,"The 'Official Habit Tracker Dashboard' is reported with a high consolidation score (8/10) and medium complexity (6/10), suggesting a relatively well-structured dashboard. However, the absence of live SQL execution data prevents validation of metric performance or data accuracy. Analysis of the static SQL logic reveals several anti-patterns, primarily the use of hardcoded `CASE` statements for categorizations (e.g., masthead groups, site sections) and repetitive `LEFT JOIN UNNEST` clauses with identical filtering conditions across multiple metrics. While the dashboard is consolidated, these patterns indicate a need for refactoring to improve maintainability, consistency, and adherence to data architecture best practices, rather than a need for further consolidation of disparate data sources.",329
783f341c-8660-4e90-bab8-9bc860119cf5,Deals Dashboard,medium,"The 'Deals Dashboard' is designed for the advertising domain, with a reported good consolidation score. However, the critical absence of SQL execution summary data prevents any validation of the dashboard's live performance, query efficiency, or data accuracy. Analysis of the underlying SQL for both metrics reveals significant reliance on hardcoded values for filtering, particularly for the 'Filtered Buyer List' metric. This practice introduces maintenance overhead, limits reusability, and could lead to data staleness or inaccuracies if not regularly updated. The 'Total Revenue Net' metric also uses a hardcoded list of transaction types, indicating a similar anti-pattern.",330
7a48a00d-07f9-4bbe-9333-a282d7182754,FY26 Content Dashboard (Julie),high,"The dashboard 'FY26 Content Dashboard (Julie)' exhibits a high complexity and consolidation score (both 8), indicating a significant opportunity for optimization. A primary observation is the complete absence of `sql_execution_summary` data, which prevents validation of assumptions against live query performance or results. However, analysis of the detailed metric SQL logic reveals a strong anti-pattern: extensive and identical hardcoded filtering logic is repeated across multiple core digital revenue metrics. This repetition significantly increases maintenance overhead and risk of inconsistency. Furthermore, financial years are hardcoded in several calculated fields, necessitating manual updates annually. The dashboard also contains a metric with intentionally inconsistent filtering compared to its related metrics, which, while documented, poses a risk for user misinterpretation.",331
19077aa0-64b6-4ca2-b0ce-4e328780e073,Self Learning Segments Report,high,"The 'Self Learning Segments Report' dashboard exhibits a high degree of consolidation potential due to pervasive hardcoded filters repeated across all defined metrics. While the initial AI analysis reported 0 governance issues, a deeper dive into the SQL logic reveals significant anti-patterns related to filter management. The absence of live SQL execution data prevents validation of performance or actual query outcomes, but the structural issues in the SQL itself indicate a strong need for refactoring to improve maintainability, flexibility, and reusability. Specifically, one metric (`agg_total_final_price_amount_filtered`) is highly specialized with numerous hardcoded values, severely limiting its general utility.",332
4d233abb-3d9b-4942-98b0-3989e8986970,Verity Newsroom display - National Sports Newsroom,low,"The dashboard is simple, containing only one metric, and has a good consolidation score (7/10). However, the absence of SQL query execution data prevents validation of the metric's live performance or data integrity. The single metric's SQL logic also contains hardcoded values for publication groups, indicating a potential anti-pattern for maintainability and scalability.",333
1bcad774-082f-442e-94b0-7a65967fc751,Hermes Daily Trading Dashboard,high,"The 'Hermes Daily Trading Dashboard' exhibits critical data consistency and maintainability issues due to extensive hardcoding within its SQL queries. A significant observation is the inconsistent hardcoded `visit_date` across 'visits' metrics: 'Total Visits Detailed' uses '2025-03-04', while 'Total Visits by Segment Group' and 'Total Visits by Segment Group and Hour (Filtered)' use '2025-03-11'. This directly undermines the 'Daily' nature of the dashboard and can lead to misleading comparisons and analysis. Furthermore, all metrics contain a `LIMIT 100` clause, potentially truncating data and presenting an incomplete picture. The absence of any live SQL execution summary data prevents validation of query performance or actual results, highlighting a critical gap in data observability and requiring immediate investigation.",334
1147dd47-ccea-49cb-bff0-6019f3249bc9,Verity 2.0 Daily C-Score report: HS,high,"The dashboard, named 'Verity 2.0 Daily C-Score report: HS', is severely impacted by hardcoded date ranges in its sole metric's SQL logic, rendering it static and unsuitable for a 'Daily' report. While the initial AI analysis reports a high consolidation score (9), this likely pertains to the underlying metric's definition (being derived from a base metric) rather than the dashboard's overall consolidation or reusability, as it contains only one metric. The absence of SQL execution summary data prevents validation of query performance or results, highlighting a critical gap in observability.",335
05edacf6-0910-4e94-bbe4-00ebc469fc80,Metadata explorer,high,"The dashboard's initial consolidation score of 9 suggests high reusability, but a deeper analysis of the SQL logic reveals significant anti-patterns. Multiple metrics duplicate complex CTEs, leading to redundant code and increased maintenance overhead. Furthermore, there's an observed inconsistency in data source environments, with some metrics pulling from a Production (PRD) environment and others from a System Integration Testing (SIT) environment, which poses a risk to data reliability. The absence of SQL execution summary data prevents validation of query performance and success.",336
f5e8e7c6-17e2-4ad7-bae5-79dfa8c47c3a,Verity 1.0 Daily C-Score report: DT,high,"The dashboard, named 'Verity 1.0 Daily C-Score report', heavily relies on metrics with hardcoded dates and date ranges. This anti-pattern suggests that new metrics are created for each reporting period, leading to significant technical debt and poor maintainability, directly contradicting the 'daily' nature implied by its name. While the initial AI analysis reported 0 governance issues, a deeper dive into the SQL logic reveals several critical anti-patterns related to hardcoding and inconsistent grouping. The absence of SQL execution summary data prevents validation of query performance or actual data behavior, leaving a critical gap in the analysis.",337
1479f9e9-5993-4969-a5b4-e74112f9134a,BSG - PowerBI,high,"The dashboard 'BSG - PowerBI' is designed to monitor BigQuery job activity within the operations domain. While the initial AI analysis indicates a high consolidation score (8), a deeper review of the detailed metric SQL reveals significant opportunities for improving logic consolidation and maintainability. All metrics draw from the same `JOBS_BY_PROJECT` table, which is a good foundation for data source consolidation. However, the pervasive use of hardcoded date ranges across multiple queries and the repetition of common date/time extraction logic present critical maintainability and accuracy issues. The absence of SQL query execution summaries prevents validation of performance or actual data results, highlighting a key area for investigation. The initial AI assessment of '0 governance issues' is contradicted by the identified hardcoded logic anti-patterns.",338
37641205-ec3e-4184-a5dd-f5ca79248335,Digital Subscriptions Report,high,"The 'Digital Subscriptions Report' dashboard, despite an initial assessment of '0 governance issues', exhibits critical anti-patterns. Its 'Current Week' metrics are hardcoded to a specific future date (FY2025, Week 43), rendering the dashboard static and ineffective for real-time reporting. Furthermore, extensive hardcoded `CASE` statements for masthead classification across all metrics severely impact maintainability and scalability. The absence of SQL execution data prevents validation of query performance or success, raising concerns about the dashboard's operational status.",339
6640a246-777a-4fcf-a692-85e02e7f7a8e,Supercoach Engagement Activity Summary,high,"The most critical finding is that all SQL queries for this dashboard failed due to a '403 Access Denied' error when attempting to query the underlying BigQuery table `nau-data-nprod-dataservices.auyeunga_sandbox.supercoach_engagement_test`. This prevents any validation of the dashboard's metrics against live data and renders the dashboard non-functional. Immediate investigation into data access permissions is required. Despite the initial AI analysis indicating a high consolidation score, the current operational status makes this a high-priority issue. Furthermore, a pattern of hardcoded filter values was observed in several metrics, which could lead to maintenance challenges and potential data incompleteness if not managed properly.",340
2b1f75a1-b473-4415-b29a-665bd2b492ae,News Pass Extract,high,"The 'News Pass Extract' dashboard, while having a good consolidation score of 7, exhibits significant opportunities for improvement in its underlying SQL logic. The most prominent issue is the repeated, complex CTE (`newspass_acquisitions`) across multiple high-criticality metrics. This anti-pattern increases maintenance overhead and introduces potential for inconsistencies. Live data validation confirms the general intent of the metrics but highlights a potential ambiguity in the business definition versus the SQL implementation for one key metric, 'Total Subscription Movements (Newspass, FY 2024-2025)', which appears to count all movements for News Pass acquired subscriptions, not just acquisitions. Additionally, hardcoded values for customer segments are present, indicating a need for more dynamic data handling.",341
8b343aa3-712e-49fe-97d4-73c8eda5277c,FY24 The Australian AOD Report,high,"The dashboard, 'FY24 The Australian AOD Report', is designed for the marketing domain with a moderate complexity and consolidation score. While the initial analysis reported zero governance issues, a deeper dive into the detailed metric SQL reveals several significant anti-patterns and potential data quality concerns. Crucially, the absence of `sql_execution_summary` data prevents real-time validation of metric performance or data consistency, necessitating further investigation into the data pipeline. The dashboard heavily relies on hardcoded filters and repeated `CASE` statements for classification and segmented measures, indicating a strong need for data model consolidation and improved metric governance.",342
376cca44-97b3-4959-aa0f-e228a9e1e408,BSG Heath - Check,high,"The 'BSG Heath - Check' dashboard, critical for operations and data freshness monitoring, exhibits significant governance and maintainability issues. Its core data freshness logic and expected refresh rates are implemented via highly complex, hardcoded SQL with extensive CASE statements and UNION ALLs. This anti-pattern has likely contributed to the consistent 'Syntax error' failures observed in the `primary_analysis_sql`, `validation_sql`, and `business_rules_sql` executions. While basic table structure queries succeed, the dashboard's ability to accurately report on data freshness is severely compromised by these underlying SQL issues and poor coding practices. Consolidation and refactoring are urgently needed to ensure reliability and scalability.",343
61c9dcaa-ebb1-48fc-9d1d-1b0042d3c075,CODE Unlocked articles,high,"The 'CODE Unlocked articles' dashboard, despite an initial AI assessment of high consolidation (score 8) and zero governance issues, exhibits significant architectural anti-patterns. All four metrics heavily rely on hardcoded lists of 'unlocked' article IDs and fixed date ranges directly embedded in their SQL queries. This approach severely compromises maintainability, scalability, and data governance. Any change to the definition of 'unlocked articles' or the reporting period necessitates manual modification of multiple SQL queries, leading to high operational overhead and a significant risk of inconsistencies and errors. The dashboard's current implementation is static and not suitable for dynamic, ongoing analysis.",344
d768f28d-cc4a-4314-b972-cffd680d1bb8,Adpoint Line Items,medium,"The 'Adpoint Line Items' dashboard, focused on advertising revenue, exhibits strong consistency in its base data filtering criteria across all metrics, which is a positive sign for data governance. However, the analysis reveals a significant reliance on hardcoded business logic within individual metric definitions, particularly for specific publications, advertisers, and financial years. This pattern suggests a lack of parameterization or externalized configuration, leading to potential maintenance overhead and inflexibility. The absence of live SQL execution data prevents validation of performance or data accuracy, making it a critical area for immediate investigation. While the dashboard has a high consolidation score (8) according to the initial AI analysis, the detailed metric review indicates opportunities for further consolidation and abstraction of common filtering logic and business rules.",345
52d44d9a-25d9-4ce0-8c70-a26a9eef8a10,CODE Sport Report,high,"The 'CODE Sport Report' dashboard, despite having a reported consolidation score of 7, exhibits significant opportunities for further data model consolidation and SQL optimization. A primary observation is the complete absence of `sql_execution_summary` data, which prevents validation of metric performance and actual query behavior. However, the detailed metric definitions reveal pervasive anti-patterns: numerous metrics are defined with highly repetitive `CASE` statements and hardcoded values for channel and campaign classifications. This indicates a lack of a robust, centralized semantic layer for key business dimensions, leading to brittle, difficult-to-maintain, and potentially inconsistent metric definitions. The hardcoded date filters further exacerbate maintenance overhead. Addressing these patterns is a high priority to improve data governance, reduce complexity, and enhance dashboard performance and reliability.",346
830018a3-2d7c-4496-bd33-5471d610b39d,Verity 2.0 Daily C-Score report: AA,low,"The dashboard 'Verity 2.0 Daily C-Score report: AA' is reported with a high consolidation score of 8, indicating a well-structured and potentially reusable set of metrics. Both defined metrics ('Total C-Score Target by Publication Group' and 'Total C-Score Target by Publication Group and ISO Week') are derived from the same base table (`cdm_reference_data.cscore_targets`) and share the same base metric (`sum_c_score_target`). This strong commonality suggests good design principles for data reusability and consistency. However, the critical absence of SQL query execution summary data prevents any validation of these metrics against live performance, query efficiency, or actual data consistency, making it impossible to confirm the real-world impact or identify potential discrepancies despite the reported high consolidation.",347
70ed3b92-987b-479b-9ed7-d2903bd2787e,Monthly Invoicing Breakdown,high,"The 'Monthly Invoicing Breakdown' dashboard, despite its low reported complexity, exhibits significant anti-patterns, primarily pervasive hardcoding of specific advertiser names, booking numbers, and static labels within its metrics. This severely limits the dashboard's reusability and dynamic capabilities, making it suitable only for very specific, fixed reporting scenarios. The initial AI analysis reported '0 governance issues,' which is contradicted by the detailed metric review revealing multiple instances of poor coding practices. Crucially, the absence of `sql_execution_summary` data prevents any validation of these metrics against live query results, leaving potential data discrepancies or performance issues unaddressed. The dashboard's current state necessitates a refactor to improve flexibility, maintainability, and scalability.",348
1d90f8d5-1170-44b0-9c20-3e16f00ddf1d,"Code Sports Clusters age, gender, mosaic ",high,"The dashboard's initial consolidation score of 7 appears to be an overestimation when examining the underlying SQL. A significant anti-pattern of repeated base data preparation logic (CTE, joins, filtering, and window functions) is present across all metrics. This indicates a lack of shared data models or views, leading to potential inconsistencies, increased maintenance overhead, and inefficient query execution. The absence of `sql_execution_summary` prevents validation of query performance or actual data outcomes, making this a critical area for investigation. The dashboard's focus on subscriber demographics (age, gender, mosaic) is clear, but the implementation suggests a siloed approach to metric definition rather than a consolidated data layer.",349
02e77971-7980-47de-853b-5bc0943a65b1,VERITY AT A GLANCE - REGIONALS,high,"The analysis of the 'VERITY AT A GLANCE - REGIONALS' dashboard reveals significant opportunities for consolidation and improved maintainability. A critical observation is the absence of live SQL execution data, which prevents validation of metric logic against real-world performance or results. However, the detailed metric definitions expose a pervasive anti-pattern: the extensive use of hardcoded dates and filter values directly within the SQL queries. This practice severely limits the dashboard's dynamic utility, requiring manual updates for date changes and making it difficult to adapt to new regional or product definitions without modifying each metric's underlying SQL. The dashboard's high consolidation score (8) from the initial AI analysis is contradicted by the observed hardcoded logic, suggesting the score might reflect the *potential* for consolidation rather than its current state. The dashboard's 'REGIONAL' focus is undermined by specific masthead filters ('THINK', 'NT', 'TC') rather than a generalized regional dimension.",350
9c8f39dc-bf5f-4292-bfe3-c6e1ec71c588,Streaming Performance FY26,high,"The 'Streaming Performance FY26' dashboard, despite an initial AI-generated consolidation score of 9, exhibits significant opportunities for SQL consolidation and refactoring. The detailed metric SQL reveals extensive duplication of complex CTEs and hardcoded logic across multiple metrics and dimensions. The absence of live SQL execution data prevents validation of current performance or data accuracy, but the observed anti-patterns strongly indicate potential for performance bottlenecks, increased maintenance burden, and risk of data inconsistencies. A primary observation is the repeated, inefficient `UNION ALL` structure used to combine revenue and target data within nearly every metric's SQL.",351
a6dbe5ec-8104-48cb-8395-d29b9c3e3494,B2B Engagement Dashboard,high,"The 'B2B Engagement Dashboard' exhibits a critical lack of parameterization and excessive hardcoding within its metric definitions, despite drawing all data from a single source table (`b2b_subscription_engagement`). This contradicts the initial AI's high consolidation score (8), which likely only considers the single data source, not the underlying SQL logic. Key anti-patterns include fixed date ranges, hardcoded company names (e.g., American Express aliases), specific agency codes (e.g., USQ, I-CEDA, I-ABCNSW), and site sections ('news'). This design severely limits the dashboard's flexibility, reusability, and maintainability, requiring manual updates for any change in scope or time period. The absence of SQL execution summary data prevents validation of query performance or actual data results, leaving potential issues unaddressed.",352
bedebbe4-3e46-47d5-bc36-6d867544ba66,News Incident Report,high,"The primary analysis was limited by the absence of live SQL execution data, preventing validation of metric assumptions against real-world performance or results. However, a detailed review of the metric definitions reveals significant opportunities for consolidation. All five metrics share highly repetitive filtering logic and query the same base table, indicating a strong need for a centralized data model or view to improve maintainability and consistency.",353
47325be1-3ddd-4d01-8fc0-3ec1e532b196,Verity 2.0 user table lookup,high,"The 'Verity 2.0 user table lookup' dashboard, while seemingly well-defined in its metrics, exhibits critical anti-patterns that severely limit its utility and data accuracy. The most significant observation is the pervasive use of `LIMIT 100` across all metric SQL queries, rendering the dashboard incapable of displaying comprehensive data. Additionally, several aggregation metrics contain hardcoded filters for specific users or roles, which restricts their reusability. The absence of `sql_execution_summary` data prevents validation of live query performance or results, highlighting a gap in observability. Despite a reported 'consolidation score' of 6 and '0 governance issues' in the initial AI analysis, the detailed metric review reveals fundamental data integrity and design flaws that necessitate immediate attention for this dashboard to be considered reliable for operational use.",354
5f6befe5-af10-4fe9-80aa-9d3827c672a,EDV - Status Monitoring,high,"The initial AI analysis reported a high consolidation score (8) and zero governance issues. However, a detailed review of the SQL logic for the 'Record Count by iDeliver Entity' metrics reveals significant anti-patterns, including extensive hardcoding, complex repeated `UNION ALL` statements, and duplicated de-duplication logic across two distinct but structurally identical metrics. This indicates a low level of underlying SQL consolidation and introduces substantial maintenance overhead. The absence of `sql_execution_summary` data prevents validation of query performance or actual data output, leaving critical areas for investigation.",355
00f8a37b-0c5f-40fd-be45-f408b3b6e0e5,Business CLV Dash,high,"The 'Business CLV Dash' dashboard, despite an initial high consolidation score (9), exhibits significant underlying SQL anti-patterns and a critical lack of live data validation. The most pressing issue is the pervasive use of `LIMIT 1` in all provided metric SQLs, which fundamentally questions whether these are the actual queries driving the dashboard's data. Without live execution data, it's impossible to validate the dashboard's accuracy or performance. Furthermore, numerous hardcoded values and repeated filter clauses across metrics indicate poor maintainability and scalability, contradicting the high consolidation score. The dashboard's reliance on hardcoded logic for categorization and filtering suggests a high technical debt and potential for data discrepancies if underlying business rules or data change.",356
81522b56-4697-49ac-93da-6faed306d799,GOOD Churn Score - Counts by healthcare Updated DG 140224 ,high,"The dashboard 'GOOD Churn Score - Counts by healthcare Updated DG 140224' demonstrates good data source consolidation by leveraging a single BigQuery table (`churn_automation`) for all its metrics. However, a critical anti-pattern observed is the pervasive use of hardcoded `CASE` statements for defining 'churn_category' across multiple metrics, leading to maintenance challenges and potential inconsistencies. Furthermore, a significant concern is the reliance on specific, hardcoded *future* date ranges (e.g., July-Aug 2025, April-May 2025, Feb-Mar 2025) for different metrics. This design choice severely limits the dashboard's utility for real-time or historical churn analysis and suggests it's either built for very specific future projections or lacks dynamic date filtering capabilities. The absence of live SQL execution data prevents validation of query performance or actual data output, necessitating further investigation into the dashboard's operational status and the relevance of these future dates.",357
abe67573-53fb-4cc2-a622-5cb9aa208166,Verity 2.0 - Prod - Newsroom display - TWT,high,"The dashboard 'Verity 2.0 - Prod - Newsroom display - TWT' exhibits a significant anti-pattern of metric proliferation. All 6 high-criticality metrics are essentially identical, differing only by hardcoded `targetdate` values and a hardcoded `website` ('The Weekly Times'). The `sql_execution_summary` confirms the underlying `subscription_targets` table contains data for 18 unique websites and over 2000 unique target dates, validating that a highly parameterized and consolidated approach is feasible. The reported 'consolidation_score' of 9 for this dashboard appears contradictory to the observed metric structure, suggesting a potential misinterpretation by the initial AI analysis or a flaw in the scoring methodology.",358
58dce9a4-ca60-474d-bf3a-733ee23e565b,Sports monthly snapshot - IPSOS,high,"The 'Sports monthly snapshot - IPSOS' dashboard is severely limited by its highly static nature. All 8 defined metrics contain hardcoded date ranges (July 2025 for content interaction metrics and April 2025 for IPSOS audience metrics) and specific categorical filters (e.g., 'sport' site section, 'Smartphone' device, 'All' gender/age). This design prevents the dashboard from dynamically updating for new reporting periods, making it unsustainable for a 'monthly snapshot' and requiring constant manual intervention. The absence of a SQL execution summary prevents any validation of these metrics against live data, leaving critical gaps in understanding their performance, accuracy, and potential for runtime errors.",359
906ca8a7-1733-4a1a-b2f5-2660551f3d3a,Month End Reporting Reconcilation - ME team copy,high,"The dashboard, titled 'Month End Reporting Reconcilation', is severely impacted by extensive hardcoding of fiscal years and specific months (e.g., 2025, Jan, Apr, Aug, Jul) across nearly all its metrics. This fundamentally contradicts its implied purpose as a dynamic, recurring month-end report, rendering it a static snapshot for 2025. Furthermore, the presence of `LIMIT 10` in every SQL query suggests these metrics are either for testing/preview or are severely restricting the data displayed, making the dashboard functionally incomplete for reconciliation purposes. The absence of a `sql_execution_summary` prevents validation of live data performance or actual results, highlighting a critical gap in monitoring. Despite an initial AI assessment of a high consolidation score (8) and zero governance issues, the detailed SQL analysis reveals significant anti-patterns that necessitate immediate attention for maintainability, accuracy, and future usability.",360
8531208f-5b20-40d0-8b57-2d15ac1fca33,Verity 2.0 Toowoomba Chronicle Sunrise Report,high,"The dashboard is reported as having a high consolidation score (9) and low complexity (2), containing only one high-criticality KPI: 'Total C-Score Target by Publication Group'. The metric's SQL definition appears straightforward and uses good practices like `SAFE_CAST`. However, the critical finding is the complete absence of SQL query execution summary data. This prevents any validation of the metric's performance, actual data output, or comparison against the AI's initial assumptions regarding filtering. The high consolidation priority is due to the inability to validate the dashboard's operational health without execution data.",361
4b158218-2a09-443c-929a-a7f5dae09979,BEYOND WORDS,low,"The 'BEYOND WORDS' dashboard is characterized by its extreme simplicity, containing only one high-criticality KPI: 'Total Distinct Contacts'. The underlying SQL logic for this metric is straightforward and appears correctly structured for its intended purpose (a simple COUNT(DISTINCT) operation). However, a significant limitation in this analysis is the complete absence of SQL Query Execution Summary data. This prevents any real-world validation of the metric's performance, actual data output, or the identification of potential runtime issues, thereby hindering a comprehensive assessment of the dashboard's operational health or the accuracy of the initial AI-generated complexity and consolidation scores based on live data.",362
ec3c813c-6c23-4a43-926c-73a56c6df69e,TCS Governance Dashboard [Data Portfolio] V2,high,"The 'TCS Governance Dashboard [Data Portfolio] V2' exhibits significant opportunities for consolidation and improvement. A critical observation is the complete absence of `sql_execution_summary` data, which prevents validation of the SQL logic against live performance or results. Analysis of the detailed metric SQL reveals pervasive hardcoding of filters (e.g., assignment groups, task types, SLA types), date ranges, and result limits across all metrics. Furthermore, one metric directly references a development dataset (`ncau-data-newsquery-dev`) for a lookup table, posing a significant governance and stability risk. These issues indicate a dashboard that is highly static, difficult to maintain, and potentially unreliable in a production environment, warranting high consolidation priority.",363
e63c5845-a981-4540-bb6d-0aba73a2dd3f,FY25 Copy of - Team Sales Performance - TY vs LY,high,"The dashboard, 'FY25 Copy of - Team Sales Performance - TY vs LY', despite an initial high consolidation score (9), exhibits significant underlying data integrity and coding practice issues. A critical error in 6 out of 10 metrics, specifically the `(CASE WHEN (false = true) THEN 1 ELSE 0 END) = 1` condition, will cause these metrics to consistently return no results, rendering a substantial portion of the dashboard non-functional. Furthermore, the widespread use of hardcoded filter values and complex, repeated `CASE` statements for data transformations (e.g., `adtype_l1` and `product_group` mapping, financial period formatting) indicates poor maintainability and scalability. This contradicts the reported high consolidation score and suggests a need for immediate refactoring to leverage a more robust, centralized data model or lookup tables.",364
f65a9149-93b4-4aa9-aef6-d12002853222,Digital Video Content Audio,high,"The dashboard 'Digital Video Content Audio' is in the advertising domain and is reported by the initial AI analysis as having a high consolidation score (8) and no governance issues. However, a detailed review of the underlying SQL for its three metrics reveals significant anti-patterns, primarily extensive hardcoding of exclusion lists and category definitions. This contradicts the initial assessment of 'high consolidation' and '0 governance issues', indicating a strong need for consolidation efforts. Crucially, the absence of `sql_execution_summary` data prevents validation of the live performance or data integrity of these metrics, making it an immediate area for investigation.",365
b15d856f-e3ce-4991-bf2a-92395390524f,Programmatic Rolling 60 Day Overview_NQ Data,high,"The analysis of the 'Programmatic Rolling 60 Day Overview_NQ Data' dashboard reveals significant opportunities for consolidation and improvement in data governance. A critical observation is the complete absence of live SQL execution data, which prevents validation of the provided SQL logic against actual query performance or results. However, the detailed metric definitions expose a repeated hardcoded `CASE` statement for SSP grouping across multiple key metrics, indicating a strong need for centralized logic. Furthermore, all provided SQL queries contain a `LIMIT 10` clause and the 'rolling 60 day' metrics use a hardcoded *future* date range, which are highly suspicious for a production dashboard and suggest either placeholder logic or fundamental design flaws.",366
b9dfd2f4-92fa-4f81-a5b1-17de880470f9,Contra Report,high,"The 'Contra Report' dashboard, despite its medium consolidation score, exhibits significant architectural debt due to highly repetitive and complex filtering logic across almost all revenue-related metrics. This indicates a lack of a centralized, well-defined 'Open Contra Account' business rule within the data model, leading to duplicated and hardcoded definitions in individual metric SQL. The absence of SQL execution data prevents validation of performance or data consistency in a live environment but highlights the critical need for refactoring to improve maintainability and reliability.",367
d410ca5f-3513-4250-ae00-7f18c6347e8c,Verity 2.0 Newsletters Performance and Value,high,"The dashboard 'Verity 2.0 Newsletters Performance and Value' exhibits significant opportunities for improvement despite its high initial consolidation score (9) and reported zero governance issues. A deep dive into the metric definitions reveals pervasive anti-patterns, primarily the extensive use of complex, hardcoded `CASE` statements with `REGEXP_CONTAINS` for business logic (e.g., categorizing newsletter types, calculating value scores, and determining costs). This logic is duplicated across numerous metrics, leading to high maintenance overhead and potential inconsistencies. Crucially, several key metrics contain logically contradictory filters (e.g., filtering for 'DailyTelegraph' AND 'TheAustralian' simultaneously), which will inevitably result in zero data, rendering them useless. Furthermore, many metrics are configured with future date ranges, suggesting either a misconfiguration or an attempt to display forecast data without clear indication of its source. The absence of `sql_execution_summary` prevents direct validation against live query results, but the identified SQL anti-patterns strongly indicate data accuracy and maintainability challenges.",368
f0af9ebe-dbaa-4690-9e9b-fba30a7e514d,NCA newsletters reporting template - for News Corp global,high,"The dashboard, while having a high initial consolidation score, exhibits a critical lack of live SQL execution data, preventing validation of metric outputs. A deep dive into the metric definitions reveals a pervasive anti-pattern: extensive use of hardcoded `CASE` statements and `REGEXP_CONTAINS` clauses for defining key dimensions like `newsletter_brand_group`, `newsletter_type_category`, and various email flags. This approach severely impacts maintainability, scalability, and data governance, making future updates or expansions highly prone to errors. The most complex dimensions (`is_marketing_email_combined_flag_dimension`, `newsletter_source_category_dimension`) are particularly problematic, indicating a strong need for a centralized data modeling layer or lookup tables. Additionally, the consistent presence of `LIMIT 1` in all metric SQL definitions is an unusual artifact, likely from the extraction process, but would be problematic if applied directly to dashboard queries without aggregation or grouping.",369
5f09cf50-19d6-4027-80de-69b30aba367e,Essentials Engagement Reporting DG ,medium,"The dashboard 'Essentials Engagement Reporting DG' demonstrates strong data source consolidation, with all four metrics drawing from the same BigQuery table (`DG_ESSENTIALS_REPORTING_SEPT23_TABLE3`). This is reflected in its high consolidation score (8). However, the analysis of detailed metric SQL reveals two key areas for improvement in coding practices and logical consistency. Firstly, the initial AI analysis's concern regarding the 'Sum of Subscriber IDs by Site Section' metric is validated, as summing a likely unique identifier (`subscriber_id_SRC`) is an anti-pattern. Secondly, the 'Unique Subscribers by Current Month SPV Bucket' metric relies on hardcoded `CASE` logic for bucketing, which can hinder maintainability and reusability. The absence of `sql_execution_summary` data prevents validation against live performance or data discrepancies, making these observations based purely on static SQL analysis.",370
3c56145d-9022-4a17-8a57-ba6fd911e013,Verity 2 - PRD - Habit Forming Dashboard - Newsletters and Website Preferences,high,"The dashboard's metrics, particularly those related to 'Filtered Newsletter Activity' (Opens, Delivered, Unsubscribes, Clicks, Sends, Bounces, Record Count), exhibit significant duplication of complex filtering logic. This anti-pattern, involving extensive `REGEXP_CONTAINS` and hardcoded values, severely impacts maintainability and scalability. The absence of SQL execution summary data prevents validation of these complex queries against live performance or result sets, highlighting a critical area for investigation. The dashboard's high complexity (score 8) and moderate consolidation (score 7) are directly reflected in these observed coding practices, indicating a strong need for refactoring to improve data governance and reusability.",371
8f848270-688f-4455-82a6-3bc9a7d39cce,Newsquery Health App,high,"The analysis reveals a critical lack of live SQL execution data, preventing validation of the dashboard's performance and actual data output. However, the detailed metric definitions expose significant anti-patterns in SQL coding practices. Both metrics on the dashboard ('Total Monitored Tables' and 'Tables Not in Critical Alert') use nearly identical, extensive SQL logic, differing only in their final aggregation. This redundancy, coupled with hardcoded table lists and complex `CASE` statements, indicates a high need for consolidation and refactoring to improve maintainability, consistency, and scalability. The dashboard's name ('Newsquery Health App') also appears to conflict with its stated 'finance' business domain, warranting further investigation into its true purpose.",372
41dda2e0-7935-4eca-9a86-1b0e763c2657,News.com.au Daily Update 5.0,high,"The initial AI analysis reported low complexity and consolidation scores with zero governance issues for this 'Daily Update' dashboard. However, a deeper review of the detailed metric SQL reveals critical design flaws: both high-criticality KPIs use hardcoded `visit_date` filters, and crucially, these dates are *different* for each metric (2025-06-04 vs. 2025-06-12). This fundamentally undermines the dashboard's stated purpose of providing a 'Daily Update' and indicates a high priority for refactoring. The empty `sql_execution_summary` prevents validation against live data, highlighting a separate area for investigation regarding data observability.",373
39513a1d-8a62-4150-ab05-06786b4ecda1,Verity 2.0 The Australian: Sunrise Report (Click here to access the full report),high,"The dashboard exhibits strong data source consolidation, with all metrics drawing from a single BigQuery view (`v_masthead_performance_summary`). However, this positive aspect is significantly undermined by critical hardcoded logic. Most notably, the `articledateupdated` is hardcoded to a future date (e.g., '20250513'), rendering the dashboard static and unable to display current or historical data. Furthermore, a complex CLV-derived article scoring calculation is duplicated across multiple metrics, indicating a lack of centralized logic definition. The absence of a SQL Query Execution Summary prevents validation of live data performance or actual results, making it impossible to confirm the dashboard's operational status or data accuracy.",374
464dbd27-97f1-4665-bd93-22b4e9520bfe,Audience Insights - Adds Performance - DRAFT,high,"The dashboard 'Audience Insights - Adds Performance - DRAFT' is flagged by the initial AI analysis with a high consolidation score (8), yet a deeper dive into the underlying SQL reveals significant opportunities for consolidation and adherence to best practices. Both metrics exhibit repeated filtering logic and, critically, hardcoded date ranges, rendering the dashboard static and requiring manual updates. The absence of SQL execution summary data prevents validation against live results, highlighting a critical area for investigation.",375
cbab66df-64cb-4ec6-a112-088557684b7e,FY25 OS extract for month end rec,high,"The 'FY25 OS extract for month end rec' dashboard, a critical financial reporting tool, exhibits a significant and pervasive anti-pattern: the identical, complex `OSandFACT` Common Table Expression (CTE) is duplicated across the SQL logic for every single metric. This structural redundancy means that each metric's calculation re-executes the same set of joins and data preparation steps, leading to highly inefficient queries, increased BigQuery costs, and a substantial maintenance burden. While live SQL execution data is unavailable for direct performance validation, the inherent design flaw indicates a high-priority consolidation and optimization opportunity. The dashboard's high complexity score (8) and its focus on business-critical financial KPIs ('Actual Amount', 'Last Year Actual Amount', 'Budget Amount', 'Forecast Amount') underscore the urgency of addressing this architectural inefficiency.",376
d3b51d1f-8b66-440f-9bc3-cc96429075bd,Verity 2.0 - S&C Federal Election Daily,high,"The dashboard 'Verity 2.0 - S&C Federal Election Daily' exhibits significant opportunities for consolidation and improved maintainability. Despite a high reported consolidation score of 8, the detailed metric analysis reveals a strong anti-pattern: two core KPI metrics are essentially duplicates, differing only by hardcoded date ranges. Furthermore, both metrics rely on a hardcoded list of news websites. This approach severely limits the dashboard's flexibility, increases maintenance overhead, and contradicts the spirit of a high consolidation score. The absence of SQL execution summary data prevents validation of query performance or actual data values, leaving potential issues unaddressed.",377
c902dea7-7c03-4995-a4f5-56ff4f6f5635,SMS send monthly count by brand,low,"The dashboard is highly consolidated with only two metrics, as indicated by its consolidation score of 5. However, the analysis reveals significant discrepancies between the business descriptions of the metrics and their underlying SQL logic, particularly concerning data aggregation levels and the use of hardcoded date ranges. The absence of SQL execution summary data prevents validation of live performance or results, highlighting a critical gap in observability for this dashboard.",378
bb75f9e0-40f6-44f7-b17c-7441e71c90e5,Interim Adsales Performance Dashboard PDFs-FY26,high,"The dashboard, 'Interim Adsales Performance Dashboard PDFs-FY26', exhibits a high initial consolidation score (9) and complexity (8) according to the AI-generated summary. However, a deeper analysis of the underlying SQL logic reveals significant anti-patterns and opportunities for improved consolidation and maintainability. The most critical observation is the complete absence of `sql_execution_summary` data, which prevents validation against live query performance or results. This necessitates framing findings as observations and areas for investigation. The primary consolidation issues stem from redundant metric definitions (e.g., `_000s` versions) and a highly complex, hardcoded, and time-sensitive conditional revenue metric that severely impacts maintainability and future accuracy.",379
3f582360-cbc4-4ee3-80a7-14fa61b2f1fd,NIS KPI REPORT,high,"The analysis reveals critical gaps in the 'NIS KPI REPORT' dashboard's data integrity and maintainability. Most notably, the complete absence of SQL query execution summaries prevents any validation against live data, making it impossible to confirm the dashboard's actual performance or data accuracy. A significant anti-pattern is observed in the provided SQL logic for all metrics, including the 'Total Opportunity Amount' KPI, where a 'LIMIT 1' clause is present. If this reflects the actual queries, it would lead to fundamentally incorrect aggregated results. Furthermore, all opportunity-related metrics are hardcoded to a specific fiscal year (July 2024 - June 2025), severely limiting the dashboard's utility for dynamic analysis and requiring annual manual updates. These issues indicate a high priority for consolidation and remediation to ensure data reliability and future usability.",380
a8df8e47-f86a-4a5a-8cee-13dd26cc367f,FNL Marketing Report,high,"The 'FNL Marketing Report' dashboard, despite a relatively high initial consolidation score (7/10), exhibits critical data validity concerns and significant hardcoding anti-patterns. The most pressing issue is the presence of future dates (e.g., 2025, 2029) in the `sql_execution_summary` sample data for both Adobe clickstream and subscription metrics. This directly contradicts the `validation_sql` reporting 'PASS' for freshness checks, indicating a potential disconnect between validation logic and actual data state, or a test environment. Furthermore, a pervasive anti-pattern of hardcoded lists (brands, mastheads) and fixed start dates for subscription data severely limits the dashboard's flexibility, maintainability, and accuracy, potentially leading to underreported or outdated results. The repeated use of `COUNT(CASE WHEN ... THEN 1 END)` for channel-specific subscription metrics also points to a need for more robust dimensional modeling.",381
ed91d3f4-4175-4293-a648-e8dbca4cea93,Newscorp Australia Daily Update,high,"The dashboard, named 'Newscorp Australia Daily Update', exhibits a critical anti-pattern: two out of four metrics contain hardcoded dates and brand names. This directly contradicts the implied 'daily update' and dynamic nature suggested by its name, indicating a significant lack of reusability and maintainability. While the initial analysis reported a high consolidation score (7), this appears to refer to the number of base metrics rather than the reusability of derived metrics, as the specific metrics are highly fragmented. Furthermore, the absence of SQL query execution data prevents any validation of live performance or data accuracy, making it impossible to confirm if the dashboard is functioning as expected or if there are any runtime issues.",382
73e125c7-5447-4e59-9560-ed12d7c7f153,Adomik Snowflake v NQ CDM,high,"The dashboard's three core metrics (Total Gross Revenue, Total Impressions, Total Net Revenue) are defined with highly repetitive and complex SQL logic. A significant anti-pattern of duplicated subqueries was identified, indicating a strong need for data model consolidation. Crucially, the absence of live SQL execution data prevents any validation of query performance, actual results, or potential data discrepancies, highlighting a critical gap in the current analysis process.",383
68765694-fddc-495e-a598-2a5b1e78e2c9,VERITY AT A GLANCE - CODE Verity 2.0 - Prod - At-a-Glance,medium,"The dashboard 'VERITY AT A GLANCE' demonstrates a high degree of internal metric consolidation, evidenced by its reported consolidation score of 9 and the clear pattern of reusing base metrics (e.g., 'adds', 'cancels', 'net_movement', 'subscriber_count') with different filtering criteria. This indicates a well-structured approach to defining metrics within the dashboard. However, a deeper analysis of the underlying SQL logic reveals opportunities for further data model consolidation and improved maintainability. Specifically, repeated hardcoded filter values and the use of `STRPOS` for categorization suggest that a more robust semantic layer or lookup tables could enhance reusability and reduce potential for errors. A critical observation is the absence of SQL execution summary data, which prevents validation of query performance, actual data values, and identification of potential data mismatches or performance bottlenecks.",384
d7dcf866-1b93-48f8-a0c3-56c743029896,Digital Campaign Performance - Data Validation,high,"The dashboard exhibits strong data source consolidation, with all 23 metrics drawing from a single BigQuery table (`ncau-data-newsquery-prd.bdm_consumer.campaign_performance_fct`). This is excellent for data consistency and simplifies data governance. However, a critical anti-pattern observed is the pervasive use of hardcoded future date ranges (April 15 - May 14, 2025) across 11 of the 23 metrics, including all key performance indicators (spend, impressions, clicks, subscriptions) and one dimension. This severely limits the dashboard's utility for real-time or dynamic digital campaign performance monitoring, suggesting it might be a static snapshot, a template requiring parameterization, or intended for a specific future validation period. The absence of live SQL execution data (`sql_execution_summary` is empty) prevents validation of query performance, actual data output, or identification of runtime errors, making it impossible to confirm if the metrics are functioning as expected in a live environment.",385
470fb761-78c5-4d29-9791-1f9b5fa3ce10,FY25 Copy of Adsales Performance Dashboard - FY25,high,"The dashboard 'FY25 Copy of Adsales Performance Dashboard - FY25' exhibits a high degree of data source consolidation, with all analyzed metrics drawing from a single BigQuery table (`ncau-data-newsquery-prd.asl_finance_derived.adsales_performance`). This is a positive foundation for data governance and performance. However, the detailed metric definitions reveal significant anti-patterns in SQL logic, primarily characterized by pervasive hardcoded `CASE` statements for filtering and transformations (e.g., time offsets, revenue types, sales segments, and even display formatting). This internal lack of consolidation within metric definitions contradicts the reported '0 governance issues' and indicates a high maintenance burden, potential for inconsistencies, and reduced reusability. The absence of `sql_execution_summary` prevents validation against live performance, but the `LIMIT 1` clause found in all metric SQLs is a critical observation, suggesting these are likely individual scorecard definitions rather than queries for aggregated components, which could severely impact dashboard flexibility and performance if applied broadly.",386
8a5e8eb0-fe0e-40f6-9131-e7a564f5e60b,NewsQuery Data Reconciliation Dashboard - For Ops,high,"The 'NewsQuery Data Reconciliation Dashboard - For Ops' is designed to monitor data freshness using a well-structured control table, indicating good data governance practices. However, the critical absence of SQL query execution summary data prevents any validation of the dashboard's live functionality and the accuracy of its reported metrics. This makes it impossible to confirm if the dashboard is currently serving its operational purpose effectively. Furthermore, a key base metric contains a 'LIMIT 1' clause, making its standalone interpretation ambiguous, and the use of 'LIKE' for load type filtering could be refined for precision.",387
52b2e0a6-fd53-4788-94da-101037302104,Data Townhall Feedback,low,"The 'Data Townhall Feedback' dashboard is characterized by its simplicity, containing only one metric: 'Total Distinct Contacts'. This aligns with its low complexity (1) and consolidation (1) scores. The metric's SQL logic is a straightforward `COUNT(DISTINCT)` query, indicating no immediate coding anti-patterns. However, a critical observation is the complete absence of SQL query execution summary data, which prevents validation of the metric's live performance or data retrieval success. Despite the dashboard's low consolidation priority due to its simplicity, its 'high' business criticality means that ensuring the underlying data is accessible and the metric is correctly populating is a high operational priority.",388
ae8a7e4a-6850-4617-aca7-de689047229d,News monthly snapshot - IPSOS,high,"The dashboard, 'News monthly snapshot - IPSOS', exhibits a paradox in consolidation. While all four metrics leverage the same underlying BigQuery table (`ipsos_mom_audience_view`), indicating good data source consolidation (reflected in the initial AI's high consolidation score of 9), the SQL logic for each metric is severely hardcoded. This hardcoding of the reporting month (to '2025-07-01'), category ('News'), subcategory ('Travel'), device, gender, and age dimensions fundamentally undermines the dashboard's ability to serve as a dynamic 'monthly snapshot' or to provide a comprehensive view of 'News' data. The live data confirms the underlying table contains a much broader range of dates and categories, highlighting that the current metric definitions are highly restrictive and static, necessitating significant refactoring for true reusability and dynamism.",389
acf4223b-efb2-4a6e-961d-a2f5fe0e004e,Verity 2.0 - Daily Digital Retro - DT,high,"The dashboard 'Verity 2.0 - Daily Digital Retro - DT' exhibits a significant anti-pattern of metric proliferation due to hardcoded dates and repeated filter logic. Despite an initial 'consolidation_score' of 8, the detailed metric analysis reveals that 6 out of 9 metrics are essentially variations of 'Total Adds', 'Total Cancels', and 'Net Adds/Cancels' for specific, hardcoded dates (May 20, 2025, and May 26, 2025), all sharing identical filtering criteria ('Standard Paid' class, 'Digital' delivery, 'DT' masthead). Similarly, 'Daily Website Target' metrics are duplicated for different hardcoded dates/ranges. This approach severely limits the dashboard's flexibility, scalability, and maintainability. The absence of `sql_execution_summary` data prevents validation against live query performance or results, but the structural issues in the SQL logic are evident and actionable.",390
3dba3db1-7b70-4bd1-9c89-c78fd19832ac,Gen Ai: comment summaries,high,"The 'Gen Ai: comment summaries' dashboard, despite an initial high consolidation score, exhibits significant opportunities for improvement due to repeated hardcoded logic across its three metrics. All metrics share a nearly identical SQL structure, differing primarily in their specific filtering criteria for emotion categories and, critically, in their hardcoded date ranges. This hardcoding severely limits the dashboard's dynamic utility and maintainability. The absence of SQL execution summary data prevents validation of query performance or actual data patterns, necessitating further investigation into the underlying data and query execution.",391
70dc50c7-72fe-4268-8e22-6de00e463d20,Verity 2.0 NewsLocal and NSW NRM performance,high,"The dashboard is reported as low complexity (3) and high consolidation (8) with only two simple, high-criticality KPI metrics. However, the complete absence of SQL execution summary data prevents any validation of the dashboard's live performance, data accuracy, or query efficiency. While the metrics themselves are straightforward aggregations from a single table, the lack of execution insights makes it impossible to confirm the dashboard's operational health or the validity of its reported targets. This missing information elevates the consolidation priority to high, as the fundamental ability to assess the dashboard is compromised.",392
c9529742-6e47-4644-ae3e-87ace36730cc,Verity 2.0 CODE weekly report,high,"The dashboard, despite being named a 'weekly report', fundamentally relies on hardcoded date ranges (May 5-11, 2025) for both of its high-criticality metrics. This design choice severely limits its utility as a dynamic weekly reporting tool, requiring manual updates for each new reporting period. The two metrics are highly similar in structure, differing only by the aggregated column from the same source table, indicating a strong opportunity for consolidation into a more flexible and maintainable data model. Crucially, the absence of SQL execution summary data prevents validation of these metrics against live results, necessitating further investigation into their actual performance and output.",393
3cf1c516-8797-455b-913a-8722b604bbfe,Audience Insights - The Australian engagement,medium,"The dashboard's initial consolidation score of 8 appears optimistic given the underlying SQL logic. A critical observation is the complete absence of SQL execution summary data, which prevents any validation of query performance, actual data volumes, or runtime errors against the detailed metric definitions. Analysis of the metric definitions reveals significant anti-patterns: multiple metrics rely on hardcoded dates or date ranges, which will lead to static and outdated data. There's also a notable inconsistency in filtering logic for key dimensions like 'customer_type' and 'masthead' across different metrics, indicating a lack of standardized data definitions or a robust semantic layer. Furthermore, the pervasive use of `LIMIT 100` in all queries is highly concerning for production metrics, suggesting these might be development or testing queries rather than live reporting.",394
f9d4736d-1798-45d3-90c2-150a93d50e55,Copy of Data Services_Looker Studio_Template_MASTER,high,"The dashboard 'Copy of Data Services_Looker Studio_Template_MASTER' exhibits a high degree of hardcoded business logic, specifically for age and gender categorization, which is redundantly defined across all 7 metrics. This anti-pattern significantly increases maintenance burden and the risk of data inconsistencies. Furthermore, the use of a fixed, hardcoded date range renders the dashboard static and unsuitable for dynamic analysis. A critical observation is the absence of live SQL execution data, which prevents any validation of query performance, cost, or actual data returned, limiting the depth of this analysis and highlighting a gap in monitoring capabilities.",395
8087886f-b3c5-4337-a45e-f51b8819a362,Funnel Report Official,medium,"The 'Funnel Report Official' dashboard demonstrates a high degree of data source consolidation, primarily relying on the `t_visit_funnel_conversion` table for all its metrics. This is positive for data consistency and simplifies data governance. However, a significant anti-pattern observed is the repeated hardcoded `CASE` statement logic for 'Referrer Group' across multiple measure metrics, which introduces maintenance overhead and potential for inconsistencies. Furthermore, the presence of hardcoded date ranges in several queries severely limits the dashboard's dynamic utility. Crucially, the absence of SQL execution summary data prevents any validation of query performance, cost, or actual data consistency in a live environment, making it a high priority for further investigation.",396
23c8b213-a9f0-4158-b8fa-bff14425abb5,TM1 NewsQuery Tables,high,"The 'TM1 NewsQuery Tables' dashboard, focused on finance subscriptions, exhibits a critical anti-pattern: multiple high-criticality metrics are hardcoded to a single fiscal week ('202535'). Live data confirms the underlying table contains 61 unique fiscal weeks (202501-202609), rendering the dashboard static and incapable of dynamic trend analysis. Additionally, most dimension metrics use a 'LIMIT 10' clause, artificially restricting the available filter values, despite the underlying data having significantly more unique entries (e.g., 27,716 business unit codes). This severely limits the dashboard's utility and indicates a high priority for consolidation and refactoring to enable dynamic filtering and comprehensive data exploration.",397
e83da1de-4227-43e6-bcc6-73051c66914b,Ad Events Dashboard,high,"The dashboard's 'Gross Revenue' metrics, despite sharing a common `base_metric_id`, are implemented using distinct underlying tables and datasets. This fragmentation contradicts the initial AI's high consolidation score (8) and indicates a significant opportunity for data model consolidation. Furthermore, the absence of live SQL execution data prevents validation of metric accuracy or performance, highlighting a critical area for investigation. One metric also exhibits a clear anti-pattern with hardcoded, error-prone values.",398
25db1e50-2b08-468d-8b46-c06dc1308920,Consumer - Core Subscription Health Check ,high,"The 'Consumer - Core Subscription Health Check' dashboard aims to monitor data freshness and integrity for critical NewsCycle and `prstn_consumer` tables. However, the provided `SQL Query Execution Summary` is empty, preventing any validation of the dashboard's live performance or data accuracy. A detailed review of the metric SQL reveals significant anti-patterns, including repeated hardcoded lists of table names across multiple metrics, and highly complex, nested `CASE` statements for freshness logic. Furthermore, several key metrics (`prstn_consumer_table_name`, `prstn_consumer_update_time_aest`, `prstn_consumer_row_count`, `prstn_consumer_row_check`, `prstn_consumer_refresh_rate`) are designed with `LIMIT 1` clauses, which, combined with their `ORDER BY` logic, will only ever display data for a single, often arbitrary, table. This fundamentally undermines the dashboard's stated purpose of providing a 'Health Check' for *multiple* tables. The initial AI analysis stating '0 governance issues' is inaccurate given these pervasive coding anti-patterns and design flaws.",399
5dae02f0-dc48-418c-bdf9-5e5d2b1d6e26,Optimizing Digital Subscriptions Report,high,"The 'Optimizing Digital Subscriptions Report' dashboard, despite an initial AI assessment of '0 governance issues', exhibits significant anti-patterns and hardcoded logic across its metrics. The high complexity and consolidation scores are validated by the detailed SQL, which reveals extensive repetition of complex `CASE` statements and filtering logic. Key issues include a hardcoded fiscal calendar, an unusual 'record volume' calculation, and inefficient generation of constant dimensions. The lack of live SQL execution data prevents direct validation of metric values but highlights the need for a thorough code review and refactoring to improve maintainability, performance, and data governance.",400
415199ee-c67c-4b55-85f1-38b4aa291931,Finance | Business Performance Summary,high,"The dashboard 'Finance | Business Performance Summary' exhibits a high degree of logical repetition and hardcoded values across its metrics, despite a reported high consolidation score. All analyzed metrics pull from the same base table (`tableau_operating_statement_query`) and redundantly re-execute complex subqueries for date flagging and ML model forecasting. This anti-pattern leads to inefficient query execution, significant maintenance overhead, and a high risk of inconsistencies or stale data, particularly with hardcoded dates and business unit filters. The absence of live SQL execution data prevents direct validation of performance impacts but strongly suggests substantial optimization opportunities through data model consolidation.",401
601ed0d2-e944-4189-8170-d593c8e72026,Adex,high,"The 'Adex' dashboard, despite its high initial consolidation score, exhibits significant opportunities for refactoring and consolidation at the SQL metric definition level. Multiple key metrics (Total Spend, News Corp Spend, Nine Spend, Record Count) share nearly identical and complex SQL logic for date period calculations, leading to high redundancy and maintenance overhead. A critical observation is the hardcoded time period selection ('Rolling 12 months') within these SQL definitions, which contradicts the business description implying dynamic period selection. The absence of live SQL execution data prevents validation of these assumptions and the actual performance impact, highlighting a key area for immediate investigation.",402
bb49fa78-5abe-4e68-a9c1-8172a832e724,optimization,high,"The initial AI analysis's claim of '0 governance issues' is directly contradicted by the detailed metric SQL. A significant anti-pattern exists where three critical filter metrics (`cancellation_type_filter`, `view_type_filter`, `date_metric_type_filter`) are implemented with hardcoded `CASE WHEN (1=1)` logic, rendering them static and non-functional as dynamic filters. This severely impacts the dashboard's interactivity and data governance. Furthermore, the core financial metrics (Budget Earned Amount, Closing Base, Opening Base, Earned Amount, Net Change) exhibit highly repetitive SQL logic, indicating a strong opportunity for consolidation and parameterization to improve maintainability and reduce query complexity. The absence of `sql_execution_summary` prevents validation of live data performance or errors, but the logical flaws are evident from the SQL definitions.",403
5491badf-5ec0-4b4f-a427-b12a3a3395dd,Programmatic / Tubi Performance FY25,high,"The dashboard, focused on 'Programmatic / Tubi Performance FY25' revenue, exhibits significant opportunities for consolidation and improved data governance. Despite an initial AI assessment of '0' governance issues, a detailed review of the SQL logic reveals a pervasive anti-pattern: a complex, hardcoded `CASE` statement used to derive revenue types. This logic is duplicated across all 24 metrics, leading to high maintenance overhead, potential for inconsistencies, and reduced query efficiency. Additionally, 'Past Dates' metrics rely on hardcoded timestamps, which will not dynamically update, requiring manual intervention or leading to stale data over time. The absence of `sql_execution_summary` prevents validation against live performance but highlights a potential gap in monitoring or data collection.",404
647e7eab-0b9d-4a55-8429-becd2ee551d1,Food monthly snapshot - IPSOS,medium,"The dashboard exhibits high data source consolidation, with all four metrics drawing from the same `ipsos_mom_audience_view` table. However, a significant anti-pattern is observed in the form of extensively hardcoded filter values (Gender, Age, Category, Subcategory, Device) within the SQL logic of every metric. While this ensures consistency across the dashboard's current scope, it severely limits flexibility, increases maintenance overhead for any future changes to these filters, and prevents dynamic analysis. The absence of live SQL execution data prevents validation of query performance or actual data output.",405
67786617-e360-4dd1-a220-285d379e356f,Adsales Performance Dashboard - FY25 Archive Archive - JJ,high,"The dashboard, despite an initial AI consolidation score of 9, exhibits significant anti-patterns in its metric definitions, primarily due to repeated hardcoded logic for fiscal year/period offsets and scaling. The 'Archive Archive' in the dashboard name suggests it may be deprecated or a temporary copy, raising questions about its current relevance and maintenance. Crucially, the absence of SQL execution summary data prevents validation of live performance or data integrity, elevating the consolidation priority to high due to potential hidden issues and maintenance burden.",406
18fdc9a7-66dc-49aa-909e-dd751e5ba491,Adsales Performance Dashboard - FY25,high,"The 'Adsales Performance Dashboard - FY25' exhibits a high degree of metric proliferation, primarily driven by variations of base metrics (e.g., 'gross_revenue_amount', 'ss_lgb') filtered by financial year offsets and scaled for presentation (e.g., 'in K'). This indicates a significant opportunity for consolidation through parameterization and dynamic filtering at the dashboard level, rather than hardcoding in SQL. A critical observation is the complete absence of SQL query execution data, which prevents validation of query performance, cost, or success rates, leaving a major blind spot in the analysis. Furthermore, the presence of highly complex, hardcoded date logic and specific segment filters within metric definitions poses substantial maintainability risks and limits reusability.",407
af564bd3-ec49-4836-9e6f-2040699aa76b,DP Dashboard - Draft v1,high,"The dashboard exhibits significant opportunities for consolidation and refactoring due to highly repetitive and inconsistent SQL logic across its metrics. A critical issue is the misapplication of date ranges for year-over-year comparisons, where FY2024 metrics for 'Metro' masthead group are filtered by calendar dates in FY2025, leading to inaccurate comparisons. Furthermore, the absence of live SQL execution data prevents validation of actual query performance or results, necessitating further investigation into data availability and permissions.",408
b456ee91-66d6-4bcb-b3a7-c752a3e02170,Verity 2.0 - S&C Health Last Week,high,"The dashboard, despite an initial high consolidation score, exhibits significant anti-patterns in its SQL logic. All three metrics rely heavily on hardcoded values for date ranges, website lists, and content categories. This makes the dashboard static, difficult to maintain, and prone to displaying outdated or inaccurate information without constant manual updates. The absence of live SQL execution data prevents validation of these metrics against real-world performance or data consistency, highlighting a critical gap in observability.",409
0aff66b8-3b9d-4830-96ec-abef5f7eb7ef,Publisher and Product Performance Dashboard - FY25,high,"The dashboard, 'Publisher and Product Performance Dashboard - FY25', exhibits a high degree of conceptual consolidation, with 11 metrics derived from a single underlying table (`adsales_performance`). However, the implementation of these metrics reveals significant opportunities for technical consolidation and improved maintainability. The absence of `sql_execution_summary` data prevents validation against live query performance or data discrepancies, making this a critical area for immediate investigation. The current metric definitions rely heavily on repeated `CASE WHEN` statements for time-based filtering, indicating a potential anti-pattern that could be streamlined through a more robust data model or semantic layer.",410
258a722d-9b6e-45df-ba00-1b9954ec36b2,Debtor to Account Mapping,high,"The dashboard exhibits strong data source consolidation, with four out of five metrics deriving from a single, well-defined view (`v_asl_gbaba_act_xref`). This aligns with the high consolidation score from the initial AI analysis. However, a critical anti-pattern was identified: the SQL logic for the primary account mapping dimensions (`Adpoint Account`, `Genera Booking Account`, `Medium Rare Debtor Account`, `National Debtor Account`) includes a `LIMIT 1` clause. This fundamentally cripples their utility as true dimensions for mapping multiple accounts, rendering the dashboard's core purpose potentially unfulfilled. The initial AI analysis incorrectly reported '0' governance issues, as this `LIMIT 1` pattern represents a significant data usability and governance flaw. The absence of SQL execution summary data prevents validation of actual query performance or results, necessitating further investigation.",411
4e74297f-bdb0-426c-9c82-d42067eef9ee,SEO Reporting Suite,high,"The dashboard's initial high consolidation score (5) is misleading. Key performance indicators like 'Total Clicks' and 'Total Impressions' are severely limited by hardcoded date ranges (February 2025), specific brand filters ('Vogue Austraila'), and query exclusions. This renders the 'SEO Reporting Suite' static and non-reusable for general analysis across different brands or time periods. Furthermore, the absence of SQL execution summary data prevents validation of these metrics against live query performance or results, highlighting a critical data observability gap.",412
9461b1c8-5b2b-4267-882b-42b427c26abb,Interim Adsales Performance Dashboard PDFs (Curr),high,"The 'Interim Adsales Performance Dashboard PDFs (Curr)' demonstrates a high degree of internal consolidation, as indicated by its consolidation score of 9 and the fact that all 5 metrics originate from a single BigQuery table (`ncau-data-newsquery-prd.asl_finance_derived.adsales_performance`). The metrics consistently apply `relative_fy_year_offset` for time-based filtering and simple arithmetic for unit conversion (e.g., 'Thousands'). This consistency suggests a well-structured data source and metric definitions. However, the critical absence of `sql_execution_summary` data prevents any validation of these metrics against live query results. This means we cannot confirm the accuracy of the reported logic, identify potential performance bottlenecks, or detect discrepancies between the intended metric calculation and actual data outcomes. The dashboard's inherent consolidation is strong, but the ability to fully analyze and validate it is currently impaired.",413
40ca2399-e61c-42bd-874c-ea7be0681a4b,KTV Dashboard,high,"The initial AI analysis reported a high consolidation score (5) and zero governance issues for the 'KTV Dashboard'. However, a detailed review of the underlying metric SQL reveals a critical anti-pattern: all metrics utilize hardcoded date ranges directly embedded in their queries. This practice severely limits the dashboard's flexibility and reusability, directly contradicting the 'no governance issues' claim. While article-related metrics are well-consolidated to a single table (`ktv_articles_traffic_summary`) with a consistent hardcoded date range, the video metric uses a different table (`ktv_video_views`) and a *different* hardcoded date range, indicating a lack of a unified date filtering strategy across the entire dashboard. The complete absence of live SQL execution data prevents any validation of query performance or actual data output, making it impossible to confirm the efficiency or accuracy of the current setup.",414
5b6fc742-e514-4052-9c56-1d7a44f755f6,Decay - Dev,high,"The 'Decay - Dev' dashboard exhibits significant opportunities for consolidation and optimization. All four metrics, including the two primary KPIs, share identical and complex Common Table Expressions (CTEs) and subquery structures, leading to highly redundant SQL execution and maintenance overhead. A critical issue is the hardcoded date range (January 2023) in all queries, rendering the dashboard static and irrelevant for current analysis. Furthermore, several business classification rules are hardcoded within CASE statements, making the logic brittle. Despite the initial AI analysis reporting '0 governance issues', the detailed SQL review reveals multiple anti-patterns that warrant immediate attention for improved data governance, performance, and maintainability. The absence of SQL execution summary data prevents validation of query performance or actual data output, highlighting a gap in monitoring.",415
50a98d01-2d0b-4834-8bb2-02b4e4bd1a32,Advertising Bespoke Report - Bikash,high,"The analysis of the 'Advertising Bespoke Report - Bikash' dashboard reveals significant opportunities for metric consolidation and code refactoring, primarily due to repetitive SQL logic for gross revenue calculations and a hardcoded categorization dimension. A critical observation is the absence of live SQL execution data, which prevents validation of metric performance or data accuracy against real-world query results. This lack of execution data also means that potential data mismatches or performance bottlenecks cannot be identified at this stage. However, the detailed metric definitions themselves highlight anti-patterns that, if addressed, would greatly improve maintainability and scalability, aligning with the initial AI's high consolidation score.",416
6e8b534b-485a-48dd-842d-13dc6bebb01a,SuperCoach Subscriptions,high,"The 'SuperCoach Subscriptions' dashboard exhibits a high degree of hardcoded logic and significant repetition across its metrics. Specifically, complex `CASE` statements for tenure bucketing, specific rate plan codes, fiscal years, and date ranges are embedded directly into multiple SQL queries. The absence of live SQL execution data prevents validation of these metrics against actual query performance or data consistency. This pattern of hardcoding introduces substantial maintenance overhead, reduces the dashboard's flexibility for future analysis (e.g., different time periods or rate plans), and indicates a strong need for data model consolidation, parameterization, and the use of lookup tables or UDFs to centralize business logic.",417
56624f8b-0974-4212-b3ef-46f11233c639,Stuart Kavanagh - Leader: My week last week,high,"The dashboard's name, 'My week last week', strongly implies a need for dynamic, relative date filtering. However, three of the five high-criticality metrics are implemented with hardcoded absolute date ranges for specific weeks in 2025. This severely limits the dashboard's utility, makes it non-dynamic, and contradicts the initial AI's high consolidation score (7). This design requires manual updates or new metrics for each new reporting period, indicating a significant anti-pattern for maintainability and scalability. Furthermore, the `sql_execution_summary` reveals that the underlying `events_intraday_*` table contains data up to September 2025, which is unusual for 'raw events' and warrants immediate investigation into the data's nature and source.",418
2be6f653-1c32-4515-8ede-29ea3e3eb6db,VERITY AT A GLANCE - CODE Weekly,high,"The dashboard leverages well-consolidated underlying data models, as indicated by its high initial consolidation score (8) and the shared use of core tables like `consumer_planning` and `v_consumer_activity_daily_summary`. This suggests a strong foundation for data governance and consistency. However, the current implementation of individual metrics heavily relies on hardcoded dates and specific categorical values within their SQL logic. This significantly limits the dashboard's dynamic capabilities and reusability, requiring manual SQL updates for different reporting periods or segments, which contradicts the 'Weekly' nature implied by the dashboard name. The absence of live SQL execution data prevents validation of query performance or actual data consistency, highlighting a critical area for investigation and potential optimization.",419
cabfc5e4-47f1-4952-a8f3-4d888c5c71e,Closing Base Extracts,high,"The 'Closing Base Extracts' dashboard, while having a high consolidation score in the initial AI analysis, exhibits significant anti-patterns in its metric definitions. Multiple critical dimensions ('Product', 'Product Group', 'Finance Recognition', 'Masthead Group') and a key KPI ('Total Subscription Count') share an identical, complex `base_data` CTE. Furthermore, the categorization logic for 'Product', 'Product Group', 'Finance Recognition', and especially 'Masthead Group' is extensively hardcoded using nested CASE statements. The 'Masthead Group' logic is duplicated across two high-criticality metrics, one of which uses a different base table, creating a high risk of inconsistency and maintenance burden. The absence of live SQL execution summaries prevents validation of these patterns against actual query performance or data completeness, but the structural issues are clear.",420
ff4058c3-43f5-4324-a3ce-0c1aa455d67b,SANDBOX VERSION - Paid Consumer Subscriptions Acquisition Dashboard,high,"The dashboard exhibits significant opportunities for consolidation and refactoring. A pervasive anti-pattern is the repeated, complex `CASE` statement logic for categorizing `masthead`, `classification_level_2`, and `subscription_type` across nearly all metrics. This duplication creates a high maintenance burden and risk of inconsistency. Furthermore, the 'Fiscal Week Label' and certain other metrics contain hardcoded dates and fiscal periods, severely limiting the dashboard's dynamic utility. The absence of live SQL execution data prevents validation of these metrics against actual query performance or result sets, highlighting a critical area for investigation.",421
97531177-92c7-4a87-a050-5ca4ddc02025,NSN ALL STAFF REPORT,high,"While the initial AI analysis rated this dashboard with a high consolidation score (8), a deeper review of the metric SQL reveals significant opportunities for further consolidation. All 8 metrics exhibit repeated hardcoded date ranges (for 'long range', 'current week', and specific fiscal years) and hardcoded publication group filters ('National Sports Newsroom'). This anti-pattern leads to a proliferation of similar metrics, making the dashboard less maintainable and scalable. The dashboard's current structure relies on creating a new metric for each specific time period or publication group filter, rather than leveraging dynamic dashboard controls or a more flexible data model. This discrepancy between the reported consolidation score and the observed implementation indicates a high priority for consolidation efforts.",422
b200db65-c2e7-4ec3-9e73-bb31875b15dc,Newsquery Health Dashboard,high,"The 'Newsquery Health Dashboard' exhibits significant opportunities for consolidation and improved data governance. While the initial analysis reported 0 governance issues, a deeper dive reveals critical anti-patterns. The most pressing issue is the severe duplication of an extremely complex SQL subquery across three key 'critical job monitoring' metrics. This not only inflates the dashboard's complexity but also poses substantial risks to maintainability and consistency. Additionally, several 'platform healthcheck' metrics rely on hardcoded values for statuses and platform names, making them brittle and difficult to scale. A notable observation is the use of a development environment data source for critical job monitoring, which is unusual for a 'Health Dashboard' and warrants immediate investigation.",423
e6db873d-657f-40e8-87a0-007d41f68a55,Verity 2.0 The Australian,high,"This dashboard is extremely narrow in scope, featuring only one highly specific metric ('Total Day Target Website for The Australian' with a fixed date range). The empty SQL query execution summary prevents validation of the metric's live performance or data accuracy. The hardcoded date range and specific 'The Australian' filter indicate a strong opportunity for consolidation into a more generalized dashboard with dynamic filtering, significantly improving reusability and reducing maintenance overhead. Given its 'consolidation_score' of 1 and single metric, it's a prime candidate for refactoring into a broader, more flexible reporting solution.",424
f66cffd5-1632-45cb-a645-f5c18f7b730e,FY24 Regionals Report,high,"The 'FY24 Regionals Report' dashboard, despite a reported consolidation score of 7, exhibits significant anti-patterns in its metric definitions. A total of 32 metrics are derived from two primary tables (`v_subscription_movement` and `campaign_performance_consol`), with extensive repetition of hardcoded WHERE clauses across all metrics from each respective source. Furthermore, channel and source categorization relies on fragile `COUNT(CASE WHEN ... THEN 1 END)` logic with explicit `NOT IN` clauses for 'other' categories, indicating a strong need for robust data modeling via dimension tables. The absence of SQL execution summary data prevents validation of live performance or data accuracy, which is a critical gap for a dashboard with high complexity (8) and business criticality.",425
b084f975-486d-4a17-af39-3c20dd915f63,Audience Insights - The Courier-Mail engagement,medium,"The dashboard focuses on 'The Courier-Mail' engagement, with all three metrics consistently filtering for this masthead, consumer subscribers, and 'subscriber' member type. This consistency is positive for business context. However, the use of two distinct base tables (`subscriber_daily_base_movement` and `subscriber_base_agg`) for related subscriber counts suggests a potential opportunity for data model consolidation or clarification. Without live SQL execution data, it's impossible to validate query performance or actual data consistency, which is a significant gap in the analysis.",426
50bcb0d7-8e55-40a5-817c-2770ca32256a,Every day User request for Engagement,high,"The dashboard, 'Every day User request for Engagement', despite an initially high consolidation score, presents significant opportunities for data consistency and maintainability improvements. A critical observation is the absence of live SQL execution data, which precludes validation of query performance or result accuracy against real-world outcomes. Analysis of the SQL logic reveals inconsistent definitions for 'Consumer' across different metrics (exact match vs. partial string match) and the use of different underlying customer type fields (`t0.combined_customer_type` vs. `t0_subscription_detail.customer_type`). Furthermore, several metrics rely on hardcoded lists for filtering (e.g., `subscriber_count` ranges, `sold_in_source_referrer` values), which introduces maintenance overhead and potential for data incompleteness if these lists evolve. These issues indicate a need for data model harmonization and parameterization/lookup table implementation to enhance robustness, reduce technical debt, and ensure consistent reporting.",427
5c2ab8ff-72ab-4387-bbb9-f29746fc7985,Subscription Movement Tracking ,high,"The live data validation for the 'Subscription Movement Tracking' dashboard completely failed due to critical access denied errors and a fundamental mismatch in the table being queried by the validation system versus the table specified in the metric definitions. The metrics are defined against `ncau-data-newsquery-prd._d3f71d804267f92199dc636cdc94e5fbfecfdf65.anon238a4dc3c300b9acabd14d037141d975342e1864357b5f6b8f57d957674dbb91`, while the validation system attempted to query `nau-data-nprod-dataservices:Adriano_working_files.CustomerValue_Final`. This prevents any verification of the dashboard's data accuracy or the underlying SQL logic, making the initial complexity and consolidation scores unreliable. Immediate investigation into data source configuration and permissions is required.",428
c441950c-1e3f-432c-9838-847d1d315b9e,Circulation Insights for Analysis,medium,"The provided SQL Query Execution Summary is empty, which prevents direct validation of the dashboard's performance or data consistency against live execution results. However, the detailed metric definitions reveal significant opportunities for consolidation and improved coding practices. All metrics are hardcoded to fiscal year 2025 and exhibit repetitive logic for filtering 'charge_type' values, indicating a need for refactoring to enhance maintainability and scalability.",429
449b9707-f939-42e1-b6f5-11998369f473,Digital Subscription Report,high,"The initial AI analysis reported a high consolidation score (10) and zero governance issues for the 'Digital Subscription Report' dashboard. However, a deep dive into the SQL logic for its three high-criticality metrics reveals significant anti-patterns and severe hardcoding. All three metrics share nearly identical, deeply nested SQL, which includes extensive hardcoded `CASE` statements for masthead categorization and fiscal calendar logic. This contradicts the reported consolidation and governance scores, indicating a critical need for refactoring and data model consolidation. The absence of `sql_execution_summary` prevents validation against live performance or results, but the static SQL itself presents clear maintainability and scalability challenges.",430
e4d96e98-6c86-47ca-b925-612919b2907b,Verity 2.0 FY24 Verity Newsletter,high,"The dashboard's initial consolidation score of 8 is misleading. While it reuses `base_metric_id`s, the underlying SQL queries for 'Daily Target' metrics are highly duplicated due to hardcoded date ranges and specific website filters ('Advertiser', 'Punters'). This anti-pattern leads to an inflexible dashboard requiring new metric definitions for each new reporting period or website, increasing maintenance overhead. The absence of `sql_execution_summary` prevents validation of query performance or actual data patterns, which is a critical gap for a comprehensive analysis.",431
